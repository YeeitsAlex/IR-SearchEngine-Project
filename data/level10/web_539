http://planet.ischool.berkeley.edu
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
 <head>
  <title>
   School of Information Blogs
  </title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
  <meta content="http://intertwingly.net/code/venus/" name="generator"/>
  <link href="planet.css" rel="stylesheet" type="text/css"/>
  <link href="favicon.ico" rel="shortcut icon" type="image/x-icon"/>
  <script src="js/jquery.js" type="text/javascript">
  </script>
  <script src="js/ischool.js" type="text/javascript">
  </script>
  <script src="//use.typekit.net/fvm3lhr.js?F" type="text/javascript">
  </script>
  <script type="text/javascript">
   <!--//--><![CDATA[//><!--
try{Typekit.load({ async: true });}catch(e){}
//--><!]]>
  </script>
  <link href="http://planet.ischool.berkeley.edu/atom.xml" rel="alternate" title="" type="application/atom+xml"/>
 </head>
 <body>
  <a class="logo" href="http://www.ischool.berkeley.edu">
   <img alt="Berkeley School of Information" class="logo" src="images/berkeleyischool-logo.svg"/>
  </a>
  <h1 id="pagetitle">
   School of Information Blogs
  </h1>
  <div class="daygroup">
   <h2 class="daygroup-date">
    March 08, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://hoofnagle.berkeley.edu" title="Chris Hoofnagle | UC Berkeley School of Information, School of Law">
       Chris Hoofnagle
      </a>
     </div>
     <div class="channel-affiliation">
      adjunct professor
     </div>
    </div>
    <div class="entrygroup" id="https://hoofnagle.berkeley.edu/?p=12186">
     <h4 class="posttitle" lang="en-US">
      <a href="https://hoofnagle.berkeley.edu/2019/03/08/comments-on-the-ccpa/">
       Comments on the CCPA
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <p>
        I filed the following comments today on the CCPA to the CA AG.
       </p>
       <p>
        March 8, 2019
       </p>
       <p>
        <strong>
         <em>
          VIA Email
         </em>
        </strong>
       </p>
       <p>
        California Department of Justice
        <br/>
        ATTN: Privacy Regulations Coordinator
        <br/>
        300 S. Spring St.
        <br/>
        Los Angeles, CA 90013
       </p>
       <p>
        Re: Comments on Assembly Bill 375, the California Consumer Privacy Act of 2018
       </p>
       <p>
        Dear Attorney General Becerra,
       </p>
       <p>
        I helped conceive of the high-level policy goals of the privacy initiative that was withdrawn from the ballot with passage of AB 375. Here I provide comment to give context and explain the high-level policy goals of the initiative, in hopes that it helps your office in contemplating regulations for the CCPA.
       </p>
       <p>
        <strong>
         Strong policy support for the initiative
        </strong>
       </p>
       <p>
        As you interpret the CCPA, please bear in mind that the initiative would have passed because Americans care about privacy. In multiple surveys, Americans have indicated support for stronger privacy law and dramatic enforcement. Americans have rarely been able to vote directly on privacy, but when they do, they overwhelmingly support greater protections. One example comes from a 2002 voter referendum in North Dakota where 73% of citizens voted in favor of establishing opt-in consent protections for the sale of financial records.
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftn1" name="_ftnref1">
         <sup>
          [1]
         </sup>
        </a>
       </p>
       <p>
        A series of surveys performed at Berkeley found that Americans wanted strong penalties for privacy transgressions. When given options for possible privacy fines, 69% chose the largest option offered, “more than $2,500,” when “a company purchases or uses someone’s personal information illegally.” When probed for nonfinancial penalties, 38% wanted companies to fund efforts to help consumers protect their privacy, while 35% wanted executives to face prison terms for privacy violations.
       </p>
       <p>
        <strong>
         Information is different
        </strong>
       </p>
       <p>
        The CCPA is unusually stringent compared to other regulatory law because information is different from other kinds of services and products. When a seller makes an automobile or a refrigerator, the buyer can inspect it, test it, and so on. It is difficult for the seller to change a physical product. Information-intensive services however are changeable, they are abstract, and since we have no physical experience with information, consumers cannot easily see the flaws and hazards of them in the way one could see an imperfection in a car’s hood.
       </p>
       <p>
        Because information services can be changed, privacy laws tend to become stringent. Information companies have a long history of changing digital processes to trick consumers and to evade privacy laws in ways that physical product sellers simply could not.
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftn2" name="_ftnref2">
         <sup>
          [2]
         </sup>
        </a>
        <strong>
        </strong>
       </p>
       <p>
        <strong>
         Some of the CCPA’s most derided provisions (e.g. application to household level data) are in response to specific evasions of industries made possible because information is different than product regulation. Here are common examples:
        </strong>
       </p>
       <ul>
        <li>
         Sellers claim not to sell personal data with third parties, but then go on to say we “may share information that our clients provide with specially chosen marketing partners.”
         <a href="https://hoofnagle.berkeley.edu/feed/#_ftn3" name="_ftnref3">
          <sup>
           [3]
          </sup>
         </a>
         For this reason, the initiative tightened definitions and required more absolute statements about data selling. Companies shouldn’t use the word “partner” or “service provider” to describe third party marketers.
        </li>
        <li>
         Companies have evaded privacy rules by mislabeling data “household-level information.” For instance, the DMA long argued that phone numbers were not personal data because they were associated with a household.
        </li>
        <li>
         Many companies use misleading, subtle techniques to identify people. For instance, retailers asked consumers their zip code and used this in combination with their name from credit card swipes to do reverse lookups at data brokers.
         <a href="https://hoofnagle.berkeley.edu/feed/#_ftn4" name="_ftnref4">
          <sup>
           [4]
          </sup>
         </a>
        </li>
        <li>
         Information companies use technologies such as hash-matching to identify people using “non personal” data.
         <a href="https://hoofnagle.berkeley.edu/feed/#_ftn5" name="_ftnref5">
          <sup>
           [5]
          </sup>
         </a>
        </li>
       </ul>
       <p>
        Careful study of information-industry tricks informed the initiative and resulted in a definitional landscape that attempts to prevent guile. Those complaining about it need only look to the industry’s own actions to understand why these definitions are in place. For your office, this means that regulations must anticipate guile and opportunistic limitations of Californians’ rights.
       </p>
       <p>
        <strong>
         The advantages of privacy markets
        </strong>
       </p>
       <p>
        <strong>
         Creating markets for privacy services was a major goal of the initiative.
        </strong>
        The ability to delegate opt out rights, for instance, was designed so that Californians could pay a for profit company (or even donate to a non-profit such as EFF) in order to obtain privacy services.
       </p>
       <p>
        There are important implications of this:
        <em>
         first, the market-establishing approach means that more affluent people will have more privacy
        </em>
        . This sounds objectionable at first, but it is a pragmatic and ultimately democratizing pro-privacy strategy. A market for privacy cannot emerge without privacy regulation to set a floor for standards and to make choices enforceable. Once privacy services emerge, because they are information services and because they can scale, privacy services will become inexpensive very quickly. For instance, credit monitoring and fraud alert services are only available because of rights given to consumers in the Fair Credit Reporting Act that can be easily invoked by third party privacy services. These services have become very inexpensive and are used by tens of millions of Americans.
       </p>
       <p>
        Some will argue that the CCPA will kill “free” business models and this will be iniquitous. This reasoning underestimates the power of markets and presents free as the only solution to news. The reality is much more complex. Digital advertising supported services do democratize news access, however, they also degrade quality. One cost of the no-privacy, digital advertising model is fake news. Enabling privacy will improve quality and this could have knock-on effects.
       </p>
       <p>
        <em>
         Second, the market strategy relieves pressure on your office
        </em>
        . The market strategy means that the AG does not have to solve all privacy problems. (That is an impossible standard to meet and perfection has become a standard preventing us from having any privacy.)
       </p>
       <p>
        Instead, the AG need only set ground rules that allow pro-privacy services to function effectively. A key ground rule that you should promote is a minimally burdensome verification procedure, so that pro-privacy services can scale and can easily deliver opt out requests. For instance, in the telemarketing context, the FTC made enrolling in the Do-Not-Call Registry simple because it understood that complexifying the process would result in lower enrollment.
       </p>
       <p>
        There is almost no verification to enroll in the Do-Not-Call Registry and this is a deliberate policy choice. One can enroll by simply calling from the phone number to be enrolled, or by visiting a website and getting a round-trip email. What this means is that online, a consumer can enroll any phone number, even one that is not theirs, so long as they provide an email address. The FTC does not run email/phone number verification.
       </p>
       <p>
        The low level of verification in the Do-Not-Call Registry is a reflection of two important policy issues: first, excessive verification imposes transaction costs on consumers, and these costs are substantial. Second, the harm of false registrations is so minimal that it is outweighed by the interest in lowering consumer transaction costs. Most people are honest and there is no evidence of systematic false registrations in the Do-Not-Call Registry. More than 200 million numbers are now enrolled.
       </p>
       <p>
        The AG should look to the FTC’s approach and choose a minimally invasive verification procedure for opt out requests that assumes 1) that most Californians are honest people and will not submit opt out requests without authority, and 2) that verification stringency imposes a real, quantifiable cost on consumers. That cost to consumers is likely to outweigh the interest of sellers to prevent false registrations. In fact, excessive verification could kill the market for privacy services and deny consumers the benefit of the right to opt out. A reasonable opt out method would be one where a privacy service delivers a list of identifiable consumers to a business, for instance through an automated system, or simply a spreadsheet of names and email addresses.
       </p>
       <p>
        The AG should look to Catalog Choice as a model for opt outs. Catalog Choice has carefully collected all the opt out mechanisms for paper mail marketing catalogs. A consumer can sign up on the site, identify catalogs to opt out from (9,000 of them!), and Catalog Choice sends either an automated email or a structured list of consumers to sellers to effectuate the opt out. This service is free. Data feeds from Catalog Choice are even recognized by data brokers as a legitimate way for consumers to stop unwanted advertising mail. Catalog choice performs no verification of consumer identity. Again, this is acceptable, because the harm of a false opt-out is negligible, and because deterring that harm would make it impossible for anyone to opt out efficiently.
       </p>
       <p>
        I served on the board of directors of Catalog Choice for years and recall no incidents of fraudulent opt outs. The bigger problem was with sellers who simply would not accept opt outs. A few would summarily deny them for no reason other than that allowing people to opt out harmed their business model, or they would claim that Catalog Choice needed a power of attorney to communicate a user’s opt out. The AG should make a specific finding that a power of attorney or any other burdensome procedure is not necessary for delivering verified opt out requests.
       </p>
       <p>
        The AG should assume that sellers will use guile to impose costs on opt out requests and to deter them. Recall that when consumer reporting agencies were required to create a free credit report website, CRAs used technical measures to block people from linking to it, so that the consumer had to enter the URL to the website manually. CRAs also set up confusing, competing sites to draw consumers away from the free one. The FTC actually had to amend its rule to require this disclosure on all “free” report sites.
       </p>
       <p>
        <strong>
         The definition of sell
        </strong>
       </p>
       <p>
        The definition of sell in the CCPA reflects the initiative’s broad policy goal of stopping guile in data “sharing.”
       </p>
       <p>
        From a consumer perspective, any transfer of personal information to a third party for consideration is a
        <em>
         sale
        </em>
        (subject to exceptions for transactional necessity, etc). But the information industry has interpreted “sale” to only mean transfers for money consideration. That is an unfounded, ahistorical interpretation.
       </p>
       <p>
        The initiative sought to reestablish the intuitive contract law rule that any transfer for value is the “consideration” that makes a data exchange a sale. In the information industry’s case, that valuable consideration is often a barter exchange. For instance, in data cooperatives, sellers input their own customer list into a database in exchange for other retailers’ data.
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftn6" name="_ftnref6">
         <sup>
          [6]
         </sup>
        </a>
        Under the stilted definition of “sale” promoted by the information industry, that is not data selling. But from a consumer perspective, such cooperative ”sharing” has the same effect as a “sale.”
       </p>
       <p>
        Recent reporting about Facebook makes these dynamics clearer in the online platform context.
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftn7" name="_ftnref7">
         <sup>
          [7]
         </sup>
        </a>
        Properly understood, Facebook sold user data to application developers. If application developers enabled “reciprocity” or if developers caused “engagement” on the Facebook platform, Facebook would give developers access to personal data. From a consumer perspective, users gave their data to Facebook, and Facebook transferred user data to third parties, in exchange for activity that gave economic benefit to Facebook. That’s a sale. The AG should view transfers of personal information for value, including barter and other exchange, as “valuable consideration” under the CCPA. Doing so will make the marketplace more honest and transparent.
       </p>
       <p>
        <strong>
         Disclosures that consumers understand
        </strong>
       </p>
       <p>
        <em>
         Over 60% of Americans believes that if a website has a privacy policy, it cannot sell data to third parties.
         <a href="https://hoofnagle.berkeley.edu/feed/#_ftn8" name="_ftnref8">
          <sup>
           <strong>
            [8]
           </strong>
          </sup>
         </a>
        </em>
       </p>
       <p>
        I have come to the conclusion, based on a series of 6 large scale consumer surveys and the extensive survey work of Alan Westin, that the term “privacy policy” is inherently misleading. Consumers do not read privacy policies. They see a link to the privacy policy, and they conclude “this website must have privacy.” My work is consonant with Alan Westin’s, who over decades of surveys, repeatedly found that most consumers think businesses handle personal data in a “confidential way.” Westin’s findings imply that consumers falsely believe that there is a broad norm against data selling.
       </p>
       <p>
        In writing consumer law, one can’t take a lawyer’s perspective. Consumers do not act nor do they think like lawyers. Lawyers think the issue is as simple as reading a disclosure. But to the average person, the mere presence “privacy policy” means something substantive. It looks more like a quality seal (e.g. “organic”) rather than an invitation to read.
       </p>
       <p>
        This is why the initiative and the CCPA go to such extraordinary measures to inform consumers with “Do not sell my personal information” disclosures. Absent such a clear and dramatic disclosure, consumers falsely assume that sellers have confidentiality obligations.
       </p>
       <p>
        The CCPA is trying to thread a needle between not violating commercial speech interests and disabusing consumers of data selling misconceptions. These competing interests explain why the CCPA is opt-out for data selling. CCPA attempts to minimize impingement on commercial free speech (in the form of data selling) while also informing consumers of businesses’ actual practices.
       </p>
       <p>
        Let me state this again: the government interest in commanding the specific representation “Do not sell my personal information,” is necessary to both 1) disabuse consumers of the false belief that services are prohibited from selling their data, and 2) to directly tell consumers that they have to take action and exercise the opt out under CCPA. It would indeed make more sense from a consumer perspective for the CCPA to require affirmative consent. But since that may be constitutionally problematic, the CCPA has taken an opt out approach, along with a strong statement to help consumers understand their need to take action. Without a visceral, dramatic disclosure, consumers will not know that they need to act to protect their privacy.
        <strong>
         Your regulatory findings should recite these value conflicts, and the need for compelled speech in order to correct a widespread consumer misconception.
        </strong>
       </p>
       <p>
        <strong>
         Data brokers and opting out
        </strong>
       </p>
       <p>
        Vermont law now requires data brokers to register, and its registry should help Californians locate opt out opportunities. However, the AG can further assist in this effort by requiring a
        <em>
         standardized textual disclosure
        </em>
        that is easy to find using search engines. Standardized is important because businesses tend to develop arbitrary terminology that has no meaning outside the industry. Text is important because it is easier to search for words than images, and because logo-based “buttons” carry arbitrary or even conflicting semiotic meaning.
       </p>
       <p>
        <strong>
         Non-discrimination norms
        </strong>
       </p>
       <p>
        Section §125 of the CCPA is the most perplexing, yet it is harmonious with the overall intent of the initiative to create markets. My understanding of §125 is that it seeks to 1) prevent platforms such as Facebook from offering a price that is widely divergent from costs. For instance, Facebook’s claims its average revenue per user (ARPU) is about $100/year in North America. The CCPA seeks to prevent Facebook from charging fees that would be greatly in excess of $10/month. Thus, the AG could look to ARPU as a peg for defining unreasonable incentive practices. 2) CCPA was attempting to prevent the spread of surveillance capitalism business models into area where information usually is not at play, for instance, at bricks and mortar businesses.
       </p>
       <p>
        One area to consider under §125 are the growing number of businesses that reject cash payment. These businesses are portrayed as progressive but actually the practice is regressive (consumers spend more when they use plastic, the practice is exclusionary for the unbanked, it subjects consumers to more security breaches, and it imposes a ~3% fee on all transactions).  Consumers probably do not understand that modern payment systems can reidentify them and build marketing lists. The privacy implications of digital payments are not disclosed nor mitigated, and as such, bricks and mortar businesses that demand digital payment may be coercive under CCPA.
       </p>
       <p>
        <strong>
         Pro-privacy incentives
        </strong>
       </p>
       <p>
        Privacy laws present a paradox: schemes like the GDPR can induce companies to use data more rather than less. This is because the GDPR’s extensive data mapping and procedural rules may end up highlighting unrealized information uses. The CCPA can avoid this by creating carrots for privacy-friendly business models, something that the GDPR does not do.
       </p>
       <p>
        The most attractive carrot for companies is an exception that broadly relieves them of CCPA duties. The AG should make the short term transient use exemption the most attractive and usable one. That exception should be interpreted broadly and be readily usable by those acting in good faith. For instance, short-term uses should be interpreted to include retention up to 13 months so long as the data are not repurposed. The broad policy goals of the CCPA are met where an exception gives companies strong pro-privacy incentives. There’s no better one than encouraging companies to only collect data it needs for transactions, and to only keep it for the time needed to ensure anti-fraud, seasonal sales trend analysis, and other service-related reasons. For many businesses, this period is just in excess of one year.
       </p>
       <p>
        Respectfully submitted,
       </p>
       <p>
        /Chris Hoofnagle
       </p>
       <p>
        Chris Jay Hoofnagle*
        <br/>
        Adjunct full professor of information and of law
        <br/>
        UC Berkeley
        <br/>
        *Affiliation provided for identification purposes only
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref1" name="_ftn1">
         [1]
        </a>
        North Dakota Secretary of State, Statewide Election Results, June 11, 2002.
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref2" name="_ftn2">
         [2]
        </a>
        Hoofnagle et al.,
        <em>
         Behavioral Advertising: The Offer You Can’t Refuse
        </em>
        , 6 Harv. L. &amp; Pol’y Rev. 273 (2012).
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref3" name="_ftn3">
         [3]
        </a>
        Jan Whittington &amp; Chris Hoofnagle,
        <em>
         Unpacking Privacy’s Price
        </em>
        , 90 N.C. L. Rev. 1327 (2011).
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref4" name="_ftn4">
         [4]
        </a>
        <em>
         Pineda v. Williams Sonoma
        </em>
        , 51 Cal.4th 524, 2011 WL 446921.
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref5" name="_ftn5">
         [5]
        </a>
        <a href="https://www.clickz.com/what-acxiom-hash-figured-out/31429/">
         https://www.clickz.com/what-acxiom-hash-figured-out/31429/
        </a>
        and
        <a href="https://developer.myacxiom.com/code/api/endpoints/hashed-entity">
         https://developer.myacxiom.com/code/api/endpoints/hashed-entity
        </a>
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref6" name="_ftn6">
         [6]
        </a>
        From Nextmark.com: “co-operative (co-op) database
       </p>
       <p>
        a prospecting database that is sourced from many mailing lists from many different sources. These lists are combined, de-duplicated, and sometimes enhanced to create a database that can then be used to select prospects. Many co-op operators require that you put your customers into the database before you can receive prospects from the database.
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref7" name="_ftn7">
         [7]
        </a>
        Chris Hoofnagle, Facebook and Google Are the New Data Brokers, Cornell Digital Life Initiative (2018)
        <a href="https://www.dli.tech.cornell.edu/blog/facebook-and-google-are-the-new-data-brokers">
         https://www.dli.tech.cornell.edu/blog/facebook-and-google-are-the-new-data-brokers
        </a>
       </p>
       <p>
        <a href="https://hoofnagle.berkeley.edu/feed/#_ftnref8" name="_ftn8">
         [8]
        </a>
        Chris Jay Hoofnagle and Jennifer M. Urban,
        <em>
         Alan Westin’s Privacy Homo Economicus
        </em>
        , 49 Wake Forest Law Review 261 (2014).
       </p>
      </div>
      <p class="date">
       <a href="https://hoofnagle.berkeley.edu/2019/03/08/comments-on-the-ccpa/">
        by chris at March 08, 2019 11:47 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    February 26, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3715">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/02/26/response-to-abdurahman/">
       Response to Abdurahman
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        <a href="https://medium.com/@blacksirenradio">
         Abdurahman
        </a>
        has
        <a href="https://medium.com/@blacksirenradio/fat-be-wilin-deb56bf92539">
         responded
        </a>
        to my
        <a href="https://digifesto.com/2019/02/02/all-the-problems-with-our-paper-racial-categories-in-machine-learning/">
         response
        </a>
        to her tweet about my
        <a href="https://arxiv.org/abs/1811.11668">
         paper
        </a>
        with
        <a href="http://sociology.ucdavis.edu/people/bdhaynes">
         Bruce Haynes
        </a>
        , and invited me to write a
        <a href="https://medium.com/@blacksirenradio/removed-upon-your-request-i-look-forward-to-reading-your-rebuttal-given-the-connection-between-the-63e4971c1d59">
         rebuttal
        </a>
        . While I’m happy to do so–arguing with intellectuals on the internet is probably one of my favorite things to do–it is not easy to rebut somebody with whom you have so little disagreement.
       </p>
       <p>
        Abdurahman makes a number of points:
       </p>
       <ol>
        <li>
         Our paper, “Racial categories in machine learning”, omits the social context in which algorithms are enacted.
        </li>
        <li>
         The paper ignores whether computational thinking “acolytes like [me]” should be in the position of determining civic decisions.
        </li>
        <li>
         That the ontological contributions of African American Vernacular English (AAVE) are not present in the FAT* conference and that constitutes a hermeneutic injustice. (I may well have misstated this point).
        </li>
        <li>
         The positive reception to our paper may be due to its appeal to people with a disingenuous, lazy, or uncommitted racial politics.
        </li>
        <li>
         “Participatory design” does not capture Abdurahman’s challenge of “peer” design. She has a different and more broadly encompassing set of concerns: “whose language is used, whose viewpoint and values are privileged, whose agency is extended, and who has the right to frame the “problem”.”
        </li>
        <li>
         That our paper misses the point about predictive policing, from the perspective of people most affected by disparities in policing. Machine learning classification is not the right frame of the problem. The problem is an unjust prison system and, more broadly the unequal distribution of power that is manifested in the academic discourse itself. “[T]he problem is framed wrongly — it is not just that classification systems are inaccurate or biased, it is who has the power to classify, to determine the repercussions / policies associated thereof and their relation to historical and accumulated injustice?”
        </li>
       </ol>
       <p>
        I have to say that I am not a stranger most of this line of thought and have great sympathy for the radical position expressed.
       </p>
       <p>
        I will continue to defend our paper.
        <strong>
         Re: point 1,
        </strong>
        a major contribution of our paper was that it shed light on the political construction of race, especially race in the United States, which is absolutely part of “the social context in which algorithmic decision making is enacted”. Abdurahman must be referring to some
        <em>
         other
        </em>
        aspect of the social context. One problem we face as academic researchers is that the entire “social context” of algorithmic decision-making is the whole frickin’ world, and conference papers are about 12 pages or so. I thought we did a pretty good job of focusing on one, important and neglected aspect of that social context, the political formation of race, which as far as I know has never previously been addressed in a computer science paper. (I’ve written more about this point
        <a href="https://digifesto.com/2019/02/09/why-sts-is-not-the-solution-to-tech-ethics/">
         here
        </a>
        ).
       </p>
       <p>
        <strong>
         Re: point 2,
        </strong>
        it’s true we omit a discussion of the relevance of computational thinking to civic decision-making. That is because this is a safe assumption to make in a publication to that venue. I happen to agree with that assumption, which is why I worked hard to submit a paper to that conference. If I didn’t think computational thinking was relevant, I probably would be doing something else with my time. That said, I think it’s wildly flattering and inaccurate to say that I, personally, have any control over “civic decision-making”. I really don’t, and I’m not sure why you’d think that, except for the erroneous myth that computer science research is,  in itself, political power. It isn’t; that’s
        <a href="https://data-activism.net/2018/04/critical-reflections-on-fat-2018-a-historical-idealist-perspective/">
         a lie that the tech companies have told the world
        </a>
        .
       </p>
       <p>
        I am quite aware (
        <strong>
         re: point 3
        </strong>
        ) that my embodied and social “location” is quite different from Abdurahman’s. For example, unlike Abdurahman, it would be utterly pretentious for me to posture or “front” with AAVE. I simply have no access to its ontological wisdom, and could not be the conduit of it into any discourse, academic or informal. I have and use different resources; I am also limited by my positionality like anybody else. Sorry.
       </p>
       <p>
        “Woke” white liberals potentially liking our argument?
        <strong>
         (Re: point 4)
        </strong>
        Fair. I don’t think that means our argument is bad or that the points aren’t worth making.
       </p>
       <p>
        <strong>
         Re: point 5:
        </strong>
        I must be forgiven for not understanding the full depth of Abdurahman’s methodological commitments on the basis of a single tweet. There are a lot of different design methodologies and their boundaries are disputed. I see now that the label of “participatory design” is not sufficiently critical or radical enough to capture what she has in mind. I’m pleased to see she is working with
        <a href="https://tech.cornell.edu/people/tapan-parikh/">
         Tap Parikh
        </a>
        on this, who has a lot of experience with critical/radical HCI methods. I’m personally not an expert on any of this stuff. I do different work.
       </p>
       <p>
        <strong>
         Re: point 6:
        </strong>
        My personal opinions about the criminal justice system did not make it into our paper, which again was a focused scientific article trying to make a different point. Our paper was about how racial categories are formed, how they are unfair, and how a computational system designed for fairness might address that problem. I agree that this approach is unlikely to have much meaningful impact on the injustices of the cradle-to-prison system in the United States, the prison-industrial complex, or the like. Based on what I’ve heard so far, the problems there would be best solved by changing the ways
        <em>
         judges
        </em>
        are trained. I don’t have any say in that, though–I don’t have a law degree.
       </p>
       <p>
        In general, while I see Abdurahman’s frustrations as valid (of course!), I think it’s ironic and frustrating that she targets our paper as an emblem of the problems with the FAT* conference, with computer science, and with the world at large. First, our paper was not a “typical” FAT* paper; it was a very unusual one, positioned to
        <em>
         broaden
        </em>
        the scope of what’s discussed there, motivated in part by my own
        <a href="https://data-activism.net/2018/04/critical-reflections-on-fat-2018-a-historical-idealist-perspective/">
         criticism
        </a>
        s of the conference the year before.  It was also just one paper: there’s tons of other good work at that conference, and the conversation is quite broad. I expect the best solution to the problem is to write and submit different papers. But it may also be that other venues are better for addressing the problems raised.
       </p>
       <p>
        I’ll conclude that many of the difficulties and misunderstandings that underlie our conversation are a result of a
        <em>
         <a href="https://commons.pacificu.edu/interface/vol1/iss1/3/">
          disciplinary collapse
         </a>
        </em>
        that is happening because of academia’s relationship with social media. Language’s meaning depends on its social context, and social media is notoriously a place where contexts collapse. It is totally unreasonable to argue that everybody in the world should be focused on what you think is most important. In general, I think battles over “framing” on the Internet are stupid, and that the fact that these kinds of battles have become so politically prominent is a big part of why our society’s politics are so stupid. The current political emphasis on the symbolic sphere is a distraction from more consequential problems of economic and social structure.
       </p>
       <p>
        As I’ve noted elsewhere, one reason why I think Haynes’s view of race is refreshing  (as opposed to a lot of what passes for “critical race theory” in popular discussion) is that it locates the source of racial inequality in structure–spatial and social segregation–and institutional power–especially, the power of law. In my view, this politically substantive view of race is, if taken seriously, more radical than one based on mere “discourse” or “fairness” and demands a more thorough response. Codifying that response, in computational thinking, was the goal of our paper.
       </p>
       <p>
        This is a more concrete and specific way of dealing with the power disparities that are at the heart of Abdurahman’s critique. Vague discourse and intimations about “privilege”, “agency”, and “power”, without an account of the specific mechanisms of that power, are weak.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/02/26/response-to-abdurahman/">
        by Sebastian Benthall at February 26, 2019 04:14 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    February 23, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3707">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/02/23/beginning-to-read-smart-technologies-and-the-ends-of-law-notes-on-hildebrandt-smart-technologies-sections-7-1-7-2/">
       Beginning to read “Smart Technologies and the End(s) of Law” (Notes on: Hildebrandt, Smart Technologies, Sections 7.1-7.2)
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I’m starting to read
        <a href="https://twitter.com/mireillemoret">
         Mireille Hildebrandt
        </a>
        ‘s
        <em>
         Smart Technologies and the End(s) of Law
        </em>
        (2015) at the recommendation of several friends with shared interests in privacy and the tensions between artificial intelligence and the law. As has been my habit with other substantive books, I intend to blog my notes from reading as I get to it, in sections, in a perhaps too stream-of-consciousness, opinionated, and personally inflected way.
       </p>
       <p>
        For reasons I will get to later, Hildebrandt’s book is a must-read for me. I’ve decided to start by jumping in on Chapter 7, because (a) I’m familiar enough with technology ethics, AI, and privacy scholarship to think I can skip that and come back as needed, and (b) I’m mainly reading because I’m interested in what a scholar of Hildebrandt’s stature says when she tackles the tricky problem of law’s response to AI head on.
       </p>
       <p>
        I expect to disagree with Hildebrant in the end. We occupy different social positions and, as I’ve argued before, people’s position on various issues of technology policy
        <a href="https://digifesto.com/2018/10/23/for-a-more-ethical-silicon-valley-we-need-a-wiser-economics-of-data/">
         appears to have a great deal to do with ones social position or habitus
        </a>
        . However, I know I have a good deal to learn about legal theory while having enough background in philosophy and social theory to parse through what Hildebrandt has to offer. And based on what I’ve read so far, I expect the contours of the possible positions that she draws out to be totally groundbreaking.
       </p>
       <h4>
        Notes on: Hildebrandt,
        <em>
         Smart Technologies
        </em>
        , §7.1-7.2
       </h4>
       <blockquote class="wp-block-quote">
        <p>
         “The third part of this book inquires into the implications of smart technologies and data-driven agency for the law.”
        </p>
        <cite>
         – Hildebrandt,
         <em>
          Smart Technologies,
         </em>
         p.133
        </cite>
       </blockquote>
       <p>
        Lots of people write about how artificial intelligence presents an existential threat. Normally, they are talking about how a superintelligence is posing an
        <a href="https://digifesto.com/2017/03/27/more-assessment-of-ai-x-risk-potential/">
         existential threat to humanity
        </a>
        . Hildebrandt is arguing something else: she is arguing that smart technologies may pose an existential threat to
        <em>
         the law
        </em>
        , or the Rule of Law. That is because the law’s “mode of existence” depends on written text, which is a different technical modality, with different affordances, than smart technology.
       </p>
       <blockquote class="wp-block-quote">
        <p>
         My take is that the mode of existence of modern law is deeply dependent upon the printing press and the way it has shaped our world. Especially the binary character of legal rules, the complexity of the legal system and the finality of legal decisions are affordances of — amongst things — the ICI [information and communication infrastructure] of the printing press.
        </p>
        <cite>
         – Hildebrandt,
         <em>
          Smart Technologies,
         </em>
         p.133
        </cite>
       </blockquote>
       <p>
        This is just so on point, it’s hard to know what to say. I mean, this is obviously on to something. But what?
       </p>
       <p>
        To make her argument, Hildebrandt provides a crash course in philosophy of law and legal theory, distinguishing a number of perspectives that braid together into an argument. She discusses several different positions:
       </p>
       <ul>
        <li>
         <em>
          7.2.1 Law as an essentially contested concept
         </em>
         (Gallie). The concept of “law” [1] denotes something valuable, [2] covers intricate complexities, that makes it [3] inherently ambiguous and [4] necessarily vague. This [5] leads interested parties into contest over conceptions. The contest is [6] anchored in past, agreed upon exemplars of the concept, and [7] the contest itself sustains and develops the concept going forward. This is the seven-point framework of an “essentially contested concept”.
        </li>
        <li>
         <em>
          7.2.2 Formal legal positivism
         </em>
         . Law as a set of legal rules dictated by a sovereign (as opposed to law as a natural moral order) (Austin). Law as a
         <em>
          coherent
         </em>
         set of rules, defined by its unity (Kelsen). A distinction between substantive rules and rules about rule-making (Hart).
        </li>
        <li>
         <em>
          7.2.3 Hermeneutic conceptions.
         </em>
         The practice of law is about the creative interpretation of (e.g.) texts (case law, statutes, etc.) to application of new cases. The
         <em>
          integrity
         </em>
         of law (Dworkin) constrains this interpretation, but the projection of legal meaning into the future is part of the activity of legal practice. Judges “do things with words”–make performative utterances through their actions. Law is not just a system of rules, but a system of meaningful activity.
        </li>
        <li>
         <em>
          7.2.3 Pragmatist conceptions (Realism legal positivism)
         </em>
         . As opposed to the formal legal positivism discusses earlier that sees law as rules, realist legal positivism sees law as a sociological phenomenon. Law is “prophecies of what the courts will do in fact, and nothing more pretentious” (Holmes). Pragmatism, as an epistemology, argues that the meaning of something is its practical effect; this approach could be seen as a constrained version of the hermeneutic concept of law.
        </li>
       </ul>
       <p>
        To summarize Hildebrandt’s gloss on this material so far: Gallie’s “essentially contested concept” theory is doing the work of setting the stage for Hildebrant’s self-aware intervention into the legal debate. Hildebrandt is going to propose a specific concept of the law, and of the Rule of Law. She is doing this well-aware that this act of scholarship is
        <em>
         engaging in contest
        </em>
        .
       </p>
       <h4>
        Punchline
       </h4>
       <p>
        I detect in Hildebrandt’s writing a sympathy or preference for hermeneutic approaches to law. Indeed, by opening with Gallie, she sets up
        <em>
         the contest about the concept of law
        </em>
        as something
        <em>
         internal
        </em>
        to the hermeneutic processes of the law. These processes, and this contest, are about texts; the proliferation of texts is due to the role of the printing press in modern law. There is a coherent “integrity” to this concept of law.
       </p>
       <p>
        The most interesting discussion, in my view, is loaded in to what reads like an afterthought: the
        <em>
         pragmatist conception of law
        </em>
        . Indeed, even at the level of
        <em>
         formatting
        </em>
        , pragmatism is buried: hermeneutic and pragmatist conceptions of law are combined into one section (7.2.3), where as Gallie and the formal positivists each get their own section (7.2.1 and 7.2.2).
       </p>
       <p>
        This is odd, because the resonances between pragmatism and ‘smart technology’ are, in Hildebrandt’s admission, quite deep:
       </p>
       <blockquote class="wp-block-quote">
        <p>
         Basically, Holmes argued that law is, in fact, what we expect it to be, because it is this expectation that regulates our actions. Such expectations are grounded in past decisions, but if these were entirely deterministic of future decisions we would not need the law — we could settle for logic and simply calculate the outcome of future decisions. No need for interpretation. Holmes claimed, however, that ‘the life of law has not been logic. It has been experience.’ This correlates with a specific conception of intelligence. As we have seen in Chapter 2 and 3, rule-based artificial intelligence, which tried to solve problems by means of deductive logic, has been superseded by machine learning (ML), based on experience.
        </p>
        <cite>
         – Hildebrandt,
         <em>
          Smart Technologies,
         </em>
         p.142
        </cite>
       </blockquote>
       <p>
        Hildebrandt considers this connection between pragmatist legal interpretation and machine learning only to reject it summarily in a single paragraph at the end of the section.
       </p>
       <blockquote class="wp-block-quote">
        <p>
         If we translate [a maxim of classical pragmatist epistemology] into statistical forecasts we arrive at judgments resulting from ML. However, neither logic nor statistics can attribute meaning. ML-based court decisions would remove the fundamental ambiguity of human language from the centre stage of the law. As noted above, this ambiguity is connected with the value-laden aspect of the concept of law. It is not a drawback of natural language, but what saves us from acting like mindless agents. My take is that an approach based on statistics would reduce judicial and legislative decisions to administration, and thus collapse the Rule of Law. This is not to say that a number of administrative decisions could not be taken by smart computing systems. It is to confirm that such decisions should be brought under the Rule of Law, notably by making them contestable in a court of law.
        </p>
        <cite>
         – Hildebrandt,
         <em>
          Smart Technologies,
         </em>
         p.143
         <br/>
        </cite>
       </blockquote>
       <p>
        This is a clear articulation of Hildebrandt’s agenda (“My take is that…”). It is also clearly an aligning the practice of law with contest, ambiguity, and interpretation as opposed to “mindless” activity. Natural language’s ambiguity is a feature, not a bug. Narrow pragmatism, which is aligned with machine learning, is a threat to the Rule of Law
       </p>
       <h4>
        Some reflections
       </h4>
       <p>
        Before diving into the argument, I have to write a bit about my urgent interest in the book. Though I only heard about it recently, my interests have tracked the subject matter for some time.
       </p>
       <p>
        For some time I have been interested in the connection between philosophical pragmatism and the concerns about AI, which I believe can be traced back to
        <a href="https://digifesto.com/2014/12/22/horkheimer-pragmatism-and-cognitive-ecology/">
         Horkheimer
        </a>
        . But I thought nobody was giving the positive case for pragmatism its due. At the end of 2015, totally unaware of “Smart Technologies” (my professors didn’t seem aware of it either…), I decided that I would write my doctoral dissertation thesis defending the bold thesis that
        <em>
         <strong>
          yes
         </strong>
        </em>
        <strong>
         , we should have AI replace the government
        </strong>
        .
        <em>
         <a href="https://digifesto.com/2016/01/08/a-constitution-written-in-source-code/">
          A constitution written in source code
         </a>
        </em>
        . I was going to back the argument up with, among other things,
        <a href="https://digifesto.com/2016/06/02/algorithmic-law-and-pragmatist-legal-theory-oliver-wendell-holmes-jr-the-path-of-the-law/">
         pragmatist
        </a>
        <a href="https://digifesto.com/2016/06/04/the-ftc-and-pragmatism-hoofnagle-and-holmes/">
         legal
        </a>
        theory.
       </p>
       <p>
        I had to drop the argument because I could not find faculty willing to be on the committee for such a dissertation! I have been convinced ever since that  this is a line of argument that is actually rather suppressed. I was able to
        <a href="https://cosmosandhistory.org/index.php/journal/article/view/570">
         articulate the perspective
        </a>
        in a philosophy journal in 2016, but had to abandon the topic.
       </p>
       <p>
        This was probably good in the long run, since it meant I wrote a
        <a href="https://escholarship.org/uc/item/5sg7q32q">
         dissertation on privacy
        </a>
        which addressed many of the themes I was interested in, but in greater depth. In particular, working with Helen Nissenbaum I learned about Hildebrandt’s articles comparing contextual integrity with purpose binding in the GDPR (Hildebrandt, 2013; Hildebrandt, 2014), which at the time my mentors at Berkeley seemed unaware of. I am still working on puzzles having to do with algorithmic implementation or response to the law, and likely will for some time.
       </p>
       <p>
        Recently, been working at a Law School and have reengaged the interdisciplinary research community at venues like FAT*. This has led me, seemingly unavoidably, back to what I believe to be the crux of disciplinary tension today: the rising epistemic dominance of
        <em>
         pragmatist computational statistics–
        </em>
        <a href="https://digifesto.com/2015/05/14/data-science-is-not-positivist-its-power/">
         “data science”
        </a>
        <em>
         —
        </em>
        and its threat to humanistic legal authority, which is manifested in the clash of institutions that are based on each, e.g., iconically, “Silicon Valley” (or Seattle) and the European Union. Because of the
        <em>
         explicitly normative
        </em>
        aspects of humanistic legal authority, it asserts itself
        <a href="https://digifesto.com/2019/02/09/why-sts-is-not-the-solution-to-tech-ethics/">
         again
        </a>
        and
        <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
         again
        </a>
        as an “ethical” alternative to pragmatist technocratic power. This is the latest manifestation of a
        <a href="https://data-activism.net/2018/04/critical-reflections-on-fat-2018-a-historical-idealist-perspective/">
         very old debate
        </a>
        .
       </p>
       <p>
        Hildebrandt is the first respectable scholar (a category from which I exclude myself) that I’ve encountered to articulate this point. I have to see where she takes the argument.
       </p>
       <p>
        So far, however, I think here argument begs the question. Implicitly, the “essentially contested” character of law is due to the ambiguity of natural language and the way in which that necessitates contest over the meaning of words. And so we have a professional class of lawyers and scholars that debate the meaning of words. I believe the the regulatory power of this class is what Hildebrandt refers to as “the Rule of Law”.
       </p>
       <p>
        While it’s true that an alternative regulatory mechanism based on statistical prediction would be quite different from this sense of “Rule of Law”, it is not clear from Hildebrandt’s argument, yet, why her version of “Rule of Law” is better. The only hint of an argument is the problem of “mindless agents”.  Is she worried about the deskilling of the legal profession, or the reduced need for elite contest over meaning? What is hermeneutics offering society,
        <em>
         outside
        </em>
        of the bounds of its own discourse?
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Benthall, S. (2016). Philosophy of computational social science.
        <em>
         Cosmos and History: The Journal of Natural and Social Philosophy
        </em>
        ,
        <em>
         12
        </em>
        (2), 13-30.
       </p>
       <p>
        Sebastian Benthall.
        <em>
         Context, Causality, and Information Flow: Implications for Privacy Engineering, Security, and Data Economics
        </em>
        . Ph.D. dissertation. Advisors: John Chuang and Deirdre Mulligan. University of California, Berkeley. 2018.
       </p>
       <p>
        Hildebrandt, Mireille. “Slaves to big data. Or are we?.” (2013).
       </p>
       <p>
        Hildebrandt, Mireille. “Location Data, Purpose Binding and Contextual Integrity: What’s the Message?.”
        <em>
         Protection of Information and the Right to Privacy-A New Equilibrium?
        </em>
        . Springer, Cham, 2014. 31-62.
       </p>
       <p>
        Hildebrandt, Mireille.
        <em>
         Smart technologies and the end (s) of law: novel entanglements of law and technology
        </em>
        . Edward Elgar Publishing, 2015.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/02/23/beginning-to-read-smart-technologies-and-the-ends-of-law-notes-on-hildebrandt-smart-technologies-sections-7-1-7-2/">
        by Sebastian Benthall at February 23, 2019 04:39 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    February 17, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3701">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/02/16/a-few-brief-notes-towards-procuring-cybersecurity/">
       A few brief notes towards “Procuring Cybersecurity”
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I’m shifting research focus a bit and wanted to jot down a few notes. The context for the shift is that I have the pleasure of organizing a roundtable discussion for NYU’s Center for Cybersecurity and Information Law Institute, working closely with
        <a href="https://its.law.nyu.edu/facultyprofiles/index.cfm?fuseaction=profile.overview&amp;personid=40498">
         Thomas Streinz
        </a>
        of NYU’s Guarini
        <a href="https://www.guariniglobal.org/">
         Global Law and Tech.
        </a>
       </p>
       <p>
        The context for the workshop is the steady feed of news about global technology supply chains and how they are not just
        <em>
         relevant
        </em>
        to “cybersecurity”, but in some respects are
        <em>
         constitutive
        </em>
        of cyberinfrastructure and hence the field of its security.
       </p>
       <p>
        I’m using “global technology supply chains” rather loosely here, but this includes:
       </p>
       <ul>
        <li>
         Transborder personal data flows as used in e-commerce
        </li>
        <li>
         Software- (and Infrastructure-)-as-a-Service being marketing internationally (including Google used abroad, for example)
        </li>
        <li>
         Enterprise software import/export
        </li>
        <li>
         Electronics manufacturing and distribution.
        </li>
       </ul>
       <p>
        Many concerns about cybersecurity as a
        <em>
         global
        </em>
        phenomenon circulate around the imagined or actual supply chain. These are sometimes national security concerns that result in real policy, as when
        <a href="https://www.itnews.com.au/news/huawei-zte-banned-from-australian-5g-networks-500708">
         Australia recently banned Hauwei and ZTE from supplying 5G network equipment
        </a>
        for fear that it would provide a vector of interference from the Chinese government.
       </p>
       <p>
        But the nationalist framing is certainly not the whole story. I’ve heard anecdotally that after the Snowden revelations, Microsoft’s internally began to see the U.S. government as a cybersecurity “
        <a href="https://en.wikipedia.org/wiki/Adversary_(cryptography)">
         adversary
        </a>
        “. Corporate tech vendors naturally don’t want to be known as being vectors for national surveillance, as this cuts down on their global market share.
       </p>
       <p>
        Governments and corporations have different cybersecurity incentives and threat models. These models intersect and themselves create the dynamic cybersecurity field. For example, these Chinese government has viewed foreign software vendors as cybersecurity threats, and has responded by mandating source code disclosure. But as this is a vector of potential IP theft, foreign vendors have balked, seeing
        <em>
         this mandate
        </em>
        as a threat. (Ahmed and Weber, 2018).Complicating things further, a defensive “cybersecurity” measure can also serve the goal of protecting domestic technology innovation–which can be framed as providing a nationalist “cybersecurity” edge in the long run.
       </p>
       <p>
        What, if anything, prevents a total cyberwar of all against all? One answer is trade agreements that level the playing field, or at least establish rules for the game. Another is open technology and standards, which provide an alternative field driven by the benefits of interoperability rather than proprietary interest and secrecy. Is it possible to capture any of this in accurate model or theory?
       </p>
       <p>
        I love having the opportunity to explore these questions, as they are at the intersection of my empirical work on software supply chains (Benthall et al., 2016; Benthall, 2017) and also theoretical work on data economics in my
        <a href="https://escholarship.org/uc/item/5sg7q32q">
         dissertation
        </a>
        . My hunch for some time has been that there’s a dearth of solid economics theory for the contemporary digital economy, and this is one way of getting at that.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Ahmed, S., &amp; Weber, S. (2018). China’s long game in techno-nationalism.
        <em>
         First Monday, 23
        </em>
        (5).
       </p>
       <p>
        Benthall, S., Pinney, T., Herz, J. C., Plummer, K., Benthall, S., &amp; Rostrup, S. (2016). An ecological approach to software supply chain risk management. In
        <em>
         15th Python in Science Conference
        </em>
        .
       </p>
       <p>
        Benthall, S. (2017, September). Assessing software supply chain risk using public data. In
        <em>
         2017 IEEE 28th Annual Software Technology Conference (STC)
        </em>
        (pp. 1-5). IEEE.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/02/16/a-few-brief-notes-towards-procuring-cybersecurity/">
        by Sebastian Benthall at February 17, 2019 01:27 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    February 09, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3698">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/02/09/why-sts-is-not-the-solution-to-tech-ethics/">
       Why STS is not the solution to “tech ethics”
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        “Tech ethics” are in (
        <a href="https://www.nytimes.com/2018/10/21/opinion/who-will-teach-silicon-valley-to-be-ethical.html">
         1
        </a>
        ) (
        <a href="https://www.scu.edu/ethics/internet-ethics-blog/false-dilemmas/">
         2
        </a>
        ) (
        <a href="https://ainowinstitute.org/AI_Now_2018_Report.pdf">
         3
        </a>
        ) and a popular refrain at
        <a href="https://fatconference.org/2019/program.html">
         FAT*
        </a>
        this year was that
        <em>
         sensitivity to social and political context
        </em>
        is the solution to the problems of unethical technology. How do we bring this sensitivity to technical design? Using the techniques of Science and Technology Studies (STS), argue variously
        <a href="https://docs.google.com/presentation/d/1qlu0sv8NVyMG0iKUdK6is2r3l6-a_gbXq_lVya0SArg/edit#slide=id.p">
         Dobbe and Ames
        </a>
        , as well as Selbst et al. (2019). Value Sensitive Design (VSD) (Friedman and Bainbridge, 2004) is one typical STS technique proposed technique for bringing this political awareness into the
        <em>
         design
        </em>
        process. In general, there is broad agreement that computer scientists should be working with social scientists when developing socially impactful technologies.
       </p>
       <p>
        In this blog post, I argue that
        <strong>
         STS is not the solution to “tech ethics” that it tries to be.
        </strong>
       </p>
       <p>
        Encouraging computer scientists to collaborate with social science domain experts is a great idea. My paper with Bruce Haynes (
        <a href="https://arxiv.org/abs/1811.11668">
         1
        </a>
        ) (
        <a href="https://digifesto.com/2018/11/29/for-fairness-in-machine-learning-we-need-to-consider-the-unfairness-of-racial-categorization/">
         2
        </a>
        ) (
        <a href="https://digifesto.com/2019/02/02/all-the-problems-with-our-paper-racial-categories-in-machine-learning/">
         3
        </a>
        ) is an example of this kind of work. In it, we drew from sociology of race to inform a technical design that addressed the unfairness of racial categories. Significantly, in my view, we did not use STS in our work. Because the social injustices we were addressing were due to broad reaching social structures and politically constructed categories, we used
        <em>
         sociology
        </em>
        to elucidate what was at stake and what sorts of interventions would be a good idea.
       </p>
       <p>
        It is important to recognize that there are many different social sciences dealing with “social and political context”, and that STS, despite its interdisciplinarity, is only one of them. This is easily missed in an interdisciplinary venue in which STS is active, because STS is somewhat activist in asserting its own importance in these venues. In a sense, STS frequently positions itself as a reminder to blindered technologists that there is a social world out there. “Let me tell you about what you’re missing!” That’s it’s shtick. Because of this positioning, STS scholars frequently get a seat at the table with scientists and technologists. It’s a powerful position, in sense.
       </p>
       <p>
        What STS scholar tend to ignore is how and when other forms of social scientists involve themselves in the process of technical design. For example, at FAT* this year there were
        <a href="https://fatconference.org/2019/program.html">
         two full tracks
        </a>
        of Economic Models. Economic Models. Economics is a well-established social scientific discipline that has tools for understanding how a particular mechanism can have unintended effects when put into a social context. In economics, this is called “mechanism design”. It addresses what Selbst et al. might call the “Ripple Effect Trap”–the fact that a system in context may have effects that are different from the intention of designers. I’ve argued before that
        <a href="https://digifesto.com/2018/10/23/for-a-more-ethical-silicon-valley-we-need-a-wiser-economics-of-data/">
         wiser economics
        </a>
        are something we need to better address technology ethics, especially if we are talking about technology deployed by industry, which is most of it! But despite deep and systematic social scientific analysis of secondary and equilibrium effects at the conference, these peer-reviewed works are not acknowledged by STS interventionists. Why is that?
       </p>
       <p>
        As usual, quantitative social scientists are
        <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
         completely ignored
        </a>
        by STS-inspired critiques of technologists and their ethics. That is too bad, because at the scale at which these technologies are operating (mainly, we are discussing civic- or web-scale automated decision making systems that are inherently about large numbers of people), fuzzier debates about “values” and contextualized impact would surely benefit from quantitative operationalization.
       </p>
       <p>
        The problem is that STS is, at its heart, a humanistic discipline, a subfield of anthropology. If and when STS does not deny the utility or truth or value of mathematization or quantification entirely, as a field of research it is
        <em>
         methodologically
        </em>
        skeptical about such things. In the self-conception of STS, this methodological relativism is part of its ethnographic rigor. This ethnographic relativism is more or less entirely incompatible with formal reasoning, which aspires to universal internal validity. At a moralistic level, it is this aspiration of universal internal validity that is so bedeviling to the STS scholar: the mathematics are
        <em>
         inherently
        </em>
        distinct from an awareness of the social context, because social context can only be understood in its ethnographic particularity.
       </p>
       <p>
        <strong>
         This is a false dichotomy.
        </strong>
        There are other social sciences  that address social and political context that do not have the same restrictive assumptions of STS. Some of these are quantitative, but not all of them are. There are qualitative sociologists and political scientists with great insights into social context that are not disciplinarily allergic to the standard practices of engineering. In many ways, these kinds of social sciences are far more compatible with the process of designing technology than STS! For example, the sociology we draw on in our “Racial categories in machine learning” paper is variously: Gramscian racial hegemony theory, structuralist sociology, Bourdieusian theories of social capital, and so on. Significantly, these theories are not based exclusively on ethnographic method. They are based on disciplines that happily mix historical and qualitative scholarship with quantitative research. The object of study is the social world, and part of the purpose of the research is to develop politically useful abstractions from it
        <em>
         that generalize and can be measured
        </em>
        . This is the form of social sciences that is compatible with
        <em>
         quantitative policy evaluation,
        </em>
        the sort of thing you would want to use if, for example, understanding the impact of an affirmative action policy.
       </p>
       <p>
        Given the widely acknowledge truism that
        <em>
         public sector technology design often encodes and enacts real policy changes
        </em>
        (a point made in Deirdre Mulligan’s keynote), it would make sense to understand the effects of these technologies using the methodologies of
        <em>
         policy impact evaluation
        </em>
        . That would involve enlisting the kinds of social scientific expertise relevant to understand society at large!
       </p>
       <p>
        But that is absolutely
        <em>
         not
        </em>
        what STS has to offer. STS is, at best, offering a humanistic evaluation of the social processes of technology design. The ontology of STS is flat, and its epistemology and ethics are immediate: the design decision comes down to a calculus of “values” of different “stakeholders”. Ironically, this is a picture of social context that often seems to neglect the political and economic context of that context. It is not an escape from empty abstraction. Rather, it insists on moving from clear abstractions to more nebulous ones, “values” like “fairness”, maintaining that if the conversation never ends and the design never gets formalized,
        <em>
         ethics
        </em>
        has been accomplished.
       </p>
       <p>
        This has proven, again and again, to be a rhetorically effective position for research scholarship. It is quite popular among “ethics” researchers that are backed by corporate technology companies. That is quite possibly because the form of “ethics” that STS offers, for all of its calls for political sensitivity, is devoid of political substance. An apples-to-apples comparison of “values”, without considering the
        <a href="https://digifesto.com/2018/02/06/values-norms-and-beliefs-units-of-analysis-in-research-on-culture/">
         social origins of those values
        </a>
        and the way those values are grounded in political interests that are not merely about “what we think is important in life”, but real contests over resource allocation. The observation by Ames et al. (2011) that people’s values with respect to technology varies with socio-economic class is terribly relevant, Bourdieusian lesson in how the standpoint of “values sensitivity” may, when taken seriously, run up against the hard realities of political agonism. I don’t believe STS researchers are truly naive about these points; however, in their rhetoric of design intervention, conducted in labs but isolated from the real conditions of technology firms, there is an idealism that can only survive under the self-imposed severity of STS’s own methodological restrictions.
       </p>
       <p>
        Independent scholars can take up this position and publish daring pieces, winning the moral high ground. But that is not a serious position to take in an industrial setting, or when pursuing generalizable knowledge about the downstream impact of a design on a complex social system. Those empirical questions require different tools, albeit far more unwieldy ones. Complex survey instruments, skilled data analysis, and substantive social theory are needed to arrive at solid conclusions about the ethical impact of technology.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Ames, M. G., Go, J., Kaye, J. J., &amp; Spasojevic, M. (2011, March). Understanding technology choices and values through social class. In
        <em>
         Proceedings of the ACM 2011 conference on Computer supported cooperative work
        </em>
        (pp. 55-64). ACM.
       </p>
       <p>
        Friedman, B., &amp; Bainbridge, W. S. (2004). Value sensitive design.
       </p>
       <p>
        Selbst, A. D., Friedler, S., Venkatasubramanian, S., &amp; Vertesi, J. (2018, August). Fairness and Abstraction in Sociotechnical Systems. In
        <em>
         ACM Conference on Fairness, Accountability, and Transparency (FAT*)
        </em>
        .
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/02/09/why-sts-is-not-the-solution-to-tech-ethics/">
        by Sebastian Benthall at February 09, 2019 10:14 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    February 03, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="http://artfordorks.com" title="Art For Dorks by Laura Devendorf">
       Laura Devendorf
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://artfordorks.com/?p=1716">
     <h4 class="posttitle" lang="en-US">
      <a href="http://artfordorks.com/2019/02/a-machine-for-being-frustrated/">
       A Machine for Being Frustrated
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <h2>
        A Machine for Being Frustrated
       </h2>
       <p>
        <a href="http://artfordorks.com/wordpress/wp-content/uploads/2019/01/39441558_10102470415085495_4428821356234145792_o-1.jpg">
         <img alt="39441558_10102470415085495_4428821356234145792_o (1)" class="alignnone size-large wp-image-1718" height="450" src="http://artfordorks.com/wordpress/wp-content/uploads/2019/01/39441558_10102470415085495_4428821356234145792_o-1-600x450.jpg" width="600"/>
        </a>
       </p>
       <p>
        An exploration into new mechanisms for DIY jacquard weaving, as well as an ongoing interest in asking how non-human materials or forces can be engaged as collaborators resulted in the prototype of the wind loom—-a modified tapestry loom that with every 4th warp connected to a sail that moves the warp position in and out. The fabrication of the loom was led by Jen Mah and Rachel Bork, who iterated between several prototypes for laser-cut heddle/hooks that can be attached to the yarn, arms are connected to umbrellas that can move when the wind blows, easily attachable and detachable components to support easy travel, and so on. Nearly everything about this design process has been frustrating, from the difficulty of waiting for windy days to test to the stress and anticipation that such a wind loom produces. As I considered a redesign, I began to think about this experience of frustrating and my almost reflexive response to design it away. It has made me wonder if collaborating with the wind ought to be frustrating and if we just stuck through frustration a bit more, then maybe we wouldn’t have some of the negative effects we see emergent from innovation. Rather than seeing this as a “wind loom” I began to think of it as a kind of tool for becoming frustrated and learning how to deal with that emotion. In consolation, you will learn a great deal about the wind patterns in your local region.
       </p>
       <p>
        More Information:
        <br/>
        <a href="http://unstable.design/designing-machines-for-human-wind-collaboration/">
         http://unstable.design/designing-machines-for-human-wind-collaboration/
         <br/>
        </a>
        <a href="https://www.instructables.com/id/Wind-Loom/">
         https://www.instructables.com/id/Wind-Loom/
        </a>
       </p>
      </div>
      <p class="date">
       <a href="http://artfordorks.com/2019/02/a-machine-for-being-frustrated/">
        by admin at February 03, 2019 02:34 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    February 02, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3694">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/02/02/all-the-problems-with-our-paper-racial-categories-in-machine-learning/">
       All the problems with our paper, “Racial categories in machine learning”
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        <a href="http://sociology.ucdavis.edu/people/bdhaynes">
         Bruce Haynes
        </a>
        and I were blown away by the reception to our paper, “
        <a href="https://arxiv.org/abs/1811.11668">
         Racial categories in machine learning
        </a>
        “. This was a huge experiment in interdisciplinary collaboration for us. We are excited about the next steps in this line of research.
       </p>
       <p>
        That includes engaging with criticism. One of our goals was to fuel a conversation in the research community about the operationalization of race. That isn’t a question that can be addressed by any one paper or team of researchers. So one thing we got out of the conference was great critical feedback on potential problems with the approach we proposed.
       </p>
       <p>
        This post is an attempt to capture those critiques.
       </p>
       <h4>
        <strong>
         Need for participatory design
        </strong>
       </h4>
       <figure class="wp-block-embed-twitter wp-block-embed is-type-rich">
        <div class="wp-block-embed__wrapper">
         <div class="embed-twitter">
          <blockquote class="twitter-tweet">
           <p dir="ltr" lang="en">
            I think people who design/discuss algorithms need peer relationships w/ the communities they research. Come to the hood and “explain” addressing root inequality by “preceding group fairness interventions with unsupervised learning” I want to see that contestability live-streamed
           </p>
           — Khadijah (@UpFromTheCracks)
           <a href="https://twitter.com/UpFromTheCracks/status/1090997609035112448?ref_src=twsrc%5Etfw">
            January 31, 2019
           </a>
          </blockquote>
         </div>
        </div>
        Khadijah Abdurahman, of
        <a href="https://wordtori.com/">
         Word to RI
        </a>
        , issues a subtweeted challenge to us to present our paper to the hood. (RI stands for Roosevelt Island, in New York City, the location of the recently established Cornell Tech campus.)
       </figure>
       <p>
        One striking challenge, raised by Khadijah Abdurahman on Twitter, is that we should be developing peer relationships with the communities we research. I read this as a call for
        <a href="https://en.wikipedia.org/wiki/Participatory_design">
         participatory design
        </a>
        . It’s true this was not part of the process of the paper. In particular, Ms. Abdurahman points to a part of our abstract that uses jargon from computer science.
       </p>
       <p>
        There are a lot of ways to respond to this comment. The first is to accept the challenge. I would personally love it if Bruce and I could present our research to folks on Roosevelt Island and get feedback from them.
       </p>
       <p>
        There are other ways to respond that address the tensions of this comment. One is to point out that in addition to being an accomplished scholar of the sociology of race and how it forms, especially in urban settings, Bruce is a black man who is originally from Harlem. Indeed, Bruce’s
        <a href="https://www.amazon.com/Down-Up-Staircase-Generations-Harlem/dp/0231181027">
         family memoir
        </a>
        shows his deep and well-researched familiarity with the life of marginalized people of the hood.  So a “peer relationship” between an algorithm designer (me) and a member of an affected community (Bruce) is really part of the origin of our work.
       </p>
       <p>
        Another is to point out that we did not research
        <em>
         a particular community
        </em>
        . Our paper was not human subjects research; it was about the racial categories that are maintained by the Federal U.S. government and which pervade society in a very general way. Indeed,
        <em>
         everybody
        </em>
        is affected by these categories. When I and others who looks like me are ascribed “white”, that is an example of these categories at work. Bruce and I were very aware of how different kinds of people
        <em>
         at the conference
        </em>
        responded to our work, and how it was an intervention in
        <em>
         our own community
        </em>
        , which is of course affected by these racial categories.
       </p>
       <p>
        The last point is that computer science jargon is alienating to basically everybody who is not trained in computer science, whether they live in the hood or not. And the fact is we presented our work at a computer science venue. Personally, I’m in favor of
        <a href="https://cosmosandhistory.org/index.php/journal/article/view/570">
         universal education in computational statistics
        </a>
        , but that is a tall order. If our work becomes successful, I could see it becoming part of, for example, a statistical demography curriculum that could be of popular interest. But this is early days.
       </p>
       <h4>
        The Quasi-Racial (QR) Categories are Not Interpretable
       </h4>
       <p>
        In our presentation, we introduced some terminology that did not make it into the paper. We named the vectors of segregation derived by our procedure “quasi-racial” (QR) vectors, to denote that we were trying to capture dimensions that were race-
        <em>
         like
        </em>
        , in that they captured the patterns of historic and ongoing racial injustice, without being the racial categories themselves, which we argued are inherently unfair categories of inequality.
       </p>
       <p>
        First, we are not wedded to the name “quasi-racial” and are very open to different terminology if anybody has an idea for something better to call them.
       </p>
       <p>
        More importantly, somebody pointed out that these QR vectors may not be
        <em>
         interpretable.
        </em>
        Given that the conference is not only about Fairness, but also Accountability and Transparency, this critique is certainly on point.
       </p>
       <p>
        To be honest, I have not yet done the work of surveying the extensive literature on algorithm interpretability to get a nuanced response. I can give two informal responses. The first is that one assumption of our proposal is that there is something wrong with how race and racial categories are intuitive understood. Normal people’s understanding of race is, of course, ridden with stereotypes, implicit biases, false causal models, and so on. If we proposed an algorithm that was fully “interpretable” according to most people’s understanding of what race is, that algorithm would likely have racist or racially unequal outcomes. That’s precisely the problem that we are trying to get at with our work. In other words, when categories are inherently unfair, interpretability and fairness may be at odds.
       </p>
       <p>
        The second response is that educating people about how the procedure works and why its motivated is part of what makes its outcomes interpretable. Teaching people about the history of racial categories, and how those categories are both the cause and effect of segregation in space and society, makes the algorithm interpretable. Teaching people about Principal Component Analysis, the algorithm we employ, is part of what makes the system interpretable. We are trying to drop knowledge; I don’t think we are offering any shortcuts.
       </p>
       <h4>
        Principal Component Analysis (PCA) may not be the right technique
       </h4>
       <p>
        An objection from the computer science end of the spectrum was that our proposed use of Principal Component Analysis (PCA) was not well-motivated enough. PCA is just one of many dimensionality reduction techniques–why did we choose it in particular? PCA has many assumptions about the input embedded within it, including the component vectors of interest are linear combinations of the inputs. What if the best QR representation is a non-linear combination of the input variables? And our use of unsupervised learning, as a general criticism, is perhaps lazy, since in order to validate its usefulness we will need to test it with labeled data anyway. We might be better off with a more carefully calibrated and better motivated alternative technique.
       </p>
       <p>
        These are all fair criticisms. I am personally not satisfied with the technical component of the paper and presentation. I know the rigor of the analysis is  not of the standard that would impress a machine learning scholar and can take full responsibility for that. I hope to do better in a future iteration of the work, and welcome any advice on how to do that from colleagues. I’d also be interested to see how more technically skilled computer scientists and formal modelers address the problem of unfair racial categories that we raised in the paper.
       </p>
       <p>
        I see our main contribution as the
        <em>
         raising of this problem of unfair categories
        </em>
        , not our particular technical solution to it. As a potential solution, I hope that it’s better than nothing, a step in the right direction, and provocative. I subscribe to the belief that science is an iterative process and look forward to the next cycle of work.
       </p>
       <p>
        Please feel free to reach out if you have a critique of our work that we’ve missed. We do appreciate all the feedback!
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/02/02/all-the-problems-with-our-paper-racial-categories-in-machine-learning/">
        by Sebastian Benthall at February 02, 2019 07:20 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    January 16, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3681">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/01/15/notes-on-oneil-chapter-2-bomb-parts/">
       Notes on O’Neil, Chapter 2, “Bomb Parts”
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        <a href="https://digifesto.com/2019/01/12/reading-oneils-weapons-of-math-destruction/">
         Continuing
        </a>
        with O’Neil’s
        <em>
         Weapons of Math Destruction
        </em>
        on to Chapter 2, “Bomb Parts”. This is a popular book and these are quick chapters. But that’s no reason to underestimate them! This is some of the most lucid work I’ve read on algorithmic fairness.
       </p>
       <p>
        This chapter talks about three kinds of “models” used in prediction and decision making, with three examples. O’Neil speak highly of the kinds of models used in baseball to predict the trajectory of hits and determine the optimal placement of people in the field. (Ok, I’m not so good at baseball terms). These are good, O’Neil says, because they are transparent, they are consistently adjusted with new data, and the goals are well defined.
       </p>
       <p>
        O’Neil then very charmingly writes about the model she uses mentally to determine how to feed her family. She juggles a lot of variables: the preferences of her kids, the nutrition and cost of ingredients, and time. This is all hugely relatable–everybody does something like this. Her point, it seems, is that this form of “model” encodes a lot of opinions or “ideology” because it reflects her values.
       </p>
       <p>
        O’Neil then discusses recidivism prediction, specifically the LSI-R (Level of Service Inventory–Revised) tool. It asks questions like “How many previous convictions have you had?” and uses that to predict likelihood of future prediction. The problem is that (a) this is sensitive to overpolicing in neighborhoods, which has little to do with actual recidivism rates (as opposed to rearrest rates), and (b) e.g. black neighborhoods are more likely to be overpoliced, meaning that the tool, which is not very good at predicting recidivism, has disparate impact. This is an example of what O’Neil calls an (eponymous)
        <em>
         weapon of math destruction
        </em>
        .(WMD)
       </p>
       <p>
        She argues that the three qualities of a WMD are Scale, Opacity, and Damage. Which makes sense.
       </p>
       <p>
        As I’ve said, I think this is a better take on algorithmic ethics than almost anything I’ve read on the subject before. Why?
       </p>
       <p>
        First, it doesn’t use the word “algorithm” at all. That is huge, because 95% of the time the use of the word “algorithmic” in the technology-and-society literature is stupid. People use “algorithm” when they really mean “software”. Now, they use “AI System” to mean “a company”. It’s ridiculous.
       </p>
       <p>
        O’Neil makes it clear in this chapter that what she’s talking about are different kinds of
        <em>
         models
        </em>
        . Models can be in ones head (as in her plan for feeding her family) or in a computer, and both kinds of models can be racist. That’s a helpful, sane view. It’s been the consensus of computer scientists, cognitive scientists, and AI types for decades.
       </p>
       <p>
        The problem with WMDs, as opposed to other, better models, is that the WMDS models are unhinged from reality. O’Neil’s complaint is not with
        <em>
         use of models
        </em>
        , but rather that models are being used without being properly trained using sound sampling on data and statistics. WMDs are not artificially intelligences; they are artificial stupidities.
       </p>
       <p>
        In more technical terms, it seems like the problem with WMDs is not that they don’t properly trade off predictive accuracy with fairness, as some computer science literature would suggest is necessary. It’s that the systems have
        <em>
         high error rates
        </em>
        in the first place because the training and calibration systems are poorly designed. What’s worse, this
        <em>
         avoidable
        </em>
        error is disparately distributed, causing more harm to some groups than others.
       </p>
       <p>
        This is a wonderful and eye-opening account of unfairness in the models used by automated decision-making systems (note the language). Why? Because it shows that there is a connection between
        <em>
         statistical
        </em>
        bias, the kind of bias that creates distortions in a quantitative predictive process, and
        <em>
         social
        </em>
        bias, the kind of bias people worry about politically, which consistently uses the term in
        <em>
         both
        </em>
        ways. If there is statistical bias that is weighing against some social group, then that’s
        <em>
         definitely, 100%
        </em>
        a form of
        <em>
         bias
        </em>
        .
       </p>
       <p>
        Importantly, this kind of bias–statistical bias–is not something that
        <em>
         every
        </em>
        model must have. Only badly made models have it. It’s something that can be mitigated using scientific rigor and sound design. If we see the problem the way O’Neil sees it, then we can see clearly how
        <em>
         better
        </em>
        science, applied
        <em>
         more rigorously
        </em>
        , is also good for social justice.
       </p>
       <p>
        As a scientist and technologist, it’s been terribly discouraging in the past years to be so consistently confronted with a false dichotomy between sound engineering and justice. At last, here’s a book that clearly outlines how the opposite is the case!
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/01/15/notes-on-oneil-chapter-2-bomb-parts/">
        by Sebastian Benthall at January 16, 2019 04:44 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    January 15, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://stuartgeiger.com/" title="R. Stuart Geiger">
       Stuart Geiger
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="https://stuartgeiger.com/posts/2019/01/digital-infrastructure-grant">
     <h4 class="posttitle">
      <a href="https://stuartgeiger.com/posts/2019/01/digital-infrastructure-grant">
       Researchers receive grant to study the invisible work of maintaining open-source software
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        Researchers at the UC Berkeley Institute for Data Science (BIDS), the University of California, San Diego, and the University of Connecticut have been awarded a grant of $138,055 from the Sloan Foundation and the Ford Foundation
        <a href="https://www.fordfoundation.org/ideas/equals-change-blog/posts/announcing-13m-in-funding-for-digital-infrastructure-research/">
         as part of a broad initiative
        </a>
        to investigate the sustainability of digital infrastructures. The grant funds research into the maintenance of open-source software (OSS) projects, particularly focusing on the visible and invisible work that project maintainers do to support their projects and communities, as well as issues of burnout and maintainer sustainability. The research project will be led by BIDS staff ethnographer and principal investigator Stuart Geiger and will be conducted in collaboration with Lilly Irani and Dorothy Howard at UC San Diego, Alexandra Paxton at the University of Connecticut, and Nelle Varoquaux and Chris Holdgraf at UC Berkeley.
       </p>
       <p>
        Many open-source software projects have become foundational components for many stakeholders and are now widely used behind-the-scenes to support activities across academia, the tech industry, government, journalism, and activism. OSS projects are often initially created by volunteers and provide immense benefits for society, but their maintainers can struggle with how to sustain and support their projects, particularly when widely used in increasingly critical contexts. Most OSS projects are maintained by only a handful of individuals, and community members often talk about how their projects might collapse if only one or two key individuals leave the project. Project leaders and maintainers must do far more than just write code to ensure a project’s long-term success: They resolve conflicts, perform community outreach, write documentation, review others’ code, mentor newcomers, coordinate with other projects, and more. However, many OSS project leaders and maintainers have publicly discussed the effects of burnout as they find themselves doing unexpected and sometimes thankless work.
       </p>
       <p>
        The one-year research project — The Visible and Invisible Work of Maintaining Open-Source Digital Infrastructure — will study these issues in various software projects, including software libraries, collaboration platforms, and discussion platforms that have come to be used as critical digital infrastructure. The researchers will conduct interviews with project maintainers and contributors from a wide variety of projects, as well as analyze projects’ code repositories and communication platforms. The goal of the research is to better understand what project maintainers do, the challenges they face, and how their work can be better supported and sustained. This research on the invisible work of maintenance will help maintainers, contributors, users, and funders better understand the complexities within such projects, helping set expectations, develop training programs, and formulate evaluations.
       </p>
      </div>
      <p class="date">
       <a href="https://stuartgeiger.com/posts/2019/01/digital-infrastructure-grant">
        by R. Stuart Geiger at January 15, 2019 08:00 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    January 12, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3678">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/01/12/reading-oneils-weapons-of-math-destruction/">
       Reading O’Neil’s Weapons of Math Destruction
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I probably should have already read Cathy O’Neil’s
        <em>
         Weapons of Math Destruction
        </em>
        . It was a blockbuster of the tech/algorithmic ethics discussion. It’s written by an accomplished mathematician, which I admire. I’ve also now seen O’Neil perform bluegrass music twice in New York City and think her band is great. At last I’ve found a copy and have started to dig in.
       </p>
       <p>
        On the other hand, as is probably clear from other blog posts, I have a hard time swallowing a lot of the gloomy political work that puts the role of algorithms in society in such a negative light. I encounter is
        <em>
         very
        </em>
        frequently, and every time feel that some misunderstanding must have happened; something seems
        <em>
         off
        </em>
        .
       </p>
       <p>
        It’s very clear that O’Neil can’t be accused of mathophobia or not understanding the complexity of the algorithms at play, which is an easy way to throw doubt on the arguments of some technology critics. Yet perhaps because it’s a popular book and not an academic work of Science and Technology Studies, I haven’t it’s arguments parsed through and analyzed in much depth.
       </p>
       <p>
        This is a start. These are my notes on the introduction.
       </p>
       <p>
        O’Neil describes the turning point in her career where she soured on math. After being an academic mathematician for some time, O’Neil went to work as a quantitative analyst for D.E. Shaw. She saw it as an opportunity to work in a global laboratory. But then the 2008 financial crisis made her see things differently.
       </p>
       <blockquote class="wp-block-quote">
        <p>
         The crash made it all too clear that mathematics, once my refuge, was not only deeply entangled in the world’s problems but also fueling many of them. The housing crisis, the collapse of major financial institutions, the rise of unemployment–all had been aided and abetted by mathematicians wielding magic formulas. What’s more, thanks to the extraordinary powers that I loved so much, math was able to combine with technology to multiply the chaos and misfortune, adding efficiency and scale to systems I now recognized as flawed.
        </p>
        <cite>
         O’Neil,
         <em>
          Weapons of Math Destruction
         </em>
         , p.2
        </cite>
       </blockquote>
       <p>
        As an independent reference on the causes of the 2008 financial crisis, which of course has been a hotly debated and disputed topic, I point to Sassen’s 2017 “Predatory Formations” article. Indeed, the systems that developed the sub-prime mortgage market were complex, opaque, and hard to regulate. Something went seriously wrong there.
       </p>
       <p>
        But was it
        <em>
         mathematics
        </em>
        that was the problem? This is where I get hung up. I don’t understand the mindset that would attribute a crisis in the financial system to the use of abstract, logical, rigorous thinking. Consider the fact that there would not have been a financial crisis if there had not been a functional financial services system in the first place. Getting a mortgage and paying them off, and the systems that allow this to happen, all require mathematics to function. When these systems operate normally, they are taken for granted. When they suffer a
        <em>
         crisis,
        </em>
        when the system fails, the mathematics takes the blame. But a system can’t suffer a crisis if it didn’t start working rather well in the first place–otherwise, nobody would depend on it. Meanwhile, the regulatory reaction to the 2008 financial crisis required, of course, more mathematicians working to prevent the same thing from happening again.
       </p>
       <p>
        So in this case (and I believe others) the question can’t be,
        <em>
         whether
        </em>
        mathematics, but rather
        <em>
         which
        </em>
        mathematics. It is so sad to me that these two questions get conflated.
       </p>
       <p>
        O’Neil goes on to describe a case where an algorithm results in a teacher losing her job for not adding enough value to her students one year. An analysis makes a good case that the cause of her students’ scores not going up is that in the previous year, the students’ scores were inflated by teachers cheating the system. This argument was not consider conclusive enough to change the administrative decision.
       </p>
       <blockquote class="wp-block-quote">
        <p>
         Do you see the paradox? An algorithm processes a slew of statistics and comes up with a probability that a certain person
         <em>
          might
         </em>
         be a bad hire, a risky borrower, a terrorist, or a miserable teacher. That probability is distilled into a score, which can turn someone’s life upside down. And yet when the person fights back, “suggestive” countervailing evidence simply won’t cut it. The case must be ironclad. The human victims of WMDs, we’ll see time and again, are held to a far higher standard of evidence than the algorithms themselves.
        </p>
        <cite>
         O’Neil,
         <em>
          WMD
         </em>
         , p.10
         <br/>
        </cite>
       </blockquote>
       <p>
        Now
        <em>
         this
        </em>
        is a
        <em>
         fascinating
        </em>
        point, and one that I don’t think has been taken up enough in the critical algorithms literature. It resonates with a point
        <a href="https://digifesto.com/2019/01/09/3675/">
         that came up earlier
        </a>
        , that traditional collective human decision making is often driven by agreement on narratives, whereas automated decisions can be a qualitatively different kind of collective action
        <em>
         because
        </em>
        they can make judgments based on probabilistic judgments.
       </p>
       <p>
        I have to wonder what O’Neil would argue the solution to this problem is. From her rhetoric, it seems like her recommendation must be prevent automated decisions from making probabilistic judgments. In other words, one could raise the evidenciary standard for algorithms so that they we equal to the standards that people use with each other.
       </p>
       <p>
        That’s an interesting proposal. I’m not sure what the effects of it would be. I expect that the result would be lower expected values of whatever target was being optimized for, since the system would not be able to “take bets” below a certain level of confidence.  One wonders if this would be a more or less arbitrary system.
       </p>
       <p>
        Sadly, in order to evaluate this proposal seriously, one would have to employ mathematics. Which is, in O’Neil’s rhetoric, a form of evil magic. So, perhaps it’s best not to try.
       </p>
       <p>
        O’Neil attributes the problems of WMD’s to the incentives of the data scientists building the systems. Maybe they know that their work effects people, especially the poor, in negative ways. But they don’t care.
       </p>
       <blockquote class="wp-block-quote">
        <p>
         But as a rule, the people running the WMD’s don’t dwell on these errors. Their feedback is money, which is also their incentive. Their systems are engineered to gobble up more data fine-tune their analytics so that more money will pour in. Investors, of course, feast on these returns and shower WMD companies with more money.
        </p>
        <cite>
         O’Neil,
         <em>
          WMD
         </em>
         , p.13
        </cite>
       </blockquote>
       <p>
        Calling out greed as the problem is effective and true in a lot of cases. I’ve
        <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
         argued
        </a>
        myself that the real root of the technology ethics problem is capitalism: the way investors drive what products get made and deployed. This is a worthwhile point to make and one that doesn’t get made enough.
       </p>
       <p>
        But the logical implications of this argument are off. Suppose it is true that “as a rule”, the makers of algorithms that do harm are made by people responding to the incentives of private capital. (IF harmful algorithm, THEN private capital created it.) That does not mean that there can’t be good algorithms as well, such as those created in the public sector. In other words, there are algorithms that are not WMDs.
       </p>
       <p>
        So the insight here has to be that private capital investment corrupts the process of designing algorithms, making them harmful. One could easily make the case that private capital investment corrupts and makes harmful many things that are
        <em>
         not
        </em>
        algorithmic as well. For example, the historic trans-Atlantic slave trade was a terribly evil manifestation of capitalism. It did not, as far as I know, depend on modern day computer science.
       </p>
       <p>
        Capitalism here looks to be the root of all evil. The fact that companies are using
        <em>
         mathematics
        </em>
        is merely incidental. And O’Neil should know that!
       </p>
       <p>
        Here’s what I find so frustrating about this line of argument. Mathematical literacy is critical for understanding what’s going on with these systems and how to improve society. O’Neil certainly has this literacy. But there are many people who don’t have it. There is a power disparity there which is uncomfortable for everybody. But while O’Neil is admirably raising awareness about how these kinds of technical systems can and do go wrong, the single-minded focus and framing risks giving people the wrong idea that these intellectual tools are
        <em>
         always
        </em>
        bad or dangerous. That is not a solution to anything, in my view. Ignorance is never
        <em>
         more ethical
        </em>
        than education. But there is an enormous appetite among ignorant people for being told that it is so.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        O’Neil, Cathy.
        <em>
         Weapons of math destruction: How big data increases inequality and threatens democracy
        </em>
        . Broadway Books, 2017.
       </p>
       <p>
        Sassen, Saskia. “Predatory Formations Dressed in Wall Street Suits and Algorithmic Math.”
        <em>
         Science, Technology and Society
        </em>
        22.1 (2017): 6-20.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/01/12/reading-oneils-weapons-of-math-destruction/">
        by Sebastian Benthall at January 12, 2019 08:00 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    January 11, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="http://bcc.npdoty.name/" title="Bcc">
       Nick Doty
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="tag:bcc.npdoty.name,2019-01-11:post:5754537977577472">
     <h4 class="posttitle">
      <a href="http://bcc.npdoty.name/no-photos-please-and-other-broadcasts">
       "no photos please" and other broadcasts
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        We've spent a lot of collective time and effort on design and policy to support the privacy of the user of a piece of software, whether it's the Web or a mobile app or a device. But more current and more challenging is the privacy of the non-user of the app, the privacy of the bystander. With the ubiquity of sensors, we are increasingly observed, not just by giant corporations or government agencies, but by, as they say, little brothers.
       </p>
       <p>
        Consider the smartphone camera. Taking digital photos is free, quick and easy; resolution and quality increase; metadata (like precise geolocation) is attached; sharing those photos is easy via online services. As facial recognition has improved, it has become easier to automatically identify the people depicted in a photo, whether they're the subject of a portrait or just in the background. If you don't want to share records of your precise geolocation and what you're doing in public places, with friends, family, strangers and law enforcement, it's no longer enough to be careful with the technology you choose to use, you'd also have to be constantly vigilant about the technology that everyone around you is using.
       </p>
       <p>
        While it may be tempting to draw a "throw your hands up" conclusion from this -- privacy is dead, get over it, there's nothing we can easily do about it -- we actually have widespread experience with this kind of value and various norms to protect it. At conferences and public events, it's not uncommon to have a system of stickers on nametags to either opt-in or opt-out of photos. This is a help (not a hindrance) for event photographers: rather than asking everyone to pose in your photo, or asking everyone after the fact if they're alright with your posting a public photo, or being afraid of posting a photo and facing the anger of your attendees, you can just keep an eye on the red and green dots on those plastic nametags and feel confident that you're respecting the attendees at your event.
       </p>
       <p>
        There are similar norms in other settings. Taking video in the movie theater violates legal protections, but there are also widespread and reasonably well-enforced norms against capturing video of live theater productions or comedians who test out new material in clubs, on grounds that may not be copyright. Art museums will often tell you whether photos are welcome or prohibited. In some settings the privacy of the people present is so essential that unwritten or written rules prohibit cameras altogether: at nude hot springs, for example, you just can't use a camera at all. You wouldn't take a photo in the waiting room of your doctor's office and you'll invite anger and social confrontation if you're taking photos of other people's children at your local playground.
       </p>
       <p>
        And even in "public" or in contexts with friends, there are spoken or unspoken expectations. "Don't post that photo of me drinking, please." "Let me see how I look in that before you post it on Facebook." "Everyone knows that John doesn't like to have his photo taken."
       </p>
       <p>
        As cameras become small and more widely used, and encompass depictions of more people, and are shared more widely and easily, and identifications of depicted people can also be shared, our social norms and spoken discussions don't easily keep up. Checking with people before you post a photo of them is absolutely a good practice and I encourage you to follow it. But why not also use technology to facilitate this checking others' preferences?
       </p>
       <p>
        We have all the tools we need to make "no photos please" nametag stickers into unobtrusive and efficiently communicated messages. If you're attending a conference or party and don't want people to take your photo, just tap the "no photos please" setting on your smartphone before you walk in. And if you're taking photos at an event, your camera will show a warning when it knows that someone in the room doesn't want their photo taken, so that you can doublecheck with the people in your photo and make sure you're not inadvertently capturing someone in the background. And the venue can remind you that way too, in case you don't know the local norm that pictures shouldn't be taken in the church or museum.
       </p>
       <p>
        <img alt="Mockup of turning on No Photos Please mode. Camera icon by Mourad Mokrane from the Noun Project." src="https://npdoty.name/images/nophotosplease-settings-mockup.png" style="width: 50%;" title="Camera icon by Mourad Mokrane from the Noun Project"/>
       </p>
       <p>
        As a technical matter, I think we're looking at Bluetooth broadcast beacons, from smartphones or stationary devices. That could be a small Arduino-based widget on the wall of a commercial venue, or one day you might have a poker-chip-sized device in your pocket that you can click into private mode. When you're using a compatible camera app on your phone or a compatible handheld camera, your device regularly scans for nearby Bluetooth beacons and if it sees a "no photos please" message, it shows a (dismissable) warning.
       </p>
       <p>
        <img alt="Mockup of camera showing no photos warning." src="https://npdoty.name/images/nophotos-camera-mockup.png" style="width: 50%;"/>
       </p>
       <p>
        The discretionary communication of preferences is ideal in part because it
        <em>
         isn't
        </em>
        self-enforcing. For example, if the police show up at the political protest you're attending and broadcast a "no photos please" beacon, you can (and should) override your camera warning to take photos of their official activity, as a safeguard for public safety and accountability. An automatically-enforcing DRM-style system would be both infeasible to construct and, if it were constructed, inappropriately inviting to government censorship or aggressive copyright maximalism. Technological hints are also less likely to confusingly over-promise a protection: we can explain to people that the "no photos please" beacon doesn't prevent impolite or malicious people from surreptitiously taking your photo, just as people are extremely familiar with the fact that placards, polite requests and even laws are sometimes ignored.
       </p>
       <p>
        Making preferences technically available could also help with legal compliance. If you're taking a photo at an event and get a "no photos" warning, your device UI can help you log why you might be taking the photo anyway. Tap "I got consent" and your camera can embed metadata in the file that you gathered consent from the depicted people. Tap "Important public purpose" at the protest and you'll have a machine-readable affirmation in place of what you're doing, and your Internet-connected phone can also use that signal to make sure photos in this area are promptly backed up securely in case your device is confiscated.
       </p>
       <p>
        People's preferences are of course more complicated than just "no photos please" or "sure, take my photo". While I, like many, have imagined that sticky policies could facilitate rules of how data is subsequently shared and used, there are good reasons to start with the simple capture-time question. For one, it's familiar, from these existing social and legal norms. For another, it can be a prompt for real-time in-person conversation. Rather than assuming an error-free technical-only system of preference satisfaction, this can be a quick reminder to check with the people right there in front of you for those nuances, and to do so prior to making a digital record.
       </p>
       <p>
        Broadcast messages provide opportunities that I think we haven't fully explored or embraced in the age of the Internet and the (rightfully lauded) end-to-end principle. Some communications just naturally take the form of letting people in a geographic area know something relevant to the place. "The cafe is closing soon." "What's the history of that statue?" "What's the next stop on this train and when are we scheduled to arrive?" If WiFi routers included latitude and longitude in the WiFi network advertisement, your laptop could quickly and precisely geolocate even in areas where you don't have Internet access, and do so passively, without broadcasting your location to a geolocation provider. (That one is a little subtle; we wrote a paper on it back when we were evaluating the various privacy implications of WiFi geolocation databases at Berkeley.) What about, "Anyone up for a game of chess?" (See also, Grindr.) eBook readers could optionally broadcast the title of the current book to re-create the lovely serendipity of seeing the book cover a stranger is reading on the train. Music players could do the same.
       </p>
       <p>
        The Internet is amazing for letting us communicate with people around the world around shared interests. We should see the opportunity for networking technology to also facilitate communications, including conversations about privacy, with those nearby.
       </p>
       <hr/>
       <p>
        Some end notes that my head wants to let go of: There is some prior art here that I don't want to dismiss or pass over, I just think we should push it further. A couple examples:
       </p>
       <ul>
        <li>
         Google folks have developed broadcast URLs that they call
         <a href="https://google.github.io/physical-web/">
          The Physical Web
         </a>
         so that real-life places can share a Web page about them (over mDNS or Bluetooth Low Energy) and I hope one day we can get a link to the presenter's current slide using networking rather than everyone taking a picture of a projected URL and awkwardly typing it into our laptops later.
        </li>
        <li>
         The Occupy movement showed an interest in geographically-located Web services, including forums and chatrooms that operate over WiFi but not connected to the Internet.
         <a href="http://occupyhere.org/">
          Occupy Here
         </a>
         :
         <blockquote>
          Anyone within range of an Occupy.here wifi router, with a web-capable smartphone or laptop, can join the network “OCCUPY.HERE,” load the locally-hosted website http://occupy.here, and use the message board to connect with other users nearby.
         </blockquote>
        </li>
       </ul>
       <p>
        Getting a little further afield but still related, it would be helpful if the network provider could communicate directly with the subscriber using the expressive capability of the Web. Lacking this capability, we've seen frustrating abuses of interception: captive portals redirect and impersonate Web traffic; ISPs insert bandwidth warnings as JavaScript insecurely transplanted into HTTP pages. Why not instead provide a way for the network to push a message to the client, not by pretending to be a server you happen to connect to around that same time, but just as a clearly separate message? ICMP control messages are an existing but underused technology.
       </p>
      </div>
      <p class="date">
       <a href="http://bcc.npdoty.name/no-photos-please-and-other-broadcasts">
        by nick@npdoty.name at January 11, 2019 06:33 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    January 09, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3675">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2019/01/09/3675/">
       computational institutions as non-narrative collective action
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Nils Gilman recently pointed to a book chapter that confirms the need for “official futures” in capitalist institutions.
       </p>
       <figure class="wp-block-embed-twitter wp-block-embed is-type-rich">
        <div class="wp-block-embed__wrapper">
         <div class="embed-twitter">
          <blockquote class="twitter-tweet">
           <p dir="ltr" lang="en">
            Great book on the necessity of official futures: “Collectively held images of how the future will unfold are critical because they free economic actors from paralyzing doubt, enabling them to commit resources and coordinate decisions even if those expectations prove inaccurate.”
            <a href="https://t.co/4oCHWgSSNp">
             https://t.co/4oCHWgSSNp
            </a>
           </p>
           — Nils Gilman (@nils_gilman)
           <a href="https://twitter.com/nils_gilman/status/1082651219628158976?ref_src=twsrc%5Etfw">
            January 8, 2019
           </a>
          </blockquote>
         </div>
        </div>
       </figure>
       <p>
        Nils indulged me in a brief exchange that helped me better grasp at a bothersome puzzle.
       </p>
       <p>
        There is a certain class of intellectuals that insist on the primacy of narratives as a mode of human experience. These tend to be, not too surprisingly, writers and other forms of storytellers.
       </p>
       <p>
        There is a different class of intellectuals that insists on the primacy of statistics. Statistics does not make it easy to tell stories because it is largely about the complexity of hypotheses and our lack of confidence in them.
       </p>
       <p>
        The narrative/statistic divide could be seen as a divide between academic disciplines. It has often been taken to be, I believe wrongly,
        <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
         the crux of the “technology ethics” debate
        </a>
        .
       </p>
       <p>
        I questioned Nils as to whether his generalization stood up to statistically driven allocation of resources; i.e., those decisions made explicitly on probabilistic judgments. He argued that in the end, management and collective action require consensus around narrative.
       </p>
       <figure class="wp-block-embed-twitter wp-block-embed is-type-rich">
        <div class="wp-block-embed__wrapper">
         <div class="embed-twitter">
          <blockquote class="twitter-tweet">
           <p dir="ltr" lang="en">
            In the (literal) final analysis, the various quantitative possibilities get distilled into narratives — that’s how they get used to drive decisions and collective action.
           </p>
           — Nils Gilman (@nils_gilman)
           <a href="https://twitter.com/nils_gilman/status/1082663235730366464?ref_src=twsrc%5Etfw">
            January 8, 2019
           </a>
          </blockquote>
         </div>
        </div>
       </figure>
       <p>
        In other words, what keeps narratives at the center of human activity is that (a) humans are in the loop, and (b) humans are
        <em>
         collectively
        </em>
        in the loop.
       </p>
       <p>
        The idea that communication is necessary for collective action is one I used to put great stock in when studying Habermas. For Habermas, consensus, and especially linguistic consensus, is how humanity moves
        <em>
         together
        </em>
        . Habermas
        <a href="https://digifesto.com/2015/11/23/late-modern-social-epistemology-round-up-technical-vs-hermeneutical-correctness/">
         contrasted
        </a>
        this mode of knowledge aimed at consensus and collective action with technical knowledge, which is aimed at efficiency. Habermas envisioned a society ruled by communicative rationality, deliberative democracy; following this line of reasoning, this communicative rationality would need to be a narrative rationality. Even if this rationality is not universal, it might, in Habermas’s later conception of governance, be shared by a responsible elite. Lawyers and a judiciary, for example.
       </p>
       <p>
        The puzzle that recurs again and again in my work has been the challenge of communicating how technology has become
        <em>
         an alternative form of collective action.
        </em>
        The claim
        <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
         made by some
        </a>
        that technologists are a social “other” makes more sense if one sees them (us) as organizing around non-narrative principles of collective behavior.
       </p>
       <p>
        It is I believe beyond serious dispute that well-constructed, statistically based collective decision-making processes perform better than many alternatives. In the field of future predictions, Phillip Tetlock’s work on
        <a href="https://hbr.org/2016/05/superforecasting-how-to-upgrade-your-companys-judgment">
         superforecasting teams
        </a>
        and prior work on expert political judgment has long stood as an
        <em>
         empirical
        </em>
        challenge to the supposed primacy of narrative-based forecasting. This challenge has not been taken up; it seems rather one-sided. One reason for this may be because the rationale for the effectiveness of these techniques rests ultimately in the science of statistics.
       </p>
       <p>
        It is now common to insist that Artificial Intelligence should be seen as a sociotechnical system and not as a technological artifact. I wholeheartedly agree with this position. However, it is sometimes implied that to understand AI as a social+ system, one must understand it one narrative terms. This is an error; it would imply that the collective actions made to build an AI system and the technology itself are held together by narrative communication.
       </p>
       <p>
        But if the whole purpose of building an AI system is to collectively act in a way that is more effective because of its facility with the nuances of probability, then the narrative lens will miss the point. The promise and threat of AI is that is delivers a different, often more effective form of collective or institution. I’ve suggested that
        <a href="https://digifesto.com/2018/12/22/computational-institutions/">
         computational institution
        </a>
        might be the best way to refer to such a thing.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2019/01/09/3675/">
        by Sebastian Benthall at January 09, 2019 03:54 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    January 08, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="http://jlzych.com/" title="Jeff Zych">
       Jeff Zych
      </a>
     </div>
     <div class="channel-affiliation">
      MIMS 2012
     </div>
    </div>
    <div class="entrygroup" id="http://jlzych.com/2019/01/08/my-yardstick-for-empathy/">
     <h4 class="posttitle">
      <a href="http://jlzych.com/2019/01/08/my-yardstick-for-empathy/">
       My Yardstick for Empathy
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        <img alt="A different perspective by Jamie Street on Unsplash" src="http://jlzych.com/images/2019-01-08-my-yardstick-for-empathy/cover.jpg?1546980459"/>
        <em>
         A different perspective. Photo by
         <a href="https://unsplash.com/photos/OAKFk5_pVWY?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">
          Jamie Street
         </a>
         on
         <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">
          Unsplash
         </a>
        </em>
       </p>
       <p>
        How do you know if you’re being empathetic? It’s easy to throw the term around, but difficult to actually apply. This is important to understand in my chosen field of design, but can also help anyone improve their interactions with other people.
       </p>
       <p>
        My yardstick for being empathetic is
        <strong>
         imagining myself make the same decisions, in the same situation
        </strong>
        , that another person made.
       </p>
       <p>
        If I look at someone’s behavior and think, “That doesn’t make sense,” or “Why did they do that?!” then I’m not being empathetic. I’m missing a piece of context — about their knowledge, experiences, skills, emotional state, environment, etc. — that led them to do what they did. When I feel that way, I push myself to keep searching for the missing piece that will make their actions become the
        <em>
         only
        </em>
        rational ones to take.
       </p>
       <p>
        Is this always possible? No. Even armed with the same knowledge, operating in the same environment, and possessing the same skills as another person, I will occasionally make different decisions than them. Every individual is unique, and interpret and act on stimuli differently.
       </p>
       <p>
        Even so, imagining myself behave the same as another person is what I strive for. That’s my yardstick for empathy.
       </p>
       <hr/>
       <p>
        <em>
         If you want to learn more about empathy and how to apply it to your work and personal life, I highly recommend
        </em>
        <a href="https://rosenfeldmedia.com/books/practical-empathy/">
         Practical Empathy
        </a>
        <em>
         by
         <a href="https://indiyoung.com/">
          Indi Young
         </a>
         .
        </em>
       </p>
      </div>
      <p class="date">
       <a href="http://jlzych.com/2019/01/08/my-yardstick-for-empathy/">
        by Jeff Zych at January 08, 2019 08:22 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    January 04, 2019
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="http://jlzych.com/" title="Jeff Zych">
       Jeff Zych
      </a>
     </div>
     <div class="channel-affiliation">
      MIMS 2012
     </div>
    </div>
    <div class="entrygroup" id="http://jlzych.com/2019/01/03/books-read-2018/">
     <h4 class="posttitle">
      <a href="http://jlzych.com/2019/01/03/books-read-2018/">
       Books Read 2018
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        In 2018 I read 23 books, which is a solid 9 more than
        <a href="http://jlzych.com/2017/12/31/books-read-in-2017/">
         last year’s paltry 14
        </a>
        , and 1 more than
        <a href="http://jlzych.com/2017/01/03/books-i-read-in-2016/">
         2016
        </a>
        ). I credit the improvement to the 4-month sabbatical I took in the spring. Not working really frees up time 😄
       </p>
       <p>
        For the last 2 years I said I needed to read more fiction since I only read 3 in 2016 and 2 in 2017. So how did I do? I’m proud to say I managed to read 7 fiction books this year (if you can count
        <em>
         My Dad Wrote a Porno
        </em>
        as “fiction”…). My reading still skews heavily to non-fiction, and specifically  design, but that’s what I’m passionate about and it helps me professionally, so I’m ok with it.
       </p>
       <p>
        I also apparently didn’t finish any books in January or February. I thought this might have been a mistake at first, but when I looked back on that time I realized it’s because I was wrapping things up at Optimizely, and reading both
        <em>
         Quicksilver
        </em>
        by Neal Stephenson and
        <em>
         Story
        </em>
        by Robert McKee at the same time, which are long books that took awhile to work through.
       </p>
       <h2 id="highlights">
        Highlights
       </h2>
       <h3 id="story-substance-structure-style-and-the-principles-of-screenwriting">
        Story: Substance, Structure, Style, and the Principles of Screenwriting
       </h3>
       <p>
        <em>
         by Robert McKee
        </em>
       </p>
       <p>
        I’ve read next to nothing about writing stories before, but Robert McKee’s primer on the subject is excellent. Even though I’m not a fiction author, I found his principles for writing compelling narratives valuable beyond just the domain of screenwriting.
       </p>
       <h3 id="handstyle-lettering">
        Handstyle Lettering
       </h3>
       <p>
        <em>
         Published and edited by Victionary
        </em>
       </p>
       <p>
        There wasn’t much to “read” in this book, but it was full of beautiful hand-lettered pieces that continue to inspire me to be a better letterer.
       </p>
       <h3 id="the-baroque-cycle">
        The Baroque Cycle
       </h3>
       <p>
        <em>
         by Neal Stephenson
        </em>
       </p>
       <p>
        Neal Stephenson’s Baroque Cycle is a broad, staggering, 3-volume and 2,500+ page opus of historical science fiction, making it no small feat to complete (I read the first 2 this year, and am almost done with the 3rd volume). It takes place during the scientific revolution of the 17th and 18th centuries when the world transitioned out of feudal rule towards a more rational and merit-based society that we would recognize as modern. It weaves together a story between fictional and non-fictional characters, including Newton, Leibniz, Hooke, Wren, royalty, and other persons-of-quality. Although the series can be slow and byzantine at times, Stephenson makes up for it with his attention to detail and the sheer amount of research and effort he put into accurately capturing the time period and bringing the story to life. Even just having the audacity to put yourself in Newton’s head to speak from his perspective, much less to do so
        <em>
         convincingly
        </em>
        , makes the series worth the effort.
       </p>
       <h3 id="good-strategy-bad-strategy">
        Good Strategy, Bad Strategy
       </h3>
       <p>
        <em>
         by Richard P. Rumelt
        </em>
       </p>
       <p>
        Strategy is a fuzzy concept, but Rumelt makes it concrete and approachable with many examples of good and bad strategy.
        <a href="http://jlzych.com/2018/06/27/notes-from-good-strategy-bad-strategy/">
         Read my full notes here
        </a>
        . Highly recommended.
       </p>
       <h3 id="bird-by-bird-some-instructions-on-writing-and-life">
        Bird by Bird: Some Instructions on Writing and Life
       </h3>
       <p>
        <em>
         by Anne Lamott
        </em>
       </p>
       <p>
        A great little meditation on the writing process (and life!), sprinkled with useful tips and tricks throughout.
       </p>
       <h3 id="creative-selection-inside-apple-39-s-design-process">
        Creative Selection: Inside Apple’s design process
       </h3>
       <p>
        <em>
         by Ken Kocienda
        </em>
       </p>
       <p>
        Ken Kocienda was a software engineer during the “golden age of Steve Jobs,” and provides a fascinating insight into the company’s design process. I’m still chewing on what I read (and hope to publish more thoughts soon), but it’s striking how different it is from any process I’ve ever seen at any company, and different from best practices written about in books. It’s basically all built around Steve Jobs’ exacting taste, with designers and developers demoing their work to Steve with the hope of earning his approval. Very difficult to replicate, but the results speak for themselves.
       </p>
       <h3 id="ogilvy-on-advertising">
        Ogilvy on Advertising
       </h3>
       <p>
        <em>
         by David Ogilvy
        </em>
       </p>
       <p>
        I hadn’t read much about advertising before, but Ogilvy’s book on the subject is great. It’s full of practical advice on how to write compelling headlines and ads that sell.
        <a href="http://jlzych.com/2018/11/12/how-to-write-effective-advertisements-according-to-david-ogilvy/">
         Read my notes here
        </a>
        .
       </p>
       <h2 id="full-list-of-books-read">
        Full List of Books Read
       </h2>
       <ul>
        <li>
         <em>
          Story: Substance, Structure, Style, and the Principles of Screenwriting
         </em>
         by Robert McKee (3/7/18)
        </li>
        <li>
         <em>
          The Color of Pixar
         </em>
         by Tia Kratter (3/18/18)
        </li>
        <li>
         <em>
          Conversational Design
         </em>
         by Erika Hall (3/27/18)
        </li>
        <li>
         <em>
          Quicksilver
         </em>
         by Neal Stephenson (4/3/18)
        </li>
        <li>
         <em>
          Handstyle Lettering
         </em>
         published and edited by Victionary (4/24/18)
        </li>
        <li>
         <em>
          Bimimicry: Innovation Inspired by Nature
         </em>
         by Janine M. Benyus (5/4/18)
        </li>
        <li>
         <em>
          Design is Storytelling
         </em>
         by Ellen Lupton (5/11/18)
        </li>
        <li>
         <em>
          Trip
         </em>
         by Tao Lin (5/20/18)
        </li>
        <li>
         <em>
          Good Strategy, Bad Strategy: The Difference and Why it Matters
         </em>
         by Richard P. Rumelt (5/27/18)
        </li>
        <li>
         <em>
          Bird by Bird: Some Instructions on Writing and Life
         </em>
         by Anne Lamott (6/10/18)
        </li>
        <li>
         <em>
          The Inmates are Running the Asylum
         </em>
         by Alan Cooper (6/13/18)
        </li>
        <li>
         <em>
          It Chooses You
         </em>
         by Miranda July (6/13/18)
        </li>
        <li>
         <em>
          String Theory
         </em>
         by David Foster Wallace (6/22/18)
        </li>
        <li>
         <em>
          Invisible Cities
         </em>
         by Italo Calvino (6/28/18)
        </li>
        <li>
         <em>
          My Dad Wrote a Porno
         </em>
         by Jamie Morton, James Cooper, Alice Levine, and Rocky Flintstone (7/1/18)
        </li>
        <li>
         <em>
          The User Experience Team of One
         </em>
         by Leah Buley (7/8/18)
        </li>
        <li>
         <em>
          Change by Design
         </em>
         by Tim Brown (9/3/18)
        </li>
        <li>
         <em>
          Darkness at Noon
         </em>
         by Arthur Koestler (9/16/2018)
        </li>
        <li>
         <em>
          Creative Selection: Inside Apple’s design process during the golden age of Steve Jobs
         </em>
         by Ken Kocienda (9/20/18)
        </li>
        <li>
         <em>
          The Confusion
         </em>
         by Neal Stephenson (9/26/18)
        </li>
        <li>
         <em>
          How to Change Your Mind
         </em>
         by Michael Pollan (10/27/18)
        </li>
        <li>
         <em>
          Ogilvy on Advertising
         </em>
         by David Ogilvy (11/11/18)
        </li>
        <li>
         <em>
          Draft No. 4. On the writing process
         </em>
         by John McPhee (11/14/18)
        </li>
       </ul>
      </div>
      <p class="date">
       <a href="http://jlzych.com/2019/01/03/books-read-2018/">
        by Jeff Zych at January 04, 2019 12:26 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 30, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3668">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/30/state-regulation-and-or-corporate-self-regulation/">
       State regulation and/or corporate self-regulation
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        The
        <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
         dust from the recent debates
        </a>
        about whether regulation or industrial self-regulation in the data/tech/AI industry appears to be settling. The smart money is on regulation and self-regulation being complementary for attaining the goal of an industry dominated by responsible actors. This trajectory leads to centralized corporate power that is lead from the top; it is a Hamiltonian not Jeffersonian solution, in
        <a href="https://digifesto.com/2018/05/27/notes-on-pasquale-tech-platforms-and-the-knowledge-problem-2018/">
         Pasquale’s terms
        </a>
        .
       </p>
       <p>
        I am personally not inclined towards this solution. But I have been convinced to see it differently after a conversation today about environmentally sustainable supply chains in food manufacturing. Nestle, for example, has been internally changing its sourcing practices to more sustainable chocolate. It’s able to finance this change from its profits, and when it does change its internal policy, it operates on a scale that’s meaningful. It is able to make this transition in part because non-profits, NGO’s, and farmers cooperatives lay through groundwork for sustainable sourcing external to the company. This lowers the barriers to having Nestle switch over to new sources–they have already been subsidized through philanthropy and international aid investments.
       </p>
       <p>
        Supply chain decisions, ‘make-or-buy’ decisions, are the heart of transaction cost economics (TCE) and critical to the constitution of institutions in general. What this story about sustainable sourcing tells us is that the configuration of private, public, and civil society institutions is complex, and that there are prospects for agency and change in the reconfiguration of those relationships. This is no different in the ‘tech sector’.
       </p>
       <p>
        However, this theory of economic and political change is not
        <em>
         popular
        </em>
        ; it does not have broad intellectual or media appeal. Why?
       </p>
       <p>
        One reason may be because while it is a critical part of
        <a href="https://digifesto.com/2018/01/15/social-structure-and-the-private-sector/">
         social structure, much of the supply chain is in the private sector
        </a>
        , and hence is opaque. This is
        <strong>
         not
        </strong>
        a matter of transparency or interpretability of
        <em>
         algorithms
        </em>
        . This is about the fact that private institutions, by virtue of being ‘private’, do not have to report everything that they do and, probably, shouldn’t. But since so much of what is done by the massive private sector is of public import, there’s a danger of the
        <a href="https://digifesto.com/2018/11/18/the-privatization-of-public-functions/">
         privatization of public functions
        </a>
        .
       </p>
       <p>
        Another reason why this view of political change through the internal policy-making of enormous private corporations is unpopular is because it leaves decision-making up to a very small number of people–the elite managers of those corporations. The real disparity of power involved in private corporate governance means that the popular attitude towards that governance is, more often than not, irrelevant. Even less so that political elites, corporate elites are not accountable to a constituency. They are accountable, I suppose, to their shareholders, which have material interests disconnected from political will.
       </p>
       <p>
        This disconnected shareholder will is one of the main reasons why I’m skeptical about the idea that large corporations and their internal policies are where we should place our hopes for moral leadership. But perhaps what I’m missing is the appropriate intellectual framework for how this will is shaped and what drives these kinds of corporate decisions. I still think TCE might provide insights that I’ve been missing. But I am on the lookout for other sources.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/30/state-regulation-and-or-corporate-self-regulation/">
        by Sebastian Benthall at December 30, 2018 08:39 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 24, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3666">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/24/ordoliberalism-and-industrial-organization/">
       Ordoliberalism and industrial organization
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        There’s a nice
        <a href="https://www.ft.com/content/9dfea428-0538-11e9-9d01-cd4d49afbbe3">
         op-ed
        </a>
        by Wolfgang Münchau in FT, “The crisis of modern liberalism is down to market forces”.
       </p>
       <p>
        Among other things, it reintroduces the term “
        <a href="https://en.wikipedia.org/wiki/Ordoliberalism">
         ordoliberalism
        </a>
        “, a particular Germanic kind of enlightened liberalism designed to prevent the kind of political collapse that had precipitated the war.
       </p>
       <p>
        In Münchau’s account, the key insight of ordoliberalism is its attention to questions of social equality, but not through the mechanism of redistribution. Rather, ordoliberal interventions primarily effect industrial organization, favoring small to mid- sized companies.
       </p>
       <p>
        As Germany’s economy remains robust and so far relatively politically stable, it’s interesting that ordoliberalism isn’t discussed more.
       </p>
       <p>
        Another question that must be asked is to what extent the rise of computational institutions challenges the kind of industrial organization recommended by ordoliberalism. If computation induces corporate concentration, and there are not good policies for addressing that, then that’s due to a deficiency in our understanding of what ‘market forces’ are.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/24/ordoliberalism-and-industrial-organization/">
        by Sebastian Benthall at December 24, 2018 02:32 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 22, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3664">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/22/when-shouldnt-you-build-a-machine-learning-system/">
       When *shouldn’t* you build a machine learning system?
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Luke Stark raises an interesting question, directed at “ML practitioner”:
       </p>
       <div class="embed-twitter">
        <blockquote class="twitter-tweet">
         <p dir="ltr" lang="en">
          The question I now most frequently ask ML practitioners — and one to which I’ve yet to receive a clear answer — is to explain what technical evidence will they accept as dispositive to not build/deploy a system in the first place.
         </p>
         <p>
          — Luke Stark PhD (@luke_stark)
          <a href="https://twitter.com/luke_stark/status/1071812025632862208?ref_src=twsrc%5Etfw">
           December 9, 2018
          </a>
         </p>
        </blockquote>
        <p>
        </p>
       </div>
       <p>
        As an “ML practitioner” in on this discussion, I’ll have a go at it.
       </p>
       <p>
        In short, one should not build an ML system for making a class of decisions if there is already a better system for making that decision that does not use ML.
       </p>
       <p>
        An example of a comparable system that does not use ML would be a team of human beings with spreadsheets, or a team of people employed to judge for themselves.
       </p>
       <p>
        There are a few reasons why a non-ML system could be superior in performance to an ML system:
       </p>
       <ul>
        <li>
         The people involved could have access to more data, in the course of their lives, in more dimensions of variation, than is accessible by the machine learning system.
        </li>
        <li>
         The people might have more sensitized ability to make semantic distinctions, such as in words or images, than an ML system
        </li>
        <li>
         The problem to be solved could be a “wicked problem” that is itself over a very high-dimensional space of options, with very irregular outcomes, such that they are not amenable to various forms of, e.g., linear approximations
        </li>
        <li>
         The people might be judging an aspect of their own social environment, such that the outcome’s validity is socially procedural (as in the outcome of a vote, or of an auction)
        </li>
       </ul>
       <p>
        These are all fine reasons not to use an ML system. On the other hand, the term “ML” has been extended, as with “AI”, to include many hybrid human-computer systems, which has led to some confusion. So, for example. crowdsourced labels of images provide useful input data to ML systems. This hybrid system might perform semantic judgments over a large scale of data, at a high speed, at a tolerable rate of accuracy. Does this system count as an ML system? Or is it a form of
        <a href="https://digifesto.com/2018/12/22/computational-institutions/">
         computational institution
        </a>
        that rivals other ways of solving the problem, and just so happens to have a machine learning algorithm as part of its process?
       </p>
       <p>
        Meanwhile, the research frontier of machine learning is all about trying to solve problems that previously haven’t been solved, or solved as well, as alternative kinds of systems. This means there will always be a disconnect between machine learning research, which is trying to expand what it is possible to do with machine learning, and what machine learning research should, today, be deployed. Sometimes, research is done to develop technology that is not mature enough to deploy.
       </p>
       <p>
        We should expect that a lot of ML research is done on things that should not ultimately be deployed! That’s because until we do the research, we may not understand the problem well enough to know the consequences of deployment. There’s a real sense in which ML
        <em>
         research
        </em>
        is about understanding the computational contours of a problem, whereas ML
        <em>
         industry practice
        </em>
        is about addressing the problems customers have with an efficient solution. Often this solution is a hybrid system in which ML only plays a small part; the use of ML here is really about a change in the institutional structure, not so much a part of what service is being delivered.
       </p>
       <p>
        On the other hand, there have been a lot of cases–search engines and social media being important ones–where the scale of data and the use of ML for processing has allowed for a qualitatively different form of product or service. These are now the big deal companies we are constantly talking about. These are pretty clearly cases of successful ML.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/22/when-shouldnt-you-build-a-machine-learning-system/">
        by Sebastian Benthall at December 22, 2018 06:47 PM
       </a>
      </p>
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3662">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/22/computational-institutions/">
       computational institutions
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        As the “AI ethics” debate metastasizes in my newsfeed and scholarly circles, I’m struck by the frustrations of technologists and ethicists who seem to be speaking past each other.
       </p>
       <div class="embed-twitter">
        <blockquote class="twitter-tweet">
         <p dir="ltr" lang="en">
          Appreciate
          <a href="https://twitter.com/Aaroth?ref_src=twsrc%5Etfw">
           @Aaroth
          </a>
          point. Our
          <a href="https://twitter.com/juliapowles?ref_src=twsrc%5Etfw">
           @juliapowles
          </a>
          piece does not indict technical work. Rather: tech can help but won't solve. And more so, obsession with bias 1) conveniently distracts from ongoing data heist and 2) shuts down existential questions about appropriate role of machines.
          <a href="https://t.co/lVurUgnkTb">
           https://t.co/lVurUgnkTb
          </a>
         </p>
         <p>
          — Helen Nissenbaum (@HNissenbaum)
          <a href="https://twitter.com/HNissenbaum/status/1071811101774540800?ref_src=twsrc%5Etfw">
           December 9, 2018
          </a>
         </p>
        </blockquote>
        <p>
        </p>
       </div>
       <p>
        While these tensions play out along disciplinary fault-lines, for example, between technologists and science and technology studies (STS), the
        <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
         economic motivations
        </a>
        are more often than not below the surface.
       </p>
       <p>
        I believe this is to some extent a problem of the nomenclature, which is again the function of the disciplinary rifts involved.
       </p>
       <p>
        Computer scientists work, generally speaking, on the design and analysis of computational systems. Many see their work as bounded by the demands of the portability and formalizability of technology (see Selbst et al., 2019). That’s their job.
       </p>
       <p>
        This is endlessly unsatisfying to critics of the social impact of technology. STS scholars will insist on changing the subject to “sociotechnical systems”, a term that means something very general: the assemblage of people and artifacts that are not people. This, fairly, removes focus from the computational system and embeds it in a social environment.
       </p>
       <p>
        A goal of this kind of work seems to be to hold computational systems, as they are deployed and used socially, accountable. It must be said that once this happens, we are no longer talking about the specialized domain of computer science per se. It is a wonder why STS scholars are so often picking fights with computer scientists, when their true beef seems to be with businesses that use and deploy technology.
       </p>
       <p>
        The AI Now Institute has attempted to rebrand the problem by discussing “AI Systems” as, roughly, those sociotechnical systems that use AI. This is one the one hand more specific–AI is a particular kind of technology, and perhaps it has particular political consequences. But their analysis of AI systems quickly overflows into sweeping claims about “the technology industry”, and it’s clear that most of their recommendations have little to do with AI, and indeed are trying, once again, to change the subject from discussion of AI as a technology (a computer science research domain) to a broader set of social and political issues that do, in fact, have their own disciplines where they have been researched for years.
       </p>
       <p>
        The problem, really, is not that any particular conversation is not happening, or is being excluded, or is being shut down. The problem is that the engineering focused conversation about AI-as-a-technology has grown very large and become an awkward synecdoche for the rise of major corporations like Google, Apple, Amazon, Facebook, and Netflix. As these corporations fund and motivate a lot of research, there’s a question of who is going to get pieces of the big pie of opportunity these companies represent, either in terms of research grants or impact due to regulation, education, etc.
       </p>
       <p>
        But there are so many aspects of these corporations that are neither addressed by the terms “sociotechnical system”, which is just so broad, and “AI System”, which is as broad and rarely means what you’d think it does (that the system uses AI is incidental if not unnecessary; what matters is that it’s a company operating in a core social domain via primarily technological user interfaces). Neither of these gets at the unit of analysis that’s really of interest.
       </p>
       <p>
        An alternative: “computational institution”. Computational, in the sense of computational cognitive science and computational social science: it denotes the essential role of theory of computation and statistics in explaining the behavior of the phenomenon being studied. “Institution”, in the sense of institutional economics: the unit is a firm, which is comprised of people, their equipment, and their economic relations, to their suppliers and customers. An economic lens would immediately bring into focus “the data heist” and the “role of machines” that Nissenbaum is concerned are being left to the side.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/22/computational-institutions/">
        by Sebastian Benthall at December 22, 2018 04:59 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 20, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://bytegeist.wordpress.com" title="The Bytegeist">
       Richmond Wong
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://bytegeist.wordpress.com/?p=466">
     <h4 class="posttitle" lang="en">
      <a href="https://bytegeist.wordpress.com/2018/12/19/tensions-of-a-digitally-connected-world-in-cricket-wireless-holiday-ad-campaign/">
       Tensions of a Digitally-Connected World in Cricket Wireless’ Holiday Ad Campaign
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        In the spirit of taking a break over the holidays, this is more of a fun post with some very rough thoughts (though inspired by some of my prior work on paying attention to and critiquing
        <a href="https://bytegeist.wordpress.com/2016/06/05/analyzing-concept-videos/">
         narratives and futures portrayed by tech advertising
        </a>
        ). The basic version is that the
        <a href="https://www.youtube.com/watch?v=psTi1ZlOUxU">
         Cricket Wireless 2018 Holiday Ad
        </a>
        ,
        <em>
         Four the Holidays
        </em>
        (made by ad company
        <a href="https://vimeo.com/300801985">
         Psyop
        </a>
        ), portrays a narrative that makes a slight critique of an always-connected world and suggests that physical face-to-face interaction is a more enjoyable experience for friends than digital sharing. While perhaps a over-simplistic critique of mobile technology use, the twin messages of “buy a wireless phone plan to connect with friends” and “try to disconnect to spend time with friends” highlight important tensions and contradictions present in everyday digital life.
       </p>
       <p>
        But let’s look at the ad in a little more detail!
       </p>
       <p style="text-align: center;">
       </p>
       <div class="jetpack-video-wrapper">
       </div>
       <p>
       </p>
       <p>
        Last month, while streaming Canadian curling matches (it’s more fun than you might think, case in point, I’ve blogged about the sport’s own
        <a href="https://bytegeist.wordpress.com/2015/11/11/curling-brooms-policy-and-provocative-design/">
         controversy with broom technology
        </a>
        ) there was a short
        <a href="https://www.youtube.com/watch?v=XOhXdnV6V2M">
         Cricket ad
        </a>
        playing with a holiday jingle. And I’m generally inclined to pay attention to an ad with a good jingle. Looking it up online brought up a 3 minute long short film version expanding upon the 15 second commercial (embedded above), which I’ll describe and analyze below.
       </p>
       <p>
        It starts with Cricket’s animated characters Ramon (the green blob with hair), Dusty (the orange fuzzy ball), Chip (the blue square), and Rose (the green oblong shape) on a Hollywood set, “filming” the aforementioned commercial, singing their jingle:
       </p>
       <blockquote>
        <p>
         The four, the merrier! Cricket keeps us share-ier!
        </p>
        <p>
         Four lines of unlimited data, for a hundred bucks a month!
        </p>
       </blockquote>
       <p>
        After their shoot is over, Dusty wants the group to watch fireworks from the Cricket water tower (which is really the Warner Brothers Studio water tower, though maybe we should call it Chekov’s water tower in this instance) on New Year’s Eve. Alas, the crew has other plans, and everyone flies to their holiday destinations: Ramon to Mexico, Dusty to Canada, Chip to New York, and Rose to Aspen.
       </p>
       <p>
        The video then shows each character enjoying the holidays in their respective locations with their smartphones. Ramon uses his phone to take pictures of food shared on a family table; Rose uses hers to take selfies on a ski lift.
       </p>
       <p>
        The first hint that there might be a message critiquing an always-connected world is when the ad shows Dusty in a snowed-in, remote Canadian cabin. Presumably this tells us that he gets a cell signal up there, but in this scene, he is not using his phone. Rather, he’s making cookies with his two (human) nieces (not sure how that works, but I’ll suspend my disbelief), highlighting a face-to-face familial interaction using a traditional holiday group activity.
       </p>
       <p>
        The second hint that something might not be quite right is the dutch angel establishing shot of New York City in the next scene. The non-horizontal horizon line (which also evokes the off-balance establishing shot of New York from an
        <a href="https://www.youtube.com/watch?v=QwievZ1Tx-8">
         Avengers: Infinity War trailer
        </a>
        ) visually puts the scene off balance. But the moment quickly passes, as we see Chip on the streets of New York taking instagram selfies.
       </p>
       <div class="wp-caption alignnone" id="attachment_467" style="width: 3830px;">
        <img alt="2 Dutch angles of New York" class="alignnone size-full wp-image-467" src="https://bytegeist.files.wordpress.com/2018/12/new-york-dutch-angles.png?w=730"/>
        <p class="wp-caption-text">
         Dutch angle of New York from Cricket Wireless’ “Four the Holidays” (left) and Marvel’s Avengers Infinity War (right)
        </p>
       </div>
       <p>
        Then comes a rapid montage of photos and smiling selfies that the group is sending and sharing with each other, in a sort of digital self-presentation utopia. But as the short film has been hinting at, this utopia is not reflective of the characters’ lived experience.
       </p>
       <p>
        The video cuts to Dusty, skating alone on a frozen pond, successfully completing a trick, but then realizes that he has no one to share the moment with. He then sings “The four the merrier, Cricket keeps us share-ier” in a minor key as re-envisions clouds in the sky as the form of the four friends. The minor key and Dusty’s singing show skepticism in the lyrics’ claim that being share-ier is indeed merrier.
       </p>
       <p>
        The minor key continues, as Ramon sings while envisioning a set of holiday lights as the four friends, and Rose sees a department store window display as the four friends. Chip attends a party where the Cricket commercial (from the start of the video) airs on a TV, but is still lonely. Chip then hails a cab, dramatically stating in a deep voice “Take me home.”
       </p>
       <p>
        In the last scene, Chip sits atop the Cricket Water Tower (or, Chekov’s Water Tower returns!) at 11:57pm on New Year’s Eve, staring alone at his phone, discontent. This is the clearest signal about the lack of fulfillment he finds from his phone, and by extension, the digitally mediated connection with his friends.
       </p>
       <p>
        Immediately this is juxtaposed with Ramon singing with his guitar from the other side of the water tower, still in the minor key. Chip hears him and immediately becomes happier, and the music shifts to a major key as Rose and Dusty enter as the tempo picks up, and the drums and orchestra of instruments join in. And the commercial ends with the four of them watching New Year’s fireworks together. It’s worth noting the lyrics at the end:
       </p>
       <blockquote>
        <p>
         <em>
          Ramon: The four the merrier…
         </em>
        </p>
        <p>
         Chip [spoken]: Ramon?! You’re here!
        </p>
        <p>
         <em>
          Rose: There’s something in the air-ier
         </em>
        </p>
        <p>
         <em>
          All: That helps us connect, all the season through. The four, the merrier
         </em>
        </p>
        <p>
         <em>
          Dusty: One’s a little harrier (So hairy!)
         </em>
        </p>
        <p>
         <em>
          All: The holidays are better, the holidays are better, the holidays are better with your crew.
         </em>
        </p>
       </blockquote>
       <p>
        Nothing here is explicitly about Cricket wireless, or the value of being digitally connected. It’s also worth noting that the phone that Chip was previously staring at is nowhere to be found after he sees Ramon. There is some ambiguous use of the word “connect,” which could refer to both a face-to-face interaction or a digitally mediated one, but the tone of the scene and emotional storyline bringing the four friends physically together seems to suggest that connect refers to the value of face-to-face interaction.
       </p>
       <p>
        So what might this all mean (beyond the fact that I’ve watched this commercial too many times and have the music stuck in my head)? Perhaps the larger and more important point is that the commercial/short film is emblematic of a series of tensions around connection and disconnection in today’s society. Being digitally connected is seen as a positive that allows for greater opportunity (and greater work output), but at the same time discontent is reflected in culture and media, ranging from articles on
        <a href="https://www.theguardian.com/technology/2017/oct/05/smartphone-addiction-silicon-valley-dystopia">
         tech addiction
        </a>
        , to guides on
        <a href="https://blog.mozilla.org/internetcitizen/2018/02/13/grayscale/">
         grayscaling iPhones
        </a>
        to combat color stimulation, to
        <a href="http://digitaldetox.org/camp-grounded/">
         disconnection camps
        </a>
        . There’s also a moralizing force behind these tensions: to be a good employee/student/friend/family member/etc, we are told that we must be digitally connected and always-on, but at the same time, we are told that we must also be dis-connected or interact face-to-face in order to be good subjects.
       </p>
       <p>
        In many ways, the tensions expressed in this video — an advertisement for a wireless provider trying to encourage customers to sign up for their wireless plans, while presenting a story highlighting the need to digitally disconnect — parallels the tensions that
        <a href="https://ellieharmon.com/docs/HarmonMazmanian-SmartphoneStories-CHI2013.pdf">
         Ellie Harmon and Melissa Mazmanian find in their analysis of media discourse of smartphones
        </a>
        : that there is both a push for individuals to integrate the smartphone into everyday life, and to dis-integrate the smartphone from everyday life. What is fascinating to me here is that this video from Cricket exhibits both of those ideas at the same time. As Harmon and Mazmanian write,
       </p>
       <blockquote>
        <p>
         The stories that circulate about the smartphone in American culture matter. They matter for how individuals experience the device, the ways that designers envision future technologies, and the ways that researchers frame their questions.
        </p>
       </blockquote>
       <p>
        While
        <em>
         Four the Holidays
        </em>
        doesn’t tell the most complex or nuanced story about connectivity and smartphone use, the narrative that Cricket and Psyop created veers away from a utopian imagining of the world with tech, and instead begins to reflect  some of the inherent tensions and contradictions of smartphone use and mobile connectivity that are experienced as a part of everyday life.
       </p>
      </div>
      <p class="date">
       <a href="https://bytegeist.wordpress.com/2018/12/19/tensions-of-a-digitally-connected-world-in-cricket-wireless-holiday-ad-campaign/">
        by Richmond at December 20, 2018 05:36 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 19, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3646">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
       The politics of AI ethics is a seductive diversion from fixing our broken capitalist system
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        There is a lot of heat these days in the tech policy and ethics discourse. There is an enormous amount of valuable work being done on all fronts. And yet there is also sometimes bitter disciplinary infighting and political intrigue about who has the moral high ground.
       </p>
       <p>
        The smartest thing I’ve read on this recently is Irina Raicu’s “
        <a href="https://www.scu.edu/ethics/internet-ethics-blog/false-dilemmas/">
         False Dilemmas
        </a>
        ” piece, where she argues:
       </p>
       <ul>
        <li>
         “Tech ethics” research, including research explore the space of ethics in algorithm design, is really code for industry self-regulation
        </li>
        <li>
         Industry self-regulation and state regulation are complementary
        </li>
        <li>
         Any claims that “the field” is dominated by one perspective or agenda or another is overstated
        </li>
       </ul>
       <p>
        All this sounds very sane but it doesn’t exactly explain why there’s all this heated discussion in the first place. I think Luke Stark gets it right:
       </p>
       <div class="embed-twitter">
        <blockquote class="twitter-tweet">
         <p dir="ltr" lang="en">
          The problem is mostly capitalism – but that’s impolite to say, which is why folks on all sides avoid making a direct diagnosis
          <a href="https://t.co/4gEOT5T63T">
           https://t.co/4gEOT5T63T
          </a>
         </p>
         <p>
          — Luke Stark PhD (@luke_stark)
          <a href="https://twitter.com/luke_stark/status/1075010360233603074?ref_src=twsrc%5Etfw">
           December 18, 2018
          </a>
         </p>
        </blockquote>
        <p>
        </p>
       </div>
       <p>
        But what does it mean to say “the problem is mostly capitalism”? And why is it impolite to say it?
       </p>
       <p>
        To say “the problem [with technology ethics and policy] is capitalism” is to note that most if not all of the social problems we associate with today’s technology have been problems with technology ever since the industrial revolution. For example, James
        <a href="https://digifesto.com/tag/beniger/">
         Beniger
        </a>
        ‘s
        <em>
         The Control Revolution
        </em>
        ,
        <a href="https://digifesto.com/tag/eclipse-of-reason/">
         Horkheimer
        </a>
        ‘s
        <em>
         Eclipse of Reason
        </em>
        , and so on all speak to the tight link that there has always been between engineering and the capitalist economy as a whole. The link has persisted through the recent iterations of recognizing first
        <a href="https://digifesto.com/2013/12/16/reflections-on-the-berkeley-institute-for-data-science-bids-launch/">
         data science
        </a>
        , then later
        <a href="https://digifesto.com/2015/08/23/instrumentality-run-amok-bostrom-and-instrumentality/">
         artificial intelligence
        </a>
        , as disruptive triumphs of engineering with a variety of problematic social effects. These are old problems.
       </p>
       <p>
        It’s impolite to say this because it cuts down on the urgency that might drive political action. More generally, it’s an embarrassment to anybody in the business of talking as if they just discovered something, which is what journalists and many academics do. The buzz of novelty is what gets people’s attention.
       </p>
       <p>
        It also suggests that the blame for how technology has gone wrong lies with
        <em>
         capitalists
        </em>
        , meaning, venture capitalists, financiers, and early stage employees with stock options. But also, since it’s the 21st century, pension funds and university endowments are just as much a part of the capitalist investing system as anybody else. In capitalism, if you are saving, you are investing. Lots of people have a diffuse interest in preserving capitalism in some form.
       </p>
       <p>
        There’s a lot of interesting work to be done on financial regulation, but it has very little to do with, say, science and technology studies and consumer products. So to acknowledge that the problem with technology is capitalism changes the subject to something remote and far more politically awkward than to say the problem is technology or technologists.
       </p>
       <p>
        As I’ve argued
        <a href="https://data-activism.net/2018/04/critical-reflections-on-fat-2018-a-historical-idealist-perspective/">
         elsewhere
        </a>
        , a lot of what’s happening with technology ethics can be thought of as an extension of what Nancy Fraser called
        <a href="https://americanaffairsjournal.org/2017/11/progressive-neoliberalism-trump-beyond/">
         progressive neoliberalism
        </a>
        : the alliance of neoliberalism with progressive political movements. It is still hegemonic in the smart, critical, academic and advocacy scene. Neoliberalism, or what is today perhaps better characterized as finance capitalism or surveillance capitalism, is what is causing the money to be invested in projects that design and deploy technology in certain ways. It is a system of economic distribution that is still hegemonic.
       </p>
       <p>
        Because it’s hegemonic, it’s impolite to say so. So instead a lot of the technology criticism gets framed in terms of the next available moral compass, which is progressivism. Progressivism is a system of distribution of
        <em>
         recognition
        </em>
        . It calls for patterns of recognizing people for their demographic and, because it’s correlated in a sensitive way, professional identities. Nancy Fraser’s insight is that neoliberalism and progressivism have been closely allied for many years. One way that progressivism is allied with neoliberalism is that progressivism serves as a moral smokescreen for problems that are in part caused by neoliberalism, preventing an effective, actionable critique of the root cause of many technology-related problems.
       </p>
       <p>
        Progressivism encourages political conflict to be articulated as an ‘us vs. them’ problem of populations and their attitudes, rather than as problem of institutions and their design. This “us versus them” framing is baldly stated than in the
        <a href="https://ainowinstitute.org/AI_Now_2018_Report.pdf">
         2018 AI Now Report
        </a>
        :
       </p>
       <blockquote>
        <p>
         <strong>
          The AI accountability gap is growing:
         </strong>
         The technology scandals of 2018 have shown that the gap between
         <u>
          those who develop and profit from AI—and those most likely to suffer the consequences of its negative effects
         </u>
         —is growing larger, not smaller. There are several reasons for this, including a lack of government regulation, a highly concentrated AI sector, insufficient governance structures within technology companies, power asymmetries between companies and the people they serve, and
         <em>
          a stark cultural divide between the engineering cohort responsible for technical research, and the vastly diverse populations where AI systems are deployed
         </em>
         . (Emphasis mine)
        </p>
       </blockquote>
       <p>
        There are several institutional reforms called for in the report, but the focus on a particular sector that it constructs as “the technology industry” composed on many “AI systems”, it cannot address broader economic issues such as unfair taxation or gerrymandering. Discussion of the overall economy is absent from the report; it is not the cause of anything. Rather, the root cause is a schism between kinds of people. The moral thrust of this claim hinges on the implied progressivism: the AI/tech people, who are developing and profiting, are a culture apart. The victims are “diverse”, and yet paradoxically unified in their culture as
        <em>
         not the developers
        </em>
        . This framing depends on the appeal of progressivism as a unifying culture whose moral force is due in large part because of its diversity. The AI developer culture is a threat in part because it is separate from diverse people–code for its being white and male.
       </p>
       <p>
        This thread continues throughout the report, as various critical perspectives are cited in the report. For example:
       </p>
       <blockquote>
        <p>
         A second problem relates to the deeper assumptions and worldviews of the designers of ethical codes in the technology industry. In response to the proliferation of corporate ethics initiatives, Greene et al. undertook a systematic critical review of high-profile “vision statements for ethical AI.” One of their findings was that these statements tend to adopt a technologically deterministic worldview, one where ethical agency and decision making was delegated to experts, “a narrow circle of who can or should adjudicate ethical concerns around AI/ML” on behalf of the rest of us. These statements often assert that AI promises both great benefits and risks to a universal humanity, without acknowledgement of more specific risks to marginalized populations. Rather than asking fundamental ethical and political questions about whether AI systems should be built, these documents implicitly frame technological progress as inevitable, calling for better building.
        </p>
       </blockquote>
       <p>
        That systematic critical reviews of corporate policies express self-serving views that ultimately promote the legitimacy of the corporate efforts
        <em>
         is a surprise to no one
        </em>
        ; it is no more a surprise than the fact that critical research institutes staffed by lawyers and soft social scientists write reports recommending that their expertise is vitally important for society and justice. As has been the case in every major technology and ethical scandal
        <a href="https://digifesto.com/2014/07/08/the-facebook-ethics-problem-is-a-political-problem/">
         for years
        </a>
        , the first thing the commentariat does is publish a lot of pieces justifying their own positions and, if they are brave, arguing that other people are getting too much attention or money. But since everybody in either business depends on capitalist finance in one way or another, the economic system is not subject to critique. In other words, once can’t argue that industrial visions of ‘ethical AI’ are favorable to building new AI products because they are written in service to capitalist investors who profit from the sale of new AI products. Rather, one must argue that they are written in this way because the authors have a weird technocratic worldview that isn’t diverse enough. One can’t argue that the commercial AI products neglect marginal populations because these populations have less purchasing power; one has to argue that the marginal populations are not
        <em>
         represented or recognized
        </em>
        enough.
       </p>
       <p>
        And yet, the report paradoxically
        <em>
         both
        </em>
        repeatedly claims that AI developers are culturally and politically out of touch
        <em>
         and
        </em>
        lauds the internal protests at companies like Google that have exposed wrongdoing within those corporations. The actions of “technology industry” employees belies the idea that problem is mainly cultural; there is a managerial profit-making impulse that is, in large, stable companies in particular, distinct from that the rank-and-file engineer. This can be explained in terms of corporate incentives and so on, and indeed the report does in places call for whistleblower protections and labor organizing. But these calls for change cut against and contradict other politically loaded themes.
       </p>
       <p>
        There are many different arguments contained in the long report; it is hard to find a reasonable position that has been
        <em>
         completely
        </em>
        omitted. But as a comprehensive survey of recent work on ethics and regulation in AI, its biases and blind spots are indicative of the larger debate. The report concludes with a call for a change in the intellectual basis for considering AI and its impact:
       </p>
       <blockquote>
        <p>
         It is imperative that the balance of power shifts back in the public’s favor. This will require significant structural change that goes
         <u>
          well beyond a focus on technical systems
         </u>
         , including a willingness to alter the standard operational assumptions that govern the modern AI industry players. The current focus on discrete technical fixes to systems should expand to draw on socially-engaged disciplines, histories, and strategies capable of providing a deeper understanding of the
         <u>
          various social contexts
         </u>
         that shape the development and use of AI systems.
        </p>
        <p>
         As more universities turn their focus to the study of AI’s social implications,
         <u>
          computer science and engineering
         </u>
         can no longer be the unquestioned center, but should collaborate more equally with
         <u>
          social and humanistic disciplines
         </u>
         , as well as with civil society organizations and affected communities. (Emphasis mine)
        </p>
       </blockquote>
       <p>
        The “technology ethics” field is often construed, in this report but also in the broader conversation, as one of tension between
        <em>
         computer science
        </em>
        on the one hand, and
        <em>
         socially engaged and humanistic disciplines
        </em>
        on the other. For example, Selbst et al.’s “
        <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3265913">
         Fairness and Abstraction in Sociotechnical Systems
        </a>
        ” presents a thorough account of pitfalls of computer science’s approach to fairness in machine learning, and proposes a Science and Technology Studies. The refrain is that by considering more social context, more nuance, and so on, STS and humanistic disciplines avoids the problems that engineers, who try to provide portable, formal solutions, don’t want to address. As the AI Now report frames it, a benefit of the humanistic approach is that it brings the diverse non-AI populations to the table, shifting the balance of power back to the public. STS and related disciplines claim the status of
        <em>
         relevant expertise
        </em>
        in matters of technology that is somehow
        <em>
         not
        </em>
        the kind of expertise that is alienating or inaccessible to the public,
        <em>
         unlike
        </em>
        engineering, which allegedly
        <em>
         dominates
        </em>
        the higher education system.
       </p>
       <p>
        I am personally baffled by these arguments; so often they appear to conflate academic disciplines with business practices in ways that most practitioners I engage with would not endorse. (Try asking an engineer how much they learned in school, versus on the job, about what it’s like to work in a corporate setting.) But beyond the strange extrapolation from academic disciplinary disputes (which are so often about the internal bureaucracies of universities it is, I’d argue after learning the hard way, unwise to take them seriously from either an intellectual or political perspective), there is also a profound absence of some fields from the debate, as framed in these reports.
       </p>
       <p>
        I’m referring to the quantitative social sciences, such as economics and quantitative sociology, or what might be more be more generally converging on computational social science. These are the disciplines that one would need to use to understand the large-scale, systemic impact of technology on people, including the ways costs and benefits are distributed. These disciplines deal with social systems and include technology–there is a long tradition within economics studying the relationship between people, goods, and capital that never once requires the term “sociotechnical”–in a systematic way that can be used to predict the impact of policy. They can also connect, through applications of business and finance, the ways that capital flows and investment drive technology design decisions and corporate competition.
       </p>
       <p>
        But these fields are awkwardly placed in technology ethics and politics. They don’t fit into the engineering vs. humanities dichotomy that entrances so many graduate students in this field. They often invoke mathematics, which makes them another form of suspicious, alien, insufficiently diverse expertise. And yet, it may be that these fields are the only ones that can correctly diagnose the problems caused by technology in society. In a sense, the progressive framing of the problems of technology makes technogy’s ills a problem of social context because it is unequipped to address them as a problem of economic context, and it wouldn’t want know that it is an economic problem anyway, for two somewhat opposed reasons: (a) acknowledging the underlying economic problems is taboo under hegemonic neoliberalism, and (b) it upsets the progressive view that more popularly accessible (and, if you think about it quantitatively, therefore as a result of how it is generated and constructed more diverse) humanistic fields need to be recognized as much as fields of narrow expertise. There is no credence given to the idea that narrow and mathematized expertise might actually be especially well-suited to understand what the hell is going on, and that this is precisely why members of these fields are so highly sought after by investors to work at their companies. (Consider, for example, who would be best positioned to analyze the “full stack supply chain” of artificial intelligence systems, as is called for by the AI Now report: sociologists, electrical engineers trained in the power use and design of computer chips, or management science/operations research types whose job is to optimize production given the many inputs and contingencies of chip manufacture?)
       </p>
       <p>
        At the end of the day, the problem with the “technology ethics” debate is a dialectic cycle whereby (a) basic research is done by engineers, (b) that basic research is developed in a corporate setting as a product funded by capitalists, (c) that product raises political hackles and makes the corporations a lot of money, (d) humanities scholars escalate the political hackles, (e) basic researchers try to invent some new basic research because the politics have created more funding opportunities, (f) corporations do some PR work trying to CYA and engage in self-regulation to avoid litigation, (g) humanities scholars, loathe to cede the moral high ground, insist the scientific research is inadequate and that the corporate PR is bull. But this cycle is not necessarily productive. Rather, it sustains itself as part of a larger capitalist system that is bigger than any of these debates, structures its terms, and controls all sides of the dialog. Meanwhile the experts on how that larger system works are silent or ignored.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Fraser, Nancy. “Progressive neoliberalism versus reactionary populism: A choice that feminists should refuse.” NORA-Nordic Journal of Feminist and Gender Research 24.4 (2016): 281-284.
       </p>
       <p>
        Greene, Daniel, Anna Laura Hoffman, and Luke Stark. “Better, Nicer, Clearer, Fairer: A Critical Assessment of the Movement for Ethical Artificial Intelligence and Machine Learning.” Hawaii International Conference on System Sciences, Maui, forthcoming. Vol. 2019. 2018.
       </p>
       <p>
        Raicu, Irina. “False Dilemmas”. 2018.
       </p>
       <p>
        Selbst, Andrew D., et al. “Fairness and Abstraction in Sociotechnical Systems.” ACM Conference on Fairness, Accountability, and Transparency (FAT*). 2018.
       </p>
       <p>
        Whittaker, Meredith et al. “AI Now Report 2018”. 2018.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/18/the-politics-of-ai-ethics-is-a-seductive-diversion-from-fixing-our-broken-capitalist-system/">
        by Sebastian Benthall at December 19, 2018 04:54 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 14, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3638">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/13/the-secret-to-social-forms-has-been-in-institutional-economics-all-along/">
       The secret to social forms has been in institutional economics all along?
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        A long-standing mystery for me has been about the
        <em>
         ontology of social forms
        </em>
        (
        <a href="https://digifesto.com/2017/04/23/process-theory-generative-epistemology-configurative-ontology-notes-on-cederman-part-1/">
         1
        </a>
        ) (
        <a href="https://digifesto.com/2017/05/22/hard-realism-about-social-structure/">
         2
        </a>
        ): under what conditions is it right to call a particular assemblage of people a thing, and why? Most people don’t worry about this; in literatures I’m familiar with it’s easy to take a sociotechnical complex or assemblage, or a company, or whatever, as a basic unit of analysis.
       </p>
       <p>
        A lot of the trickiness comes from thinking about this as a problem of identifying
        <em>
         social
        </em>
        structure (Sawyer, 200; Cederman, 2005). This implies that people are in some sense together and obeying shared norms, and raises questions about whether those norms exist in their own heads or not, and so on. So far I haven’t seen a lot that really nails it.
       </p>
       <p>
        But
        <em>
         what if
        </em>
        the answer has been lurking in institutional economics all along? The “theory of the firm” is essentially a question of why a particular social form–the firm–exists as opposed to a bunch of disorganized transactions. The answers that have come up are quite good.
       </p>
       <p>
        Take for example Holmstrom (1982), who argues that in a situation where collective outcomes depend on individual efforts, individuals will be tempted to free-ride. That makes it beneficial to have somebody monitor the activities of the other people and have their utility be tied to the net success of the organization. That person becomes the owner of the company, in a capitalist firm.
       </p>
       <p>
        What’s nice about this example is that it explains social structure based on an efficiency argument; we would expect organizations shaped like this to be bigger and command more resources than others that are less well organized. And indeed, we have many enormous hierarchical organizations in the wild to observe!
       </p>
       <p>
        Another theory of the firm is Williamson’s transaction cost economics (TCE) theory, which is largely about the
        <a href="https://digifesto.com/2018/12/04/the-make-or-buy-decision-tce-in-the-software-and-cybersecurity/">
         make-or-buy decision
        </a>
        . If the transaction between a business and its supplier has “asset specificity”, meaning that the asset being traded is specific to the two parties and their transaction, then any investment from either party will induce a kind of ‘lock-in’ or ‘switching cost’ or, in Williamson’s language, a ‘bilateral dependence’. The more of that dependence, the more a free market relationship between the two parties will expose them to opportunistic hazards. Hence, complex contracts, or in the extreme case outright ownership and internalization, tie the firms together.
       </p>
       <p>
        I’d argue: bilateral dependence and the complex ‘contracts’ the connect entities are very much the stuff of “social forms”. Cooperation between people is valuable; the relation between people who cooperate is valuable as a consequence; and so both parties are ‘structurated’ (to mangle a Giddens term) individually into maintaining the reality of the relation!
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Cederman, L.E., 2005. Computational models of social forms: Advancing generative process theory 1. American Journal of Sociology, 110(4), pp.864-893.
       </p>
       <p>
        Holmstrom, Bengt. “Moral hazard in teams.” The Bell Journal of Economics (1982): 324-340.
       </p>
       <p>
        Sawyer, R. Keith. “Simulating emergence and downward causation in small groups.” Multi-agent-based simulation. Springer Berlin Heidelberg, 2000. 49-67.
       </p>
       <p>
        Williamson, Oliver E. “Transaction cost economics.” Handbook of new institutional economics. Springer, Berlin, Heidelberg, 2008. 41-65.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/13/the-secret-to-social-forms-has-been-in-institutional-economics-all-along/">
        by Sebastian Benthall at December 14, 2018 04:04 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 09, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3631">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/09/transaction-cost-economics-and-privacy-looking-at-hoofnagle-and-whittingtons-free/">
       Transaction cost economics and privacy: looking at Hoofnagle and Whittington’s “Free”
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        As I’ve been reading about
        <a href="https://digifesto.com/2018/12/02/discovering-transaction-cost-economics-tce/">
         transaction cost economics
        </a>
        (TCE) and independently scrutinizing the
        <a href="https://digifesto.com/2018/12/06/data-isnt-labor-because-using-search-engines-is-really-easy/">
         business model of search engines
        </a>
        , it stands to reason that I should look to the key paper holding down the connection between TCE and privacy, Hoofnagle and Whittinton’s “Free: Accounting for the Costs of the Internet’s Most Popular Price” (2014).
       </p>
       <p>
        I want to preface the topic by saying I stand by what I
        <a href="https://digifesto.com/2018/12/06/data-isnt-labor-because-using-search-engines-is-really-easy/">
         wrote earlier
        </a>
        : that at the heart of what’s going on with search engines, you have a trade of
        <em>
         attention
        </em>
        ; it requires imagining the user has have attention-time as a scarce resource. The user has a query and has the option to find material relevant to the query in a variety of ways (like going to a library). Often (!) they will do so in a way that costs them as little attention as possible: they use a search engine, which gives an almost instant and often high-quality response; they are also shown advertisements which consume some small amount of their attention, but less than they would expend searching through other means. Advertisers pay the search engine for this exposure to the user’s attention, which funds the service that is “free”, in dollars (but not in attention) to the users.
       </p>
       <p>
        Hoofnagle and Whittington make a very different argument about what’s going on with “free” web services, which includes free search engines. They argue that the claim that these web services are “free” is deceptive because the user may incur costs after the transaction on account of potential uses of their personal data. An example:
       </p>
       <blockquote>
        <p>
         The freemium business model Anderson refers to is popular among industries online. Among them, online games provide examples of free services with hidden costs. By prefacing play with the disclosure of personal identification, the firms that own and operate games can contact and monitor each person in ways that are difficult for the consumer to realize or foresee. This is the case for many games, including Disney’s “Club Penguin,” an entertainment website for children. After providing personal information to the firm, consumers of Club Penguin receive limited exposure to basic game features and can see numerous opportunities to enrich their play with additional features. In order to enrich the free service, consumers must buy all sort of enhancements, such as an upgraded igloo or pets for one’s penguin. Disney, like others in the industry, places financial value on the number of consumers it identifies, the personal information they provide, and the extent to which Disney can track consumer activity in order to modify the game and thus increase the rate of conversion of consumers from free players to paying customers.
        </p>
       </blockquote>
       <p>
        There are a number of claims here. Let’s enumerate them:
       </p>
       <ol>
        <li>
         This is an example of a ‘free’ service with hidden costs to users.
        </li>
        <li>
         The consumer doesn’t know what the game company will do with their personal information.
        </li>
        <li>
         In fact, the game will use the personal information to personalize pitches for in-game purchases that ‘enrich’ the free service.
        </li>
        <li>
         The goal of the company is to convert free players to paying customers.
        </li>
       </ol>
       <p>
        Working backwards, claim (4) is totally true. The company wants to make money by getting their customers to pay, and they will use personal information to make paying attractive to the customers (3). But this does not mean that the customer is always unwitting. Maybe children don’t understand the business model when they begin playing Penguin Club, but especially today parents certainly do. App Stores, for example, now label apps when they have “in-app purchases”, which is a pretty strong signal. Perhaps this is a recent change due to some saber rattling by the FTC, which to be fair would be attributable as a triumph to the authors if this article had influence on getting that to happen. On the other hand, this is a very simple form of customer notice.
       </p>
       <p>
        I am not totally confident that even if (2), (3), and (4) are true, that that entails (1), that there are “hidden costs” to free services. Elsewhere, Hoofnagle and Whittington raise more convincing examples of “costs” to release of PII, including being denied a job and resolving identity theft. But being convincingly sold an upgraded igloo for your digital penguin seems so trivial. Even if it’s personalized, how could it be a
        <em>
         hidden cost
        </em>
        ? It’s a separate transaction, no? Do you or do you not buy the igloo?
       </p>
       <p>
        Parsing this through requires, perhaps, a deeper look at TCE. According to TCE, agents are boundedly rational (they can’t know everything) and opportunistic (they will make an advantageous decision in the moment). Meanwhile, the world is complicated. These conditions imply that there’s a lot of uncertainty about future behavior, as agents will act strategically in ways that they can’t themselves predict. Nevertheless, agents engage in contracts with some kinds of obligations in them in the course of a transaction. TCE’s point is that these contracts are always
        <em>
         incomplete
        </em>
        , meaning that there are always uncertainties left unresolved in contracts that will need to be negotiated in certain contingent cases. All these costs of drafting, negotiating, and safeguarding the agreement are
        <em>
         transaction costs
        </em>
        .
       </p>
       <p>
        Take an example of software contracting, which I happen to know about from personal experience. A software vendor gets a contract from a client to do some customization. The client and the vendor negotiated some sort of scope of work ex ante. But always(!), the client doesn’t actually know what they want, and if the vendor delivers on the specification literally the client doesn’t like it. Then begins the ex post negotiation as the client tries to get the vendor to tweak the system into something more usable.
       </p>
       <p>
        Software contracting often resolves this by getting off the fixed cost contracting model and onto a cost-and-materials contact that allows billing by hours of developer time. Alternatively, the vendor can internalize the costs into the contract by inflating the cost “estimates” to cover for contingencies. In general, this all amounts to having more contract and a stronger relationship between the client and vendor, a “bilateral dependency” which TCE sees as a natural evolution of the incomplete contract under several common conditions, like “asset specificity”, which means that the asset is specialized to a particular transaction (or the two agents involved in it). Another term for this is
        <a href="https://en.wikipedia.org/wiki/Vendor_lock-in">
         lock-in
        </a>
        , or the presence of high switching costs, though this way of thinking about it reintroduces the idea of a classical market for essentially comparable goods and services that TCE is designed to mitigate against. This explains how technical dependencies of an organization become baked in more or less constitutionally as part of the organization, leading to the robustness of
        <a href="https://en.wikipedia.org/wiki/Installed_base">
         installed base
        </a>
        of a computing platform over time.
       </p>
       <p>
        This ebb and flow of contract negotiation with software vendors was a bit unsettling to me when I first encountered it on the job, but I think it’s safe to say that most people working in the industry accept this as How Things Work. Perhaps it’s the continued influence of orthodox economics that makes this all seem inefficient somehow, and TCE is the right way to conceptualize things that makes better sense of reality.
       </p>
       <p>
        But back to the Penguins…
       </p>
       <p>
        Hoofnagle and Whittington make the case that sharing PII with a service that then personalizes its offerings to you creates a kind of bilateral dependence between service and user. They also argue that loss of privacy, due to the many possible uses of this personal information (some nefarious), is a hidden cost that can be thought of as an ex post transaction cost that is a hazard because it has not been factored into the price ex ante. The fact that this data is valuable to the platform/service for paying their production costs, which is not part of the “free” transaction, is an indication that this data is a lot more valuable than consumers think it is.
       </p>
       <p>
        I am still on the fence about this.
       </p>
       <p>
        I can’t get over the feeling that
        <em>
         successfully selling a user a personalized, upgraded digital igloo
        </em>
        is such an absurd example of a “hidden cost” that it belies the whole argument that these services have hidden costs.
       </p>
       <p>
        Splitting hairs perhaps, it seems reasonable to say that Penguin Club has a free version, which is negotiated as one transaction. Then, conditional on the first transaction, it offers personalized igloos for real dollars. This purchase, if engaged in, would be
        <em>
         another, different transaction
        </em>
        , not an ex post renegotiation of the original contract with the Disney. This small difference changes the cost of the igloo from a hidden transaction cost into a normal, transparent cost. So it’s no big deal!
       </p>
       <p>
        Does the use of PII create a bilateral dependence between Disney and the users of Penguin Club? Yes, in a sense. Any application of attention to an information service, learning how to use it and getting it to be part of your life, is in a sense a bilateral dependence with a switching cost. But there are so many other free games to play on the internet that these costs seem hardly
        <em>
         hidden
        </em>
        . They could just be understood as part of the game. Meanwhile, we are basically unconcerned with Disney’s “dependence” on the consumer data, because Disney can get new users easily (unless the user is a “whale”, who actual pays the company). And “dependence” Disney has on particular users is a hidden cost for Disney, not for the user, and who cares about Disney.
       </p>
       <p>
        The cases of identity theft or job loss are strange cases that seem to have more to do with freaky data reuse than what’s going on with a particular transaction. Purpose binding notices and restrictions, which are being normed on through generalized GDPR compliance, seem adequate to deal with these cases.
       </p>
       <p>
        So, I have two conclusions:
       </p>
       <p>
        (1)
        <em>
         Maybe
        </em>
        TCE is the right lens for making an economic argument for why purpose binding restrictions are a good idea. They make transactions with platforms
        <em>
         less incomplete
        </em>
        , avoiding the moral hazard of ex post use of data in ways that incurs asymmetrically unknown effects on users.
       </p>
       <p>
        (2) This TCE analysis of platforms doesn’t address the explanatorily powerful point that
        <em>
         attention
        </em>
        is part of the trade. In addition to being concretely what the user is “giving up” to the platform and directly explaining monetization in some circumstances, the fact that attention is “sticky” and creates some amount of asset-specific learning is a feature of the information economy more generally. Maybe it needs a closer look.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Hoofnagle, Chris Jay, and Jan Whittington. “Free: accounting for the costs of the internet’s most popular price.” UCLA L. Rev. 61 (2013): 606.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/09/transaction-cost-economics-and-privacy-looking-at-hoofnagle-and-whittingtons-free/">
        by Sebastian Benthall at December 09, 2018 09:01 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 06, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3620">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/06/data-isnt-labor-because-using-search-engines-is-really-easy/">
       Data isn’t labor because using search engines is really easy
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        A theme I’ve heard raised in a couple places recently, including Ibarra et al. “Should We Treat Data As Labor?” and the
        <a href="https://ainowinstitute.org/AI_Now_2018_Report.pdf">
         AI Now 2018 Report
        </a>
        , is that there is something wrong with how “data”, particularly data “produced” by people on the web, is conceptualized as part of the economy. Creating data, the argument goes, requires labor. And as the product of labor, it should be protected according to the values and practices of labor movements in the past. In particular, the current uses of data in, say, targeted advertising, social media, and search, are exploitative; the idea that consumers ‘pay’ for these services with their data is misleading and ultimately unfair to the consumer. Somehow the value created by the data should be reapportioned back to the user.
       </p>
       <p>
        This is a sexy and popular argument among a certain subset of intellectuals who care about these things. I believe the core emotional appeal of this proposal is this: It is well known that a few well-known search engine and social media companies,
        <em>
         namely
        </em>
        Google and Facebook, are
        <em>
         rich
        </em>
        . If the value added by user data were in part returned to the users, the users, who are compared to Google and Facebook
        <em>
         not rich
        </em>
        , would get something they otherwise would not get. I.e., the benefits for recognizing the labor involved in creating data is redistribution of surplus to The Rest of Us.
       </p>
       <p>
        I don’t have a problem personally with that redistributive impulse. However, I don’t think the “data is labor” argument actually makes much sense.
       </p>
       <p>
        Why not? Well, let’s take the example of a search engine. Here is the transaction between a user and a search engine:
       </p>
       <ul>
        <li>
         Alice types a query, “avocado toast recipes”, into the search engine. This submits data to the company computers.
        </li>
        <li>
         The company computers use that data to generate a list of results that it deems relevant to that query.
        </li>
        <li>
         Alice sees the results, and maybe clicks on one or two of them, if they are good, in the process of navigating to the thing she was looking for in the first place.
        </li>
        <li>
         The search engine records that click as well, in order to better calibrate how to respond to others making that query.
        </li>
       </ul>
       <p>
        We might forget that the search engine is providing Alice a service and isn’t just a ubiquitous part of the infrastructure we should take for granted. The search engine has provided Alice with relevant search results. What this does is (dramatically) reduce Alice’s
        <em>
         search costs
        </em>
        ; had she tried to find the relevant URL by asking her friends, organically surfing the web, or using the library, who knows what she would have found or how long it would take her. But we would assume that Alice is using the search engine because it gets her more relevant results, faster.
       </p>
       <p>
        It is not clear how Alice could get this thing she wants
        <em>
         without
        </em>
        going through the motions of typing and clicking and submitting data. These actions all seem like a bare minimum of what is necessary to conduct this kind of transaction. Similarly, when I got to a grocery store and buy vegetables, I have to get out my credit card and swipe it at the machine. This creates data–the data about my credit card transaction. But I would never advocate for recognizing my hidden labor at the credit card machine is necessary to avoid the exploitation of the credit card companies, who then use that information to go about their business. That would be insane.
       </p>
       <p>
        Indeed, it is a principle of user interface design that the most compelling user interfaces are those that require the least effort from their users. Using search engines is really, really easy because they are designed that way. The fact that oodles of data are collected from a person without that person exerting much effort may be problematic in a lot of ways. But it’s not problematic because it’s laborious for the user; it is designed and compelling precisely because it is labor-saving. The smart home device industry has taken this even further, building voice-activated products for people who would rather not use their hands to input data. That is, if anything,
        <em>
         less labor
        </em>
        for the user, but
        <em>
         more data and more processing
        </em>
        on the automated part of the transaction. That the data is work for the company, and less work for the user, indicates that data is not the same thing as user labor.
       </p>
       <p>
        There is a version of this argument that brings up feminism. Women’s labor, feminists point out, has long been insufficiently recognized and not properly remunerated. For example, domestic labor traditionally performed by women has been taken for granted, and emotional labor (the work of controlling ones emotions on the job), which has often been feminized, has not been taken seriously  enough. This is a problem, and the social cause of recognizing women’s labor and rewarding it is,
        <em>
         ceteris paribus
        </em>
        , a great thing.
        <em>
         But
        </em>
        , and I know I’m on dicey ground here, so bear with me, this does not mean that everything that women do that they are not paid to do is unrecognized labor in the sense that is relevant for feminist critiques. Case in point, both men and women use credit cards to buy things, and make telephone calls, and drive vehicles through toll booths, and use search engines, and do any number of things that generate “data”, and in most of these cases it is not remunerated directly; but this lack of remuneration isn’t gendered. I would say, perhaps controversially, that the feminist critique does not actually apply to the general case of user generated data much at all! (Though is may apply in specific cases that I haven’t thought of.)
       </p>
       <p>
        So in conclusion, data isn’t labor, and labor isn’t data. They are different things. We may want a better, more just, political outcome with respect to the distribution of surplus from the technology economy. But trying to get there through an analogy between data and labor is a kind of incoherent way to go about it. We should come up with a better, different way.
       </p>
       <p>
        <strong>
         So what’s a better alternative?
        </strong>
        If the revenue streams of search engines are any indication, then it would seem that users “pay” for search engines through being exposed to advertising. So the “resource” that users are giving up in order to use the search engine is
        <em>
         attention
        </em>
        , or mental time; hence the term,
        <em>
         attention economy
        </em>
        .
       </p>
       <p>
        Framing the user cost of search engines in terms of attention does not easily lend itself to an argument for economic reform. Why? Because search engines are already saving people a lot of that attention by making it so easy to look stuff up. Really the transaction looks like:
       </p>
       <ul>
        <li>
         Alice pays some attention to Gob (the search engine).
        </li>
        <li>
         Gob gives Alice some good search results back in return, and then…
        </li>
        <li>
         Gob passes on some of Alice’s attention through to Bob, the advertiser, in return for money.
        </li>
       </ul>
       <p>
        So Alice gives up attention but gets back search results and the advertisement. Gob gets money. Bob gets attention. The “data” that matters is not the data transmitted from Alice’s computer up to Gob. Rather, the valuable data is the data that Alice
        <em>
         receives through her eyes
        </em>
        : of this data, the search results are positively valued, the advertisement is negatively valued, but the value of the bundled good is net positive.
       </p>
       <p>
        If there is something unjust about this economic situation, it has to be due to the way consumer’s attention is being managed by Gob. Interestingly, those who have studied the value of ‘free’ services in attentional terms have chalked up a substantial consumer surplus due to saved attention (Brynjolfsson and Oh, 2012) This appears to be the perspective of management scientists, who tend to be pro-business, and is not a point repeated often by legal scholars, who tend to be more litigious in outlook. For example, legal scholarship has detailed the view of how attention could be abused through digital market manipulation (Calo, 2013).
       </p>
       <p>
        Ironically for data-as-labor theorists, the search-engine-as-liberator-of-attention argument could be read as the view that what people get from using search engines is
        <em>
         more time
        </em>
        , or more ability to do other things with their time. In other words, we would use a search engine instead of some other, more laborious discovery mechanism precisely because it would cost us
        <em>
         net negative labor
        </em>
        . That absolutely throws a wrench in any argument that the users of search engines should be rewarded on dignity of labor grounds. Instead, what’s happened is that search engines are ubiquitous because consumers have undergone a phase transition in their willingness to work to discover things, and now very happily use search engines which, on the whole, seem like a pretty good deal! (The cost of being-advertised-to is small compared to the benefits of the search results.)
       </p>
       <p>
        If we start seeing search engines as a compelling labor-saving device rather than a exploiter of laborious clickwork, then some of the disregard consumers have for privacy on search engines becomes more understandable. People are willing to give up their data, even if they would rather not, because search engines are saving them so much time. The privacy harms that come as consequence, then, can be seen as externalities to what is essentially a healthy transaction, rather than a perverse matter of a business model that is evil to the bone.
       </p>
       <p>
        This is, I wager, on the whole a common sense view, one that I’d momentarily forgotten because of my intellectual milieu but now am ashamed to have overlooked. It is, on the whole, far more
        <em>
         optimistic
        </em>
        than other attempt to characterize the zeitgeist of new technology economy.
       </p>
       <p>
        Somehow, this rubric for understanding the digital economy appears to have fallen out of fashion. Davenport and Beck (2001) wrote a business book declaring attention to be “the new currency of business”, which if the prior analysis is correct makes more sense than
        <em>
         data
        </em>
        being the new currency (or oil) of business. The term appears to have originated in an
        <a href="https://journals.uic.edu/ojs/index.php/fm/article/view/519/440">
         article
        </a>
        by Goldhaber (1997). Ironically, the term appears to have had no uptake in the
        <em>
         economics
        </em>
        literature, despite it being the key to everything! The concept was understood, however, by Herbert Simon, in 1971 (see also Terranova, 2012):
       </p>
       <blockquote>
        <p>
         In an information-rich world, the wealth of information means a dearth of something else: a scarcity of whatever it is that information consumes. What information consumes is rather obvious: it consumes the attention of its recipients. Hence a wealth of information creates a poverty of attention and a need to allocate that attention efficiently among the overabundance of information sources that might consume it.
        </p>
       </blockquote>
       <p>
        (A digitized version of this essay, which amazingly appears to be set by a typewriter and then hand-edited (by Simon himself?) can be found
        <a href="https://cosimoaccoto.com/2013/03/09/designing-organizations-for-an-information-rich-world-1969/">
         here
        </a>
        .)
       </p>
       <p>
        This is where I bottom out–the discover that the line of thought I’ve been on all day starts with Herbert Simon, that the sciences of the artificial are not new, they are just forgotten (because of the glut of other information), and exhaustingly hyped. The attention economy discovered by Simon explains why each year we are surrounded with new theories about how to organize ourselves with technology, when perhaps the wisest perspectives on these topics are ones that will not hype themselves because their authors cannot tweet from the grave.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Arrieta-Ibarra, Imanol, et al. “Should We Treat Data as Labor? Moving beyond” Free”.” AEA Papers and Proceedings. Vol. 108. 2018.
       </p>
       <p>
        Brynjolfsson, Erik, and JooHee Oh. “The attention economy: measuring the value of free digital services on the Internet.” (2012).
       </p>
       <p>
        Calo, Ryan. “Digital market manipulation.” Geo. Wash. L. Rev. 82 (2013): 995.
       </p>
       <p>
        Davenport, Thomas H., and John C. Beck. The attention economy: Understanding the new currency of business. Harvard Business Press, 2001.
       </p>
       <p>
        Goldhaber, Michael H. “The attention economy and the net.” First Monday 2.4 (1997).
       </p>
       <p>
        Simon, Herbert A. “Designing organizations for an information-rich world.” (1971): 37-72.
       </p>
       <p>
        Terranova, Tiziana. “Attention, economy and the brain.” Culture Machine 13 (2012).
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/06/data-isnt-labor-because-using-search-engines-is-really-easy/">
        by Sebastian Benthall at December 06, 2018 08:23 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 04, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3616">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/04/the-make-or-buy-decision-tce-in-the-software-and-cybersecurity/">
       the make or buy decision (TCE) in the software and cybersecurity
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        The paradigmatic case of transaction cost economics (TCE) is the
        <em>
         make-or-buy decision
        </em>
        . A firm, F, needs something, C. Do they make it in-house or do they buy it from somewhere else?
       </p>
       <p>
        If the firm makes it in-house, they will incur some bureaucratic overhead costs in addition to the costs of production. But they will also be able to specialize C for their purposes. They can institute their own internal quality controls. And so on.
       </p>
       <p>
        If the firm buys it on the open market from some other firm, say, G, they don’t pay the overhead costs. They do lose the benefits of specialization, and the quality controls are only those based on economic competitive pressure on suppliers.
       </p>
       <p>
        There is an intermediate option, which is a contract between F and G which establishes an ongoing relationship between the two firms. This contract creates a field in which C can be specialized for F, and there can be assurances of quality, while the overhead is distributed efficiently between F and G.
       </p>
       <p>
        This situation is both extremely common in business practice and not well handled by neoclassical, orthodox economics. It’s the case that TCE is tremendously preoccupied with.
       </p>
       <hr/>
       <p>
        My background and research is in the software industry, which is rife with cases like these.
       </p>
       <p>
        Developers are constantly faced with a decision to make-or-buy software components. In principle, they can developer any component themselves. In practice, this is rarely cost-effective.
       </p>
       <p>
        In software, open source software components are a prevalent solution to this problem. This can be thought of as a very strange market where all the prices are zero. The most popular open source libraries are very generic , having little “asset specificity” in TCE terms.
       </p>
       <p>
        The lack of contract between developers and open source components/communities is sometimes seen as a source of hazard in using open source components. The recent
        <a href="http://www.eweek.com/security/node.js-event-stream-hack-exposes-supply-chain-security-risks">
         event-stream
        </a>
        hack, where an upstream component was injected with malicious code by a developer who had taken over maintaining the package, illustrates the problems of outsourcing technical dependencies without a contract. In this case, the quality problem is manifest as a
        <em>
         supply chain cybersecurity problem
        </em>
        .
       </p>
       <p>
        In Williamson’s analysis, these kinds of hazards are what drive firms away from purchasing on spot markets and towards contracting or in-house development. In practice, the role of open source support companies fills the role of being a responsible entity G that firm F can build a relationship with.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/04/the-make-or-buy-decision-tce-in-the-software-and-cybersecurity/">
        by Sebastian Benthall at December 04, 2018 04:51 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 03, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="http://jlzych.com/" title="Jeff Zych">
       Jeff Zych
      </a>
     </div>
     <div class="channel-affiliation">
      MIMS 2012
     </div>
    </div>
    <div class="entrygroup" id="http://jlzych.com/2018/12/03/my-beliefs-about-design/">
     <h4 class="posttitle">
      <a href="http://jlzych.com/2018/12/03/my-beliefs-about-design/">
       My Beliefs About Design
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        <img alt="Trees by Spencer Backman on Unsplash" src="http://jlzych.com/images/2018-12-03-my-beliefs-about-design/trees.jpg?1543874691"/>
        <em>
         Photo by
         <a href="https://unsplash.com/@spencerbackman">
          Spencer Backman
         </a>
         on
         <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">
          Unsplash
         </a>
        </em>
       </p>
       <ul>
        <li>
         Design doesn’t own the customer experience. A great customer experience is the emergent outcome of the contributions of every department.
        </li>
        <li>
         Design is not the center of the universe. Design is one function of many at an organization.
        </li>
        <li>
         Other departments have more customer contact than you. Listen to them.
        </li>
        <li>
         Don’t hand your work down from on high and expect everyone to worship its genius. You need to bring people along for the ride so that they see how you got to your solution, and can get there themselves.
        </li>
        <li>
         Everyone can improve the customer’s experience, not just designers. Foster an environment where everyone applies a user-centered mindset to their work.
        </li>
        <li>
         There’s no perfect, one-size-fits-all design process. Skilled designers have a variety of tools in their tool belt, and know when to use each one.
        </li>
        <li>
         Done is better than perfect.
        </li>
        <li>
         No design is perfect. Always be iterating.
        </li>
        <li>
         Don’t fall in love with your designs. Be willing to kill your darlings.
        </li>
        <li>
         You should always feel a little uncomfortable showing your work to peers. If you don’t, you’ve waited too long.
        </li>
        <li>
         The only thing that matters to customers is what ships. Not your prototypes, wireframes, user journeys, or any other artifact of the design process.
        </li>
        <li>
         The only true measure of your design’s success is the response from customers.
        </li>
        <li>
         Stay curious. Regularly seek out new ideas, experiences, and perspectives.
        </li>
        <li>
         Stay
         <a href="https://www.youtube.com/watch?v=tvTRZJ-4EyI">
          humble
         </a>
         . You don’t know what’s best just because the word “designer” is in your title.
        </li>
        <li>
         Don’t hide behind jargon and the cloak of the “creative.”
        </li>
        <li>
         Great design is rooted in empathy. Empathy not just for the end user, but also for your coworkers, company, and society.
        </li>
        <li>
         Having empathy for your customers means actually talking to them.
        </li>
        <li>
         Don’t automatically ignore someone’s feedback because they’re more junior than you, or don’t have “designer” in their title. Don’t automatically listen to someone’s feedback because they’re more senior than you.
        </li>
        <li>
         Design needs to be aligned to the needs of the business, and deliver measurable business value. Don’t design for design’s sake.
        </li>
       </ul>
      </div>
      <p class="date">
       <a href="http://jlzych.com/2018/12/03/my-beliefs-about-design/">
        by Jeff Zych at December 03, 2018 09:12 PM
       </a>
      </p>
     </div>
    </div>
   </div>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3612">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/03/williamson-on-four-injunctions-for-good-economics/">
       Williamson on four injunctions for good economics
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Williamson (2008) (
        <a href="https://indomarine.webs.com/documents/Handbook%20of%20New%20Institutional%20Economics.pdf#page=49">
         pdf
        </a>
        ) concludes with a description of four injunctions for doing good economics, which I will quote verbatim.
       </p>
       <blockquote>
        <p>
         Robert Solow’s prescription for doing good economics is set out in three injunctions: keep it simple; get it right; make it plausible (2001, p. 111). Keeping it simple entails stripping away the inessentials and going for the main case (the jugular). Getting it right “includes translating economic concepts into accurate
         <br/>
         mathematics (or diagrams, or words) and making sure that further logical operations are correctly performed and verified” (Solow, 2001, p. 112). Making it plausible entails describing human actors in (reasonably) veridical ways and maintaining meaningful contact with the phenomena of interest (contractual or otherwise).
        </p>
        <p>
         To this, moreover, I would add a fourth injunction: derive refutable implications to which the relevant (often microanalytic) data are brought to bear. Nicholas Georgescu-Roegen has a felicitous way of putting it: “The purpose of science in general is not prediction, but knowledge for its own sake,” yet prediction is “the touchstone of scientific knowledge” (1971, p. 37).
        </p>
        <p>
         Why the fourth injunction? This is necessitated by the need to choose among alternative theories that purport to deal with the same phenomenon—say vertical integration—and (more or less) satisfy the first three injunctions. Thus assume that all of the models are tractable, that the logic of each hangs together, and that agreement cannot be reached as to what constitutes veridicality and meaningful contact with the phenomena. Does each candidate theory then have equal claimsfor our attention? Or should we be more demanding? This is where refutable implications and empirical testing come in: ask each would-be theory to stand up and be counted.
        </p>
        <p>
         Why more economists are not insistent upon deriving refutable implications and submitting these to empirical tests is a puzzle. One possibility is that the world of theory is set apart and has a life of its own. A second possibility is that some economists do not agree that refutable implications and testing are
         <br/>
         important. Another is that some theories are truly fanciful and their protagonists would be discomfited by disclosure. A fourth is that the refutable implications of favored theories are contradicted by the data. And perhaps there are still other reasons. Be that as it may, a multiplicity of theories, some of which are
         <br/>
         vacuous and others of which are fanciful, is an embarrassment to the pragmatically oriented members of the tribe. Among this subset, insistence upon the fourth injunction—derive refutable implications and submit these to the data—is growing.
        </p>
       </blockquote>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Williamson, Oliver E. “Transaction cost economics.” Handbook of new institutional economics. Springer, Berlin, Heidelberg, 2008. 41-65.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/03/williamson-on-four-injunctions-for-good-economics/">
        by Sebastian Benthall at December 03, 2018 04:41 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    December 02, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3606">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/12/02/discovering-transaction-cost-economics-tce/">
       Discovering transaction cost economics (TCE)
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I’m in the process of discovering transaction cost economics (TCE), the branch of economics devoted to the study of transaction costs, which include bargaining and search costs. Oliver Williamson, who is a professor at UC Berkeley, won the Nobel Prize for his work on TCE in 2009. I’m starting with the Williamson, 2008 article (in the References) which seems like a late-stage overview of what is a large body of work.
       </p>
       <p>
        Personally, this is yet another time when I’ve discovered that the answers or proper theoretical language for understanding something I am struggling with has simply been Somewhere Else all alone. Delight and frustration are pretty much evening each other out at this point.
       </p>
       <p>
        Why is TCE so critical (to me)?
       </p>
       <ul>
        <li>
         I think the real story about how the Internet and AI have
         <em>
          changed things
         </em>
         , which is the topic constantly reiterated in so many policy and HCI studies about
         <em>
          platforms
         </em>
         , is that they
         <a href="https://digifesto.com/2018/07/30/how-the-internet-changed-everything-a-grand-theory-of-ai-etc/">
          reduced search costs
         </a>
         . However, it’s hard to make the case for that without a respectable theorization of search costs and how they matter to the economy. This, I think, what transaction cost economics are about.
        </li>
        <li>
         You may recall I wrote
         <a href="https://www.ischool.berkeley.edu/research/publications/2018/context-causality-and-information-flow-implications-privacy-engineering">
          my doctoral dissertation
         </a>
         about “data economics” on the presumption (which was, truly, presumptuous) that a proper treatment of the role of data in the economy had not yet been done. This was due mainly to the deficiencies of the discussion of information in neoclassical economic theory. But
         <em>
          perhaps I was a fool
         </em>
         , because it may be that this missing-link work on information economics has been in transaction cost economics all along! Interestingly,
         <a href="https://www.linkedin.com/in/pat-bajari-00a31313/">
          Pat Bajari
         </a>
         , who is Chief Economist at Amazon, has done some TCE work, suggesting that like Hal Varian’s economics, this is stuff that actually works in a business context, which is more or less the epistemic standard you want economics to meet. (I would argue that economics should be seen, foremost, as a discipline of
         <em>
          social engineering
         </em>
         .)
        </li>
        <li>
         A whole other line of research I’ve worked on over the years has been trying to understand the software supply chain, especially with respect to open source software (Benthall 2016; Benthall, 2017). That’s a tricky topic because the idea of “supply” and “chain” in that domain are both highly metaphorical and essentially inaccurate. Yet there are clearly profound questions about the relationships between sociotechnical organizations, their internal and external complexity, and so on to be found there, along with (and this is really what’s exciting about it) ample empirical basis to support arguments about it, just by the nature of it. Well, it turns out that the
         <em>
          paradigmatic case
         </em>
         for transaction cost economics is
         <em>
          vertical integration
         </em>
         , or the “make-or-buy” decision wherein a firm decides to (A) purchase it from an open market, (D) produce something in-house,  or (C) (and this is the case that transaction cost economics really tries to develop) engage with the supplier in a contract which creates an ongoing and secure relationship between them. Labor contracts are all, for reasons that I may go into later, of this (C) kind.
        </li>
       </ul>
       <p>
        So, here comes TCE, with its firm roots in organization theory, Hayekian theories of the market, Coase’s and other theories of the firm, and firm emphasis on the supply chain relation between sociotechnical organizations. And I HAVEN’T STUDIED IT. There is even solid work on its relation to privacy done by Whittington and Hoofnagle (2011; 2013). How did I not know about this? Again, if I were not so delighted, I would be livid.
       </p>
       <p>
        Please expect a long series of posts as I read through the literature on TCE and try to apply it to various cases of interest.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Benthall, S. (2017) Assessing Software Supply Chain Risk Using Public Data. IEEE STC 2017 Software Technology Conference.
       </p>
       <p>
        Benthall, S., Pinney, T., Herz, J., Plummer, K. (2016) An Ecological Approach to Software Supply Chain Risk Management. Proceedings of the 15th Python in Science Conference. p. 136-142. Ed. Sebastian Benthall and Scott Rostrup.
       </p>
       <p>
        Hoofnagle, Chris Jay, and Jan Whittington. “Free: accounting for the costs of the internet’s most popular price.” UCLA L. Rev. 61 (2013): 606.
       </p>
       <p>
        Whittington, Jan, and Chris Jay Hoofnagle. “Unpacking Privacy’s Price.” NCL Rev. 90 (2011): 1327.
       </p>
       <p>
        Williamson, Oliver E. “Transaction cost economics.” Handbook of new institutional economics. Springer, Berlin, Heidelberg, 2008. 41-65.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/12/02/discovering-transaction-cost-economics-tce/">
        by Sebastian Benthall at December 02, 2018 10:31 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 30, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://hoofnagle.berkeley.edu" title="Chris Hoofnagle | UC Berkeley School of Information, School of Law">
       Chris Hoofnagle
      </a>
     </div>
     <div class="channel-affiliation">
      adjunct professor
     </div>
    </div>
    <div class="entrygroup" id="https://hoofnagle.berkeley.edu/?p=11647">
     <h4 class="posttitle" lang="en-US">
      <a href="https://hoofnagle.berkeley.edu/2018/11/30/amsterdam-privacy-conference-2018/">
       Amsterdam Privacy Conference 2018
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <p>
        Opening keynote talk on
        <em>
         The Tethered Economy
        </em>
        , 87(4) Geo. Wash. L. Rev. ___ (2019)(with Aaron Perzanowski and Aniket Kesari),
        <a href="https://www.apc2018.com/">
         Amsterdam Privacy Conference
        </a>
        , Oct. 2018.
       </p>
      </div>
      <p class="date">
       <a href="https://hoofnagle.berkeley.edu/2018/11/30/amsterdam-privacy-conference-2018/">
        by chris at November 30, 2018 05:55 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 29, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3602">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/29/for-fairness-in-machine-learning-we-need-to-consider-the-unfairness-of-racial-categorization/">
       For fairness in machine learning, we need to consider the unfairness of racial categorization
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Pre-prints of
        <a href="https://fatconference.org/2019/acceptedpapers.html">
         papers accepted
        </a>
        to this coming
        <em>
         2019 Fairness, Accountability, and Transparency
        </em>
        conference are floating around Twitter. From the looks of it, many of these papers add a wealth of historical and political context, which I feel is a big
        <a href="https://data-activism.net/2018/04/critical-reflections-on-fat-2018-a-historical-idealist-perspective/">
         improvement
        </a>
        .
       </p>
       <p>
        A noteworthy paper, in this regard, is
        <a href="https://arxiv.org/abs/1811.10104">
         Hutchinson and Mitchell’s “50 Years of Test (Un)fairness: Lessons for Machine Learning”
        </a>
        , which puts recent ‘fairness in machine learning’ work in the context of very analogous debates from the 60’s and 70’s that concerned the use of testing that could be biased due to cultural factors.
       </p>
       <p>
        I like this paper a lot, in part because it is very thorough and in part because it tees up a line of argument that’s dear to me. Hutchinson and Mitchell raise the question of how to properly think about fairness in machine learning when the protected categories invoked by nondiscrimination law are themselves social constructs.
       </p>
       <blockquote>
        <p>
         Some work on practically assessing fairness in ML has tackled the problem of using race as a construct. This echoes concerns in the testing literature that stem back to at least 1966: “one stumbles immediately over the scientific difficulty of establishing clear yardsticks by which people can be classified into convenient racial categories” [30]. Recent approaches have used Fitzpatrick skin type or unsupervised clustering to avoid racial categorizations [7, 55]. We note that the testing literature of the 1960s and 1970s frequently uses the phrase “cultural fairness” when referring to parity between blacks and whites.
        </p>
       </blockquote>
       <p>
        They conclude that this is one of the areas where there can be a lot more useful work:
       </p>
       <blockquote>
        <p>
         This short review of historical connections in fairness suggest several concrete steps forward for future research in ML fairness: Diving more deeply into the question of how subgroups are defined, suggested as early as 1966 [30], including questioning whether subgroups should be treated as discrete categories at all, and how intersectionality can be modeled. This might include, for example, how to quantify fairness along one dimension (e.g., age) conditioned on another dimension (e.g., skin tone), as recent work has begun to address [27, 39].
        </p>
       </blockquote>
       <p>
        This is all very cool to read, because this is precisely the topic that
        <a href="http://sociology.ucdavis.edu/people/bdhaynes">
         Bruce Haynes
        </a>
        and I address in our FAT* paper, “Racial categories in machine learning” (
        <a href="https://128.84.21.199/abs/1811.11668">
         arXiv link
        </a>
        ). The problem we confront in this paper is that the racial categories we are used to using in the United States (White, Black, Asian) originate in the white supremacy that was enshrined into the Constitution when it was formed and perpetuated since then through the legal system (with some countervailing activity during the Civil Rights Movement, for example). This puts “fair machine learning” researchers in a bind: either they can use these categories, which have always been about perpetuating social inequality, or they can ignore the categories and reproduce the patterns of social inequality that prevail
        <em>
         in fact
        </em>
        because of the history of race.
       </p>
       <p>
        In the paper, we propose a third option. First, rather than reify racial categories, we propose breaking race down into the kinds of personal features that get inscribed with racial meaning. Phenotype properties like skin type and ocular folds are one such set of features. Another set are events that indicate position in social class, such as being arrested or receiving welfare. Another set are facts about the national and geographic origin of ones ancestors. These facts about a person are clearly relevant to how racial distinctions are made, but are themselves more granular and multidimensional than race.
       </p>
       <p>
        The next step is to detect race-like categories by looking at who is
        <em>
         segregated
        </em>
        from each other. We propose an unsupervised machine learning technique that works with the distribution of the phenotype, class, and ancestry features across spatial tracts (as in when considering where people physically live) or across a social network (as in when considering people’s professional networks, for example). Principal component analysis can identify what race-like dimensions capture the greatest amounts of spatial and social separation. We hypothesize that these dimensions will encode the ways racial categorization has shaped the social structure in tangible ways; these effects may include both politically recognized forms of discrimination as well as forms of discrimination that have not yet been surfaced. These dimensions can then be used to classify people in race-like ways as input to fairness interventions in machine learning.
       </p>
       <p>
        A key part of our proposal is that race-like classification depends on the empirical distribution of persons in physical and social space, and so are not fixed. This operationalizes the way that race is socially and politically constructed without reifying the categories in terms that reproduce their white supremacist origins.
       </p>
       <p>
        I’m quite stoked about this research, though obviously it raises a lot of serious challenges in terms of validation.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/29/for-fairness-in-machine-learning-we-need-to-consider-the-unfairness-of-racial-categorization/">
        by Sebastian Benthall at November 29, 2018 03:05 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 27, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="http://bcc.npdoty.name/" title="Bcc">
       Nick Doty
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="tag:bcc.npdoty.name,2018-11-27:post:5636027884503040">
     <h4 class="posttitle">
      <a href="http://bcc.npdoty.name/directions-to-migrate-your-WebFaction-site-to-HTTPS">
       directions to migrate your WebFaction site to HTTPS
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        Hiya friends using
        <a href="https://www.webfaction.com/?aid=61750">
         WebFaction
        </a>
        ,
       </p>
       <p>
        Securing the Web, even our little websites, is important — to set a good example, to maintain the confidentiality and integrity of our visitors, to get the best Google search ranking. While secure Web connections had been difficult and/or costly in the past, more recently, migrating a site to HTTPS has become fairly straightforward and costs $0 a year. It may get even easier in the future, but for now, the following steps should do the trick.
       </p>
       <p>
        Hope this helps, and please let me know if you have any issues,
        <br/>
        Nick
       </p>
       <p>
        P.S. Yes, other friends, I recommend WebFaction as a host; I’ve been very happy with them. Services are reasonably priced and easy to use and I can SSH into a server and install stuff.
        <a href="https://www.webfaction.com/?aid=61750">
         Sign up via this affiliate link
        </a>
        and maybe I get a discount on my service or something.
       </p>
       <p>
        P.S. And really, let me know if and when you have issues. Encrypting access to your website has gotten easier, but it needs to become much easier still, and one part of that is knowing which parts of the process prove to be the most cumbersome. I’ll make sure your feedback gets to the appropriate people who can, for realsies, make changes as necessary to standards and implementations.
       </p>
       <p>
        <strong>
         Updated 27 November 2018:
        </strong>
        As of Fall 2018, WebFaction's control panel now handles installing and renewing Let's Encrypt certificates, and that functionality also breaks by default the scripts described below (you'll likely start getting email errors regarding a 404 error in loading
        <code>
         .well-known/acme-challenge
        </code>
        ).
        <strong>
         I recommend using WebFaction's Let's Encrypt support
        </strong>
        ,
        <a href="https://docs.webfaction.com/user-guide/websites.html#secure-sites-https">
         review their simple one-button documentation
        </a>
        . This blog post contains the full documentation in case it still proves useful, but if you want to run these scripts, you'll also want to review
        <a href="https://github.com/will-in-wi/letsencrypt-webfaction/issues/161">
         this issue regarding nginx configuration
        </a>
        .
       </p>
       <p>
        <strong>
         Updated 16 July 2016:
        </strong>
        to fix the cron job command, which may not have always worked depending on environment variables
       </p>
       <p>
        <strong>
         Updated 2 December 2016:
        </strong>
        to use new
        <code>
         letsencrypt-webfaction
        </code>
        design, which uses WebFaction's API and doesn't require emails and waiting for manual certificate installation.
       </p>
       <hr/>
       <p>
        <strike>
         One day soon I hope WebFaction will make more of these steps unnecessary, but the configuring and testing will be something you have to do manually in pretty much any case.
        </strike>
        <a href="https://blog.webfaction.com/2018/09/issue-lets-encrypt-ssl-certificates-with-the-control-panel/">
         WebFaction now supports installing and renewing certificates with Let's Encrypt just by clicking a button in the control panel
        </a>
        ! While the full instructions are still included here, you should mostly only need to follow my directions for
        <strong>
         Create a secure version of your website in the WebFaction Control Panel
        </strong>
        ,
        <strong>
         Test your website over HTTPS
        </strong>
        , and
        <strong>
         Redirect your HTTP site
        </strong>
        . You should be able to complete all of this in an hour some evening.
       </p>
       <p>
        <strong>
         Create a secure version of your website in the WebFaction Control Panel
        </strong>
       </p>
       <p>
        Login to the
        <a href="https://my.webfaction.com/">
         Web Faction Control Panel
        </a>
        , choose the “DOMAINS/WEBSITES” tab and then click “Websites”.
       </p>
       <p>
        “Add new website”, one that will correspond to one of your existing websites. I suggest choosing a name like
        <code>
         existingname-secure
        </code>
        . Choose “Encrypted website (https)”. For Domains, testing will be easiest if you choose both your custom domain and a subdomain of
        <code>
         yourusername.webfactional.com
        </code>
        . (If you don’t have one of those subdomains set up, switch to the Domains tab and add it real quick.) So, for my site, I chose
        <code>
         npdoty.name
        </code>
        and
        <code>
         npdoty.npd.webfactional.com
        </code>
        .
       </p>
       <p>
        Finally, for “Contents”, click “Re-use an existing application” and select whatever application (or multiple applications) you’re currently using for your
        <code>
         http://
        </code>
        site.
       </p>
       <p>
        Click “Save” and this step is done. This shouldn’t affect your existing site one whit.
       </p>
       <p>
        <strong>
         Test to make sure your site works over HTTPS
        </strong>
       </p>
       <p>
        Now you can test how your site works over HTTPS, even before you’ve created any certificates, by going to https://subdomain.yourusername.webfactional.com in your browser. Hopefully everything will load smoothly, but it’s reasonably likely that you’ll have some mixed content issues. The debug console of your browser should show them to you: that’s Apple-Option-K in Firefox or Apple-Option-J in Chrome. You may see some warnings like this, telling you that an image, a stylesheet or a script is being requested over HTTP instead of HTTPS:
       </p>
       <blockquote>
        <p>
         Mixed Content: The page at ‘https://npdoty.name/’ was loaded over HTTPS, but requested an insecure image ‘http://example.com/blah.jpg’. This content should also be served over HTTPS.
        </p>
       </blockquote>
       <p>
        Change these URLs so that they point to
        <code>
         https://example.com/blah.jpg
        </code>
        (you could also use a
        <em>
         scheme-relative
        </em>
        URL, like
        <code>
         //example.com/blah.jpg
        </code>
        ) and update the files on the webserver and re-test.
       </p>
       <p>
        Good job! Now, https://subdomain.yourusername.webfactional.com should work just fine, but https://yourcustomdomain.com shows a really scary message. You need a proper certificate.
       </p>
       <p>
        <strong>
         Get a free certificate for your domain
        </strong>
       </p>
       <p>
        <a href="https://letsencrypt.org/">
         Let’s Encrypt
        </a>
        is a new, free, automated certificate authority from a bunch of wonderful people. But to get it to setup certificates on WebFaction is a little tricky, so we’ll use the
        <a href="https://github.com/will-in-wi/letsencrypt-webfaction">
         <code>
          letsencrypt-webfaction
         </code>
         utility
        </a>
        —- thanks
        <a href="https://github.com/will-in-wi">
         will-in-wi
        </a>
        !
       </p>
       <p>
        SSH into the server with
        <code>
         ssh yourusername@yourusername.webfactional.com
        </code>
        .
       </p>
       <p>
        To install, run this command:
       </p>
       <pre><code>GEM_HOME=$HOME/.letsencrypt_webfaction/gems RUBYLIB=$GEM_HOME/lib gem2.2 install letsencrypt_webfaction
</code></pre>
       <p>
        (Run the same command to upgrade; necesary if you followed these instructions before Fall 2016.)
       </p>
       <p>
        For convenience, you can add this as a function to make it easier to call. Edit
        <code>
         ~/.bash_profile
        </code>
        to include:
       </p>
       <pre><code>function letsencrypt_webfaction {
    PATH=$PATH:$GEM_HOME/bin GEM_HOME=$HOME/.letsencrypt_webfaction/gems RUBYLIB=$GEM_HOME/lib ruby2.2 $HOME/.letsencrypt_webfaction/gems/bin/letsencrypt_webfaction $*
}
</code></pre>
       <p>
        Now, let’s test the certificate creation process. You’ll need your email address, the domain you're getting a certificate for, the path to the files for the root of your website on the server, e.g.
        <code>
         /home/yourusername/webapps/sitename/
        </code>
        and the WebFaction username and password you use to log in. Filling those in as appropriate, run this command:
       </p>
       <pre><code>letsencrypt_webfaction --letsencrypt_account_email you@example.com --domains yourcustomdomain.com --public /home/yourusername/webapps/sitename/ --username webfaction_username --password webfaction_password
</code></pre>
       <p>
        If all went well, you’ll see nothing on the command line. To confirm that the certificate was created successfully, check the
        <a href="https://my.webfaction.com/ssl-certificates">
         SSL certificates tab
        </a>
        on the WebFaction Control Panel. ("Aren't these more properly called TLS certificates?" Yes. So it goes.) You should see a certificate listed that is valid for your domain
        <code>
         yourcustomdomain.com
        </code>
        ; click on it and you can see the expiry date and a bunch of gobblydegook which actually is the contents of the certificate.
       </p>
       <p>
        To actually apply that certificate, head back to the
        <a href="https://my.webfaction.com/websites">
         Websites tab
        </a>
        , select the
        <code>
         -secure
        </code>
        version of your website from the list and in the Security section, choose the certificate you just created from the dropdown menu.
       </p>
       <p>
        <strong>
         Test your website over HTTPS
        </strong>
       </p>
       <p>
        This time you get to test it for real. Load https://yourcustomdomain.com in your browser. (You may need to force refresh to get the new certificate.) Hopefully it loads smoothly and without any mixed content warnings. Congrats, your site is available over HTTPS!
       </p>
       <p>
        <em>
         You are not done.
        </em>
        You might think you are done, but if you think so, you are wrong.
       </p>
       <p>
        <strong>
         Set up automatic renewal of your certificates
        </strong>
       </p>
       <p>
        Certificates from Let’s Encrypt expire in no more than 90 days. (Why?
        <a href="https://letsencrypt.org/2015/11/09/why-90-days.html">
         There are two good reasons
        </a>
        .) Your certificates aren’t truly set up until you’ve set them up to renew automatically. You
        <em>
         do not
        </em>
        want to do this manually every few months; you will forget, I promise.
       </p>
       <p>
        Cron lets us run code on WebFaction’s server automatically on a regular schedule. If you haven’t set up a cron job before, it’s just a fancy way of editing a special text file. Run this command:
       </p>
       <pre><code>EDITOR=nano crontab -e
</code></pre>
       <p>
        If you haven’t done this before, this file will be empty, and you’ll want to test it to see how it works. Paste the following line of code exactly, and then hit Ctrl-O and Ctrl-X to save and exit.
       </p>
       <pre><code>* * * * * echo "cron is running" &gt;&gt; $HOME/logs/user/cron.log 2&gt;&amp;1
</code></pre>
       <p>
        This will output to that log every single minute; not a good cron job to have in general, but a handy test. Wait a few minutes and check
        <code>
         ~/logs/user/cron.log
        </code>
        to make sure it’s working.
       </p>
       <p>
        Rather than including our username and password in our cron job, we'll set up a configuration file with those details. Create a file
        <code>
         config.yml
        </code>
        , perhaps at the location
        <code>
         ~/le_certs
        </code>
        . (If necessary,
        <code>
         mkdir le_certs
        </code>
        ,
        <code>
         touch le_certs/config.yml
        </code>
        ,
        <code>
         nano le_certs/config.yml
        </code>
        .) In this file, paste the following, and then customize with your details:
       </p>
       <pre>letsencrypt_account_email: 'you@example.com'
api_url: 'https://api.webfaction.com/'
username: 'webfaction_username'
password: 'webfaction_password'
</pre>
       <p>
        (Ctrl-O and Ctrl-X to save and close it.) Now, let’s edit the crontab to remove the test line and add the renewal line, being sure to fill in your domain name, the path to your website’s directory, and the path to the configuration file you just created:
       </p>
       <pre><code>0 4 15 */2 * PATH=$PATH:$GEM_HOME/bin GEM_HOME=$HOME/.letsencrypt_webfaction/gems RUBYLIB=$GEM_HOME/lib /usr/local/bin/ruby2.2 $HOME/.letsencrypt_webfaction/gems/bin/letsencrypt_webfaction --domains example.com --public /home/yourusername/webapps/sitename/ --config /home/yourusername/le_certs/config.yml &gt;&gt; $HOME/logs/user/cron.log 2&gt;&amp;1
</code></pre>
       <p>
        You’ll probably want to create the line in a text editor on your computer and then copy and paste it to make sure you get all the substitutions right. Paths must be fully specified as the above; don't use
        <code>
         ~
        </code>
        for your home directory. Ctrl-O and Ctrl-X to save and close it. Check with
        <code>
         crontab -l
        </code>
        that it looks correct. As a test to make sure the config file setup is correct, you can run the command part directly; if it works, you shouldn't see any error messages on the command line. (Copy and paste the line below, making the the same substitutions as you just did for the crontab.)
       </p>
       <pre><code>PATH=$PATH:$GEM_HOME/bin GEM_HOME=$HOME/.letsencrypt_webfaction/gems RUBYLIB=$GEM_HOME/lib /usr/local/bin/ruby2.2 $HOME/.letsencrypt_webfaction/gems/bin/letsencrypt_webfaction --domains example.com --public /home/yourusername/webapps/sitename/ --config /home/yourusername/le_certs/config.yml
</code></pre>
       <p>
        With that cron job configured, you'll automatically get a new certificate at 4am on the 15th of alternating months (January, March, May, July, September, November). New certificates every two months is fine, though one day in the future we might change this to get a new certificate every few days; before then WebFaction will have taken over the renewal process anyway. Debugging cron jobs can be tricky (I've had to update the command in this post once already); I recommend adding an alert to your calendar for the day after the first time this renewal is supposed to happen, to remind yourself to confirm that it worked. If it didn't work, any error messages should be stored in the
        <code>
         cron.log
        </code>
        file.
       </p>
       <p>
        <strong>
         Redirect your HTTP site
        </strong>
        <em>
         (optional, but recommended)
        </em>
       </p>
       <p>
        Now you’re serving your website in parallel via
        <code>
         http://
        </code>
        and
        <code>
         https://
        </code>
        . You can keep doing that for a while, but everyone who follows old links to the HTTP site won’t get the added security, so it’s best to start permanently re-directing the HTTP version to HTTPS.
       </p>
       <p>
        <a href="https://docs.webfaction.com/software/static.html#static-redirecting-from-http-to-https">
         WebFaction has very good documentation on how to do this
        </a>
        , and I won’t duplicate it all here. In short, you’ll create a new static application named “redirect”, which just has a
        <code>
         .htaccess
        </code>
        file with, for example, the following:
       </p>
       <pre><code>RewriteEngine On
RewriteCond %{HTTP_HOST} ^www\.(.*)$ [NC]
RewriteRule ^(.*)$ https://%1/$1 [R=301,L]
RewriteCond %{HTTP:X-Forwarded-SSL} !on
RewriteRule ^(.*)$ https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L]
</code></pre>
       <p>
        This particular variation will both redirect any URLs that have
        <code>
         www
        </code>
        to the “naked” domain and make all requests HTTPS. And in the Control Panel, make the redirect application the only one on the HTTP version of your site. You can re-use the “redirect” application for different domains.
       </p>
       <p>
        Test to make sure it’s working! http://yourcustomdomain.com, http://www.yourcustomdomain.com, https://www.yourcustomdomain.com and https://yourcustomdomain.com should all end up at https://yourcustomdomain.com. (You may need to force refresh a couple of times.)
       </p>
      </div>
      <p class="date">
       <a href="http://bcc.npdoty.name/directions-to-migrate-your-WebFaction-site-to-HTTPS">
        by nick@npdoty.name at November 27, 2018 09:01 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 26, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3600">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/25/is-competition-good-for-cybersecurity/">
       Is competition good for cybersecurity?
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        A question that keeps coming up in various forms, but for example in response to
        <a href="https://www.ft.com/content/6ea0f440-ee0b-11e8-89c8-d36339d835c0">
         recent events
        </a>
        around the ‘trade war’ between the U.S. and China and its impact on technology companies, is whether or not market competition is good or bad for cyber-security.
       </p>
       <p>
        Here is a simple argument for why competition could be
        <em>
         good
        </em>
        for cyber-security: The security of technical products is a positive quality of them, something that consumers would like. Market competition is what gets producers to make higher quality products at lower cost. Therefore, competition is good for security.
       </p>
       <p>
        Here is an argument for why competition could be
        <em>
         bad
        </em>
        for cyber-security: Security is a hard thing for any consumer to understand; since most won’t, we have an information asymmetry here and therefore a ‘market for lemons’ kind of market failure. Therefore, competition is bad for security. It would be better to have a well-regulated monopoly.
       </p>
       <p>
        This argument echoes, though it doesn’t exactly parallel, some of the arguments in Pasquale’s
        <a href="https://digifesto.com/2018/05/27/notes-on-pasquale-tech-platforms-and-the-knowledge-problem-2018/">
         work on Hamiltonian’s and Jeffersonian’s in technology platform regulation
        </a>
        .
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/25/is-competition-good-for-cybersecurity/">
        by Sebastian Benthall at November 26, 2018 12:36 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 18, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3598">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/18/the-privatization-of-public-functions/">
       “the privatization of public functions”
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        An emerging theme from the conference on
        <a href="https://digifesto.com/2018/11/16/trade-secrecy-an-fda-for-algorithms-a-software-bills-of-materials-sbom-secretalgos/">
         Trade Secrets and Algorithmic System
        </a>
        s was that legal scholars have become concerned about the
        <em>
         privatization of public functions
        </em>
        . For example, the use of proprietary risk assessment tools instead of the discretion of judges who are supposed to be publicly accountable is
        <em>
         a problem
        </em>
        . More generally, use of “trade secrecy” in court settings to prevent inquiry into software systems is bogus and moves more societal control into the realm of private ordering.
       </p>
       <p>
        Many remedies were proposed. Most involved some kind of disclosure and audit to experts. The most extreme form of disclosure is making the software and, where it’s a matter of public record, training data publicly available.
       </p>
       <p>
        It is striking to me to be encountering the call for government use of open source systems because…this is not a new issue. The conversation about
        <a href="https://digifesto.com/2012/07/24/why-federally-funded-software-should-be-open-source/">
         federal use of open source software
        </a>
        was alive and well over five years ago. Then, the arguments were about vendor lock-in; now, they are about accountability of AI. But the essential problem of whether core governing logic should be available to public scrutiny, and the effects of its privatization, have been the same.
       </p>
       <p>
        If we are concerned with the reliability of a closed and large-scale decision-making process of any kind, we are dealing with problems of
        <a href="https://digifesto.com/2018/11/15/the-crevasse-a-meditation-on-accountability-of-firms-in-the-face-of-opacity-as-the-complexity-of-scale/">
         credibility, opacity, and complexity
        </a>
        . The prospects of
        <a href="https://digifesto.com/2018/11/16/the-paradox-of-data-markets/">
         an efficient market
        </a>
        for these kinds of systems are dim. These market conditions are
        <a href="https://digifesto.com/2018/11/15/open-source-sustainability-and-autonomy-revisited/">
         the conditions of sustainability
        </a>
        of open source infrastructure. Failures in sustainability are
        <a href="http://www.govtech.com/pcio/articles/Growth-in-Open-Source-Leaves-Government-Exposed-to-Vulnerabilities.html">
         manifest as software vulnerabilities
        </a>
        , which are one of the key reasons why governments are warned against OSS now, though the process of measurement and evaluation of OSS software vulnerability versus proprietary vulnerabilities is methodologically highly fraught.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/18/the-privatization-of-public-functions/">
        by Sebastian Benthall at November 18, 2018 05:25 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 16, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3595">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/16/trade-secrecy-an-fda-for-algorithms-a-software-bills-of-materials-sbom-secretalgos/">
       Trade secrecy, “an FDA for algorithms”, a software bills of materials (SBOM) #SecretAlgos
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        At the
        <em>
         <a href="http://www.law.nyu.edu/centers/ili/events/trade-secrets">
          Conference on Trade Secrets and Algorithmic Systems
         </a>
        </em>
        at NYU today, the target of most critiques is the use of
        <em>
         trade secrecy
        </em>
        by proprietary technology providers to prevent courts and the public from seeing the inner workings of
        <em>
         algorithms
        </em>
        that determine people’s credit scores, health care, criminal sentencing, and so on. The overarching theme is that sometimes companies will use trade secrecy to hide the ways that their software is bad, and that that is a problem.
       </p>
       <p>
        In one panel, the question of whether an “FDA for Algorithms” is on the table–referring the Food and Drug Administration’s approval of pharmaceuticals. It was not dealt with in too much depth, which is too bad, because it is a nice example of how government oversight of potentially dangerous technology is managed in a way that respects trade secrecy.
       </p>
       <p>
        According to
        <a href="https://www.fdli.org/2018/04/update-protecting-trade-secrets-medical-product-approval-process/">
         this article
        </a>
        , when filing for FDA approval, a company can declare some of their ingredients to be trade secrets. The upshot of that is that those trade secrets are not subject to FOIA requests. However, these ingredients are still considered when approval is granted by the FDA.
       </p>
       <p>
        It so happens that in the
        <em>
         cybersecurity policy
        </em>
        conversation (more so than in
        <em>
         privacy
        </em>
        ) the question of openness of “ingredients” to inspection has been coming up in a serious way. NTIA has been hosting multistakeholder meetings about standards and policy around
        <a href="https://www.ntia.doc.gov/SoftwareTransparency">
         Software Component Transparency
        </a>
        . In particular they are encouraging standardizations of
        <a href="https://en.wikipedia.org/wiki/Software_bill_of_materials">
         Software Bills of Materials
        </a>
        (SBOM) like the Linux Foundation’s
        <a href="https://spdx.org/">
         Software Package Data Exchange (SPDX)
        </a>
        . SPDX (and SBOM’s more generally) describe the “ingredients” in a software package at a higher level of resolution than exposing the full source code, but at a level specific enough useful for security audits.
       </p>
       <p>
        It’s possible that a similar method could be used for algorithmic audits with fairness (i.e., nondiscrimination compliance) and privacy (i.e., information sharing to third-parties) in mind. Particular components could be audited (perhaps in a way that protects trade secrecy), and then those components could be listed as “ingredients” by other vendors.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/16/trade-secrecy-an-fda-for-algorithms-a-software-bills-of-materials-sbom-secretalgos/">
        by Sebastian Benthall at November 16, 2018 08:56 PM
       </a>
      </p>
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3593">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/16/the-paradox-of-data-markets/">
       The paradox of ‘data markets’
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        We often hear that companies are “selling out data”, or that we are “paying for services” with our data. Data brokers
        <em>
         literally
        </em>
        buy and sell data about people. There are other forms of expensive data sources or data sets. There is, undoubtedly, one or more data markets.
       </p>
       <p>
        We know that classically, perfect competition in markets depends on perfect information. Buyers and sellers on the market need to have equal and instantaneous access to information about utility curves and prices in order for the market to price things efficiently.
       </p>
       <p>
        Since the bread and butter of the data market is information asymmetry, we know that data markets can never be perfectly competitive. If it was, the data market would cease to exist, because the perfect information condition would entail that there is nothing to buy and sell.
       </p>
       <p>
        Data markets therefore
        <em>
         have
        </em>
        to be imperfectly competitive. But since these are the markets that perfect information in other markets might depend on, this imperfection is viral. The vicissitudes of the data market are the vicissitudes of the economy in general.
       </p>
       <p>
        The upshot is that the challenges of information economics are not only those that appear in special sectors like insurance markets. They are at the heart of all economic activity, and there are no equilibrium guarantees.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/16/the-paradox-of-data-markets/">
        by Sebastian Benthall at November 16, 2018 04:50 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 15, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://ctsp.berkeley.edu" title="CTSP">
       Citizen Technologist
      </a>
     </div>
     <div class="channel-affiliation">
      Center for Technology, Society &amp; Policy
     </div>
    </div>
    <div class="entrygroup" id="https://ctsp.berkeley.edu/?p=1893">
     <h4 class="posttitle" lang="en-US">
      <a href="https://ctsp.berkeley.edu/using-crowdsourcing-to-address-disparities-in-police-reported-data-addressing-challenges-in-technology-and-community-engagement/">
       Using Crowdsourcing to address Disparities in Police Reported Data: Addressing Challenges in Technology and Community Engagement
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <p>
        <em>
         This is a project update from a CTSP project from 2017:
         <a href="https://ctsp.berkeley.edu/projects2017/#safetydatacollection">
          Assessing Race and Income Disparities in Crowdsourced Safety Data Collection
         </a>
         (with
         <a href="https://ctsp.berkeley.edu/people2017#kate">
          Kate Beck
         </a>
         ,
         <a href="https://ctsp.berkeley.edu/people2017#aditya">
          Aditya Medury
         </a>
         , and
         <a href="https://ctsp.berkeley.edu/people2017#jesus">
          Jesus M. Barajas
         </a>
         )
        </em>
       </p>
       <p>
        <strong>
         Project Update
        </strong>
       </p>
       <p>
        This work has led to the development of
        <a href="http://streetstory.berkeley.edu">
         Street Story
        </a>
        , a community engagement tool that collects street safety information from the public, through UC Berkeley SafeTREC.
       </p>
       <p>
        The tool collects qualitative and quantitative information, and then creates maps and tables that can be publicly viewed and downloaded. The Street Story program aims to collect information that can create a fuller picture of transportation safety issues, and make community-provided information publicly accessible.
       </p>
       <p>
        <img alt="" class="aligncenter size-full wp-image-1905" height="458" src="https://ctsp.berkeley.edu/files/2018/11/Picture1.png" width="899"/>
        <img alt="" class="aligncenter size-full wp-image-1904" height="520" src="https://ctsp.berkeley.edu/files/2018/11/Picture2.png" width="899"/>
       </p>
       <p>
       </p>
       <p>
        <strong>
         The Problem
        </strong>
       </p>
       <p>
        <img alt="" class="size-full wp-image-1901 alignleft" height="206" src="https://ctsp.berkeley.edu/files/2018/11/Picture5.png" width="310"/>
       </p>
       <p>
        Low-income groups, people with disabilities, seniors and racial minorities are at higher risk of being injured while walking and biking, but experts have limited information on what these groups need to reduce these disparities. Transportation agencies typically rely on statistics about transportation crashes aggregated from police reports to decide where to make safety improvements. However, police-reported data is limited in a number of ways. First, crashes involving pedestrians or cyclists are significantly under-reported to police, with reports finding that up to 60% of pedestrian and bicycle crashes go unreported. Second, some demographic groups, including low-income groups, people of color and undocumented immigrants, have histories of contentious relationships with police. Therefore, they may be less likely to report crashes to the police when they do occur. Third, crash data doesn’t include locations where near–misses have happened, or locations where individuals feel unsafe but an issue has not yet happened. In other words, the data allow professionals to react to safety issues, but don’t necessarily allow them to be proactive about them.
       </p>
       <p style="text-align: left;">
        One solution to improve and augment the data agencies use to make decisions and allocate resources is to provide a way for people to report transportation safety issues themselves. Some public agencies and private firms are developing apps and websites whether people can report issues for this purpose. But one concern is that the people who are likely to use these crowdsourcing platforms are those who have access to smart phones or the internet and who trust that government agencies with use the data to make changes, biasing the data toward the needs of these privileged groups.
       </p>
       <p>
        <strong>
         Our Initial Research Plan
        </strong>
       </p>
       <p>
        <img alt="" class="size-large wp-image-1902 alignleft" height="204" src="https://ctsp.berkeley.edu/files/2018/11/Picture4.png" width="306"/>
       </p>
       <p>
        We chose to examine whether crowdsourced traffic safety data reflected similar patterns of underreporting and potential bias as police-reported safety data. To do this, we created an online mapping tool that people could use to report traffic crashes, near-misses and general safety issues. We planned to work with a city to release this tool to and collected data from the general public, then work directly with a historically marginalized community, under-represented in police-reported data, to target data collection in a high-need neighborhood. We planned to reduce barriers to entry for this community, including meeting the participants in person to explain the tool, providing them with in-person and online training, providing participants with cell phones, and compensating their data plans for the month. By crowdsourcing data from the general public and from this specific community, we planned to analyze whether there were any differences in the types of information reported by different demographics.
       </p>
       <p>
        This plan seemed to work well with the research question and with community engagement best practices. However, we came up against a number of challenges with our research plan. Although many municipal agencies and community organizations found the work we were doing interesting and were working to address similar transportation safety issues we were focusing on, many organizations and agencies seemed daunted by the prospect of using technology to address underlying issues of under-reporting. Finally, we found that a year was not enough time to build trusting relationships with the organizations and agencies we had hoped to work with. Nevertheless, we were able to release a web-based mapping tool to collect some crowdsourced safety data from the public.
       </p>
       <p>
        <strong>
         Changing our Research Plan
        </strong>
       </p>
       <p>
        <img alt="" class="size-large wp-image-1903 alignleft" height="208" src="https://ctsp.berkeley.edu/files/2018/11/Picture3.png" width="279"/>
       </p>
       <p>
        To better understand how more well-integrated digital crowdsourcing platforms perform, we pivoted our research project to explore how different neighborhoods engage with government platforms to report non-emergency service needs. We assumed some of these non-emergency services would mirror the negative perceptions of bicycle and pedestrian safety we were interested in collecting via our crowdsourcing safety platform. The City of Oakland relies on SeeClickFix, a smartphone app, to allow residents to request service for several types of issues: infrastructure issues, such as potholes, damaged sidewalks, or malfunctioning traffic signals; and non-infrastructure issues such as illegal dumping or graffiti. The city also provides phone, web, and email-based platforms for reporting the same types of service requests. These alternative platforms are collectively known as 311 services. We looked at 45,744 SeeClickFix-reports and 35,271 311-reports made between January 2013 and May 2016. We classified Oakland neighborhoods by status as community of concern. In the city of Oakland, 69 neighborhoods meet the definition for communities of concern, while 43 do not. Because we did not have data on the characteristics of each person reporting a service request, we made the assumption that people reporting requests also lived in the neighborhood where the request was needed.
       </p>
       <p>
        How did communities of concern interact with the SeeClickFix and 311 platforms to report service needs? Our analysis highlighted two main takeaways. First, we found that communities of concern were more engaged in reporting than other communities, but had different reporting dynamics based on the type of issue they were reporting. About 70 percent of service issues came from communities of concern, even though they represent only about 60 percent of the communities in Oakland. They were nearly twice as likely to use SeeClickFix than to report via the 311 platforms overall, but only for non-infrastructure issues. Second, we found that even though communities of concern were more engaged, the level of engagement was not equal for everyone in those communities. For example, neighborhoods with higher proportions of limited-English proficient households were less likely to report any type of incident by 311 or SeeClickFix.
       </p>
       <p>
        <strong>
         Preliminary Findings from Crowdsourcing Transportation Safety Data
        </strong>
       </p>
       <p>
        We deployed the online tool in August 2017. The crowdsourcing platform was aimed at collecting transportation safety-related concerns pertaining to pedestrian and bicycle crashes, near misses, perceptions of safety, and incidents of crime while walking and bicycling in the Bay Area. We disseminated the link to the crowdsourcing platform primarily through Twitter and some email lists. . Examples of organizations who were contacted through Twitter-based outreach and also subsequently interacted with the tweet (through likes and retweets) include
        <em>
         Transform Oakland
        </em>
        ,
        <em>
         Silicon Valley Bike Coalition
        </em>
        ,
        <em>
         Walk Bike Livermore
        </em>
        ,
        <em>
         California Walks
        </em>
        ,
        <em>
         Streetsblog CA
        </em>
        , and
        <em>
         Oakland Built
        </em>
        . By December 2017, we had received 290 responses from 105 respondents. Half of the responses corresponded to perceptions of traffic safety concerns (“I feel unsafe walking/cycling here”), while 34% corresponded to near misses (“I almost got into a crash but avoided it”). In comparison, 12% of responses reported an actual pedestrian or bicycle crash, and 4% of incidents reported a crime while walking or bicycling. The sample size of the responses is too small to report any statistical differences.
       </p>
       <p>
        Figure 1 shows the spatial patterns of the responses in the Bay Area aggregated to census tracts. Most of the responses were concentrated in Oakland and Berkeley. Oakland was specifically targeted as part of the outreach efforts since it has significant income and racial/ethnic diversity.
       </p>
       <p>
        <img alt="Figure 1 Spatial Distribution of the Crowdsourcing Survey Responses" class="aligncenter wp-image-1894 size-full" height="710" src="https://ctsp.berkeley.edu/files/2018/11/Figure1.png" width="550"/>
       </p>
       <p style="text-align: center;">
        <strong>
         Figure 1 Spatial Distribution of the Crowdsourcing Survey Responses
        </strong>
       </p>
       <p>
       </p>
       <p>
        In order to assess the disparities in the crowdsourced data collection, we compared responses between census tracts that are classified as communities of concern or not. A community of concern (COC), as defined by the Metropolitan Transportation Commission, a regional planning agency, is a census tract that ranks highly on several markers of marginalization, including proportion of racial minorities, low-income households, limited-English speakers, and households without vehicles, among others.
       </p>
       <p>
        Table 1 shows the comparison between the census tracts that received at least one crowdsourcing survey response. The average number of responses received in COCs versus non-COCs across the entire Bay Area were similar and statistically indistinguishable. However, when focusing on Oakland-based tracts, the results reveal that average number of crowdsourced responses in non-COCs were statistically higher. To assess how the trends of self-reported pedestrian/cyclist concerns compare with police-reported crashes, an assessment of pedestrian and bicycle-related police-reported crashes (from 2013-2016) shows that more police-reported pedestrian/bicycle crashes were observed on an average in COCs across the Bay Area as well as in Oakland. The difference in trends observed in the crowdsourced concerns and police-reported crashes suggest that either walking/cycling concerns are greater in non-COCs (thus underrepresented in police crashes), or that participation from among COCs is relatively underrepresented.
       </p>
       <p style="text-align: center;">
        <strong>
         Table 1 Comparison of crowdsourced concerns and police-reported pedestrian/bicycle crashes in census tracts that received at least 1 response
        </strong>
       </p>
       <p>
        <img alt="Table 1 Comparison of crowdsourced concerns and police-reported pedestrian/bicycle crashes in census tracts that received at least 1 response" class="wp-image-1898 size-large aligncenter" height="315" src="https://ctsp.berkeley.edu/files/2018/11/Table1-1024x315.png" width="1024"/>
       </p>
       <p>
        Table 2 compares the self-reported income and race/ethnicity characteristics of the respondents with the locations where the responses were reported. For reference purposes, Bay Area’s median household income in 2015 was estimated to be $85,000 (Source:
        <a href="http://www.vitalsigns.mtc.ca.gov/income">
         http://www.vitalsigns.mtc.ca.gov/income
        </a>
        ), and Bay Area’s population was estimated to be 58% White, per the 2010 Census, (Source:
        <a href="http://www.bayareacensus.ca.gov/bayarea.htm">
         http://www.bayareacensus.ca.gov/bayarea.htm
        </a>
        ).
       </p>
       <p style="text-align: center;">
        <strong>
         Table 2 Distribution of all Bay Area responses based on the location of response and the self-reported income and race/ethnicity of respondents
        </strong>
       </p>
       <p>
        <img alt="" class="aligncenter size-large wp-image-1900" height="406" src="https://ctsp.berkeley.edu/files/2018/11/Table2-1024x406.png" width="1024"/>
       </p>
       <p>
        The results reveal that White, medium-to-high income respondents were observed to report more walking/cycling -related safety issues in our survey, and more so in non-COCs. This trend is also consistent with the definition of COCs, which tend to have a higher representation of low-income people and people of color. However, if digital crowdsourcing without widespread community outreach is more likely to attract responses from medium-to-high income groups, and more importantly, if they only live, work, or play in a small portion of the region being investigated, the aggregated results will reflect a biased picture of a region’s transportation safety concerns. Thus, while the scalability of digital crowdsourcing provides an opportunity for capturing underrepresented transportation concerns, it may require greater collaboration with low-income, diverse neighborhoods to ensure uniform adoption of the platform.
       </p>
       <p>
        <strong>
         Lessons Learned
        </strong>
       </p>
       <p>
        From our attempts to work directly with community groups and agencies and our subsequent decision to change our research focus, we learned a number of lessons:
       </p>
       <ol>
        <li>
         <strong>
          Develop a research plan in partnership with communities and agencies.
         </strong>
         This would have allowed us to ensure that we began with a research plan in which community groups and agencies were better able to partner with us on, and this would have ensured that the partners were on board the topic of interest and the methods we hoped to use.
        </li>
        <li>
         <strong>
          Recognize the time it takes to build relationships.
         </strong>
         We found that building relationships with agencies and communities was more time intensive and took longer that we had hoped. These groups often have limitations on the time they can dedicate to unfunded projects. Next time, we should plan for this in our initial research plan.
        </li>
        <li>
         <strong>
          Use existing data sources to supplement research.
         </strong>
         We found that using See-Click-Fix and 311 data was a way to collect and analyze information to add context to our research question. Although the data did not have all demographic information we had hoped to analyze, this data source added additional context to the data we collected.
        </li>
        <li>
         <strong>
          Speak in a language that the general public understands.
         </strong>
         We found that when we used the term self-reporting, rather than crowdsourcing, when talking to potential partners and to members of the public, these individuals were more willing to consider the use of technology to collect information on safety issues from the public as legitimate. Using vocabulary and phrasing that people are familiar with is crucial when attempting to use technology to benefit the social good.
        </li>
       </ol>
      </div>
      <p class="date">
       <a href="https://ctsp.berkeley.edu/using-crowdsourcing-to-address-disparities-in-police-reported-data-addressing-challenges-in-technology-and-community-engagement/">
        by Daniel Griffin at November 15, 2018 05:44 PM
       </a>
      </p>
     </div>
    </div>
   </div>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3591">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/15/the-crevasse-a-meditation-on-accountability-of-firms-in-the-face-of-opacity-as-the-complexity-of-scale/">
       The Crevasse: a meditation on accountability of firms in the face of opacity as the complexity of scale
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        To recap:
       </p>
       <p>
        (A1) Beneath corporate secrecy and user technical illiteracy, a fundamental source of opacity in “algorithms” and “machine learning” is the complexity of scale, especially scale of data inputs. (Burrell, 2016)
       </p>
       <p>
        (A2) The opacity of the operation of companies using consumer data makes those consumers unable to engage with them as informed market actors. The consequence has been a “free fall” of market failure (Strandburg, 2013).
       </p>
       <p>
        (A3) Ironically, this “free” fall has been “free” (zero price) for consumers; they appear to get something for nothing without knowing what has been given up or changed as a consequence (Hoofnagle and Whittington, 2013).
       </p>
       <p>
        Comments:
       </p>
       <p>
        (B1) The above line of argument conflates “algorithms”, “machine learning”, “data”, and “tech companies”, as is common in the broad discourse. That this conflation is possible speaks to the ignorance of the scholarly position on these topics, and ignorance that is implied by corporate secrecy, technical illiteracy, and complexity of scale simultaneously. We can, if we choose, distinguish between these factors analytically. But because, from the standpoint of the discourse, the internals are unknown, the general indication of a ‘black box’ organization is intuitively compelling.
       </p>
       <p>
        (B1a) Giving in to the lazy conflation is an error because it prevents informed and effective praxis. If we do not distinguish between a corporate entity and its multiple internal human departments and technical subsystems, then we may
        <a href="https://data-activism.net/2018/04/critical-reflections-on-fat-2018-a-historical-idealist-perspective/">
         confuse ourselves
        </a>
        into thinking that a
        <em>
         fair and interpretable algorithm
        </em>
        can give us a
        <em>
         fair and interpretable tech company
        </em>
        . Nothing about the former guarantees the latter because tech companies operate in a larger operational field.
       </p>
       <p>
        (B2) The
        <em>
         opacity as the complexity of scale
        </em>
        , a property of the functioning of machine learning algorithms, is
        <em>
         also
        </em>
        a property of the functioning of sociotechnical organizations more broadly. Universities, for example, are often opaque to themselves, because of their own internal complexity and scale. This is because the mathematics governing opacity as a function of complexity and scale are the same in both technical and sociotechnical systems (Benthall, 2016).
       </p>
       <p>
        (B3) If we discuss the
        <em>
         complexity of firms
        </em>
        , as opposed the the complexity of algorithms, we should conclude that firms that are complex due to scale of operations and data inputs (including number of customers) will be opaque and therefore have strategic advantage in the market against less complex market actors (consumers) with stiffer bounds on rationality.
       </p>
       <p>
        (B4) In other words, big, complex, data rich firms will be smarter than individual consumers and outmaneuver them in the market. That’s not just “tech companies”. It’s part of the MO of every firm to do this. Corporate entities are “artificial general intelligences” and they compete in a complex ecosystem in which consumers are a small and vulnerable part.
       </p>
       <p>
        Twist:
       </p>
       <p>
        (C1) Another source of opacity in data is that the meaning of data come from the causal context that generates it. (Benthall, 2018)
       </p>
       <p>
        (C2)  Learning causal structure from observational data is hard, both in terms of being data-intensive and being computationally complex (NP). (c.f. Friedman et al., 1998)
       </p>
       <p>
        (C3) Internal complexity, for a firm, is not sufficient to be “all-knowing” about the data that is coming it; the  firm has epistemic challenges of secrecy, illiteracy, and scale with respect to
        <em>
         external
        </em>
        complexity.
       </p>
       <p>
        (C4) This is why many applications of machine learning are overrated and so many “AI” products kind of suck.
       </p>
       <p>
        (C5) There is, in fact, an epistemic crevasse between all autonomous entities, each containing its own complexity and constituting a larger ecological field that is the external/being/environment for any other autonomy.
       </p>
       <p>
        To do:
       </p>
       <p>
        The most promising direction based on this analysis is a deeper read into transaction cost economics as a ‘theory of the firm’. This is where the formalization of the idea that
        <a href="https://digifesto.com/2018/07/30/how-the-internet-changed-everything-a-grand-theory-of-ai-etc/">
         what the Internet changed most are search costs
        </a>
        (a kind of transaction cost) should be.
       </p>
       <p>
        It would be nice if those insights could be expressed in the mathematics of “AI”.
       </p>
       <p>
        There’s still a deep idea in here that I haven’t yet found the articulation for, something to do with autopoeisis.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Benthall, Sebastian. (2016) The Human is the Data Science. Workshop on Developing a Research Agenda for Human-Centered Data Science. Computer Supported Cooperative Work 2016. (
        <a href="https://cscw2016hcds.files.wordpress.com/2015/10/benthall_hcds2016.pdf">
         link
        </a>
        )
       </p>
       <p>
        Sebastian Benthall. Context, Causality, and Information Flow: Implications for Privacy Engineering, Security, and Data Economics. Ph.D. dissertation. Advisors: John Chuang and Deirdre Mulligan. University of California, Berkeley. 2018.
       </p>
       <p>
        Burrell, Jenna. “How the machine ‘thinks’: Understanding opacity in machine learning algorithms.” Big Data &amp; Society 3.1 (2016): 2053951715622512.
       </p>
       <p>
        Friedman, Nir, Kevin Murphy, and Stuart Russell. “Learning the structure of dynamic probabilistic networks.” Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence. Morgan Kaufmann Publishers Inc., 1998.
       </p>
       <p>
        Hoofnagle, Chris Jay, and Jan Whittington. “Free: accounting for the costs of the internet’s most popular price.” UCLA L. Rev. 61 (2013): 606.
       </p>
       <p>
        Strandburg, Katherine J. “Free fall: The online market’s consumer preference disconnect.” U. Chi. Legal F. (2013): 95.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/15/the-crevasse-a-meditation-on-accountability-of-firms-in-the-face-of-opacity-as-the-complexity-of-scale/">
        by Sebastian Benthall at November 15, 2018 04:10 PM
       </a>
      </p>
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3589">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/15/open-source-sustainability-and-autonomy-revisited/">
       open source sustainability and autonomy, revisited
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Some recent chats with
        <a href="https://twitter.com/choldgraf/status/1062024417935417346">
         Chris Holdgraf
        </a>
        and colleagues at NYU interested in “critical digital infrastracture” have gotten me thinking again about the sustainability and autonomy of open source projects again.
       </p>
       <p>
        I’ll admit to having had naive views about this topic in the past. Certainly, doing empirical data science work on open source software projects has given me a firmer perspective on things. Here are what I feel are the hardest earned insights on the matter:
       </p>
       <ul>
        <li>
         There is tremendous heterogeneity in open source software projects. Almost all quantitative features of these projects fall in log-normal distributions. This suggests that the keys to open source software success are myriad and exogenous (how the technology fits in the larger ecosystem, how outside funding and recognition is accomplished, …) rather than endogenous factors (community policies, etc.) While many open source projects start as hobby and unpaid academic projects, those that go on to be successful find one or more funding sources. This funding is an exogenous factor.
        </li>
        <li>
         The most significant exogenous factors to an open source software project’s success are the industrial organization of private tech companies. Developing an open technology is part of the strategic repertoire of these companies: for example, to undermine the position of a monopolist, developing an open source alternative decreases barriers to market entry and allows for a more competitive field in that sector. Another example: Google funded Mozilla for so long arguably to deflect antitrust action over Google Chrome.
        </li>
        <li>
         There is some truth to Chris Kelty’s idea of open source communities as
         <em>
          recursive publics
         </em>
         , cultures that have autonomy that can assert political independence at the boundaries of other political forces. This autonomy comes from: the way developers of OSS get specific and valuable human capital in the process of working with the software and their communities; the way institutions begin to depend on OSS as part of their technical stack, creating an installed base; and how many different institutions may support the same project, creating competition for the scarce human capital of the developers. Essentially, at the point where the software and the skills needed to deploy it effectively and the community of people with those skills is self-organized, the OSS community has gained some economic and political autonomy. Often this autonomy will manifest itself in some kind of formal organization, whether a foundation, a non-profit, or a company like Redhat or Canonical or Enthought. If the community is large and diverse enough it may have multiple organizations supporting it. This is in principle good for the autonomy of the project but may also reflect political tensions that can lead to a schism or fork.
        </li>
        <li>
         In general, since OSS development is internally most often very fluid, with the primary regulatory mechanism being the fork, the shape of OSS communities is more determined by exogenous factors than endogenous ones. When exogenous demand for the technology rises, the OSS community can find itself with a ‘surplus’, which can be channeled into autonomous operations.
        </li>
       </ul>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/15/open-source-sustainability-and-autonomy-revisited/">
        by Sebastian Benthall at November 15, 2018 02:45 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 13, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="http://jlzych.com/" title="Jeff Zych">
       Jeff Zych
      </a>
     </div>
     <div class="channel-affiliation">
      MIMS 2012
     </div>
    </div>
    <div class="entrygroup" id="http://jlzych.com/2018/11/12/how-to-write-effective-advertisements-according-to-david-ogilvy/">
     <h4 class="posttitle">
      <a href="http://jlzych.com/2018/11/12/how-to-write-effective-advertisements-according-to-david-ogilvy/">
       How to Write Effective Advertisements, according to David Ogilvy
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        David Ogilvy is known as the “Father of Advertising.” He earned that moniker by pioneering the use of research to come up with effective ads and measure their impact. This was decades before the internet and the deluge of data we have available to us now. I can only imagine how much more potent he would be today.
       </p>
       <p>
        He breaks down his methods in his book
        <a href="https://www.amazon.com/Ogilvy-Advertising-David/dp/039472903X/ref=sr_1_1?ie=UTF8&amp;qid=1542089363&amp;sr=8-1&amp;keywords=ogilvy+on+advertising">
         <em>
          Ogivly on Advertising
         </em>
        </a>
        , which is just as relevant today as it was when it was written in 1983. Since I’ve found his techniques useful, I’m publishing my notes here so I can easily refer back to them and share them.
       </p>
       <h2 id="how-to-write-headlines-that-sell">
        How to Write Headlines That Sell
       </h2>
       <p>
        Headlines are the most important part of your advertisements. According to research done by Ogilvy, “five times as many people read the headlines as read the body copy. It follows that unless your headline sells your product, you have wasted 90 per cent of your money.”
       </p>
       <ul>
        <li>
         Promise a benefit. Make sure the benefit is important to your customer. For example, “whiter wash, more miles per gallon, freedom from pimples, fewer cavities.”
         <ul>
          <li>
           Make it persuasive, and make it unique. Persuasive headlines that aren’t unique, which your competitors can claim, aren’t effective.
          </li>
         </ul>
        </li>
        <li>
         Make it specific. Use percentages, time elapsed, dollars saved.
        </li>
        <li>
         Personalize it to your audience, such as the city they’re in.
         <em>
          (Or the words in their search query)
         </em>
        </li>
        <li>
         Include the brand and product name.
        </li>
        <li>
         Make it as long or as short as it needs to be. Ogilvy’s research found that, “headlines with more than ten words get less readership than short headlines. On the other hand, a study of retail advertisements found that headlines of ten words sell more merchandise than short headlines. Conclusion: if you need a long headline, go ahead and write one, and if you want a short headline, that’s all right too.”
        </li>
        <li>
         Make it clear and to the point, not clever or tricky.
        </li>
        <li>
         Don’t use superlatives like, “Our product is the best in the world.” Market researcher George Gallup calls this “Brag and Boast.” They convince nobody.
        </li>
       </ul>
       <h3 id="ideas-for-headlines">
        Ideas for Headlines
       </h3>
       <ul>
        <li>
         Headlines that contain news are surefire. The news can be announcing a new product, or a new way to use an existing product. “And don’t scorn tried-and-true words like
         <em>
          amazing
         </em>
         ,
         <em>
          introducing
         </em>
         ,
         <em>
          now
         </em>
         ,
         <em>
          suddenly
         </em>
         .”
        </li>
        <li>
         Include information that’s useful to the reader, provided the information involves your product.
        </li>
        <li>
         Try including a quote, such as from an expert or customers.
        </li>
       </ul>
       <h2 id="how-to-write-persuasive-body-copy">
        How to Write Persuasive Body Copy
       </h2>
       <p>
        According to Ogilvy, body copy is seldom read by more than 10% of people. But the 10% who read it are prospects. What you say determines the success of your ad, so it’s worth spending the time to get it right.
       </p>
       <ul>
        <li>
         Address readers directly, as if you are speaking to them. "One human being to another, second person singular.”
        </li>
        <li>
         Write short sentences and short paragraphs. Avoid complicated words. Use plain, everyday language.
        </li>
        <li>
         Don’t write long-winded, philosophical essays. “Tell your reader what your product will do for him or her, and tell it with specifics.”
        </li>
        <li>
         Write your copy in the form of a story. The headline can be a hook.
        </li>
        <li>
         Avoid analogies. People often misunderstand them.
        </li>
        <li>
         Just like with headlines, stay away from superlatives like, “Our product is the best in the world.”
        </li>
        <li>
         Use testimonials from customers or experts (also known as “social proof”). Avoid celebrity testimonials. Most people forget the product and remember the celebrity. Further, people assume the celebrity has been bought, which is usually true.
        </li>
        <li>
         Coupons and special offers work.
        </li>
        <li>
         Always include the price of your products. “You may see a necklace in a jeweler’s window, but you don’t consider buying it because the price is not shown and you are too shy to go in and ask. It is the same way with advertisements. When the price of the product is left out, people have a way of turning the page.”
        </li>
        <li>
         Long copy sells more than short. “I believe, without any research to support me, that advertisements with long copy convey the impression that you have something important to say, whether people read the copy or not.”
        </li>
        <li>
         Stick to the facts about what your product is and can do.
        </li>
        <li>
         Make the first paragraph a grabber to draw people into reading your copy.
        </li>
        <li>
         Sub-headlines make copy more readable and scannable.
        </li>
        <li>
         People often skip from the headline to the coupon to see the offer, so make the coupons mini-ads, complete with brand name, promise, and a mini photo of the product.
        </li>
        <li>
         To keep prospects on the hook, try “limited edition,” “limited supply,” “last time at this price,” or “special price for promptness.”
        </li>
       </ul>
       <h2 id="suggestions-for-images">
        Suggestions for Images
       </h2>
       <p>
        After headlines, images are the most important part of advertisements. They draw people in. Here’s what makes imagery effective:
       </p>
       <ul>
        <li>
         The best images arouse the viewer’s curiosity. They look at it and ask, “What’s going on here?” This leads them to read the copy to find out. This is called “Story Appeal.”
        </li>
        <li>
         If you don’t have a good story to tell, make your product the subject.
        </li>
        <li>
         Show the end result of using your product. Before-and-after photographs are highly effective.
        </li>
        <li>
         Photographs attract more readers, are more believable, and better remembered than illustrations.
        </li>
        <li>
         Human faces that are larger than life size repel readers. Don’t use them.
        </li>
        <li>
         Historical subjects bore people.
        </li>
        <li>
         If your picture includes people, it’s most effective if it uses people your audience can identify with. Doctors if you’re trying to sell to doctors, men if you’re trying to appeal to men, and so on.
        </li>
        <li>
         Include captions under your photographs. More people read captions than body copy, so make the caption a mini-advertisement.
        </li>
       </ul>
       <h2 id="layout">
        Layout
       </h2>
       <ul>
        <li>
         KISS – Keep It Simple, Stupid.
        </li>
        <li>
         “Readers look first at the illustration, then at the headline, then at the copy. So put these elements in that order.” This also follows the normal order of scanning.
        </li>
        <li>
         More people read captions of images than body copy, so always include a caption under it. Captions should be mini-advertisements, so include the brand name and promise.
        </li>
       </ul>
       <h2 id="a-few-more-tips-for-effective-ads">
        A Few More Tips for Effective Ads
       </h2>
       <p>
        These are some other principles I picked up from the book, which can be useful in many different types of ads.
       </p>
       <ul>
        <li>
         Demonstrations of how well your product works are effective. Try coming up with a demonstration that your reader can perform.
        </li>
        <li>
         Don’t name competitors. The ad is less believable and more confusing. People often think the competitor is the hero.
        </li>
        <li>
         Problem-solution is a tried-and-true ad technique.
        </li>
        <li>
         Give people a reason
         <em>
          why
         </em>
         they should buy.
        </li>
        <li>
         Emotion can be highly effective. Nostalgia, charm, sentimentality, etc. Consumers need a rational excuse to justify their emotional decisions.
        </li>
        <li>
         Cartoons don’t sell well to adults.
        </li>
        <li>
         The most successful products and services are differentiated from their competitors. This is most effective if you can differentiate via low cost or highest quality. A differentiator doesn’t need to be relevant to the product’s performance, however, to be effective. For example, Owens-Corning differentiated their insulation by advertising the color of the product, which has nothing to do with how the product performs.
        </li>
       </ul>
       <hr/>
       <p>
        Ogilvy’s principles are surprisingly evergreen, despite the technological changes. Towards the end of the book he quotes Bill Bernbach, another advertising giant, on why this is:
       </p>
       <blockquote>
        <p>
         Human nature hasn’t changed for a billion years. It won’t even vary in the next billion years. Only the superficial things have changed. It is fashionable to talk about changing man. A communicator must be concerned with unchanging man – what compulsions drive him, what instincts dominate his every action, even though his language too often camouflages what really motivates him. For if you know these things about a man, you can touch him at the core of his being. One thing is unchangingly sure. The creative man with an insight into human nature, with the artistry to touch and move people, will succeed. Without them he will fail.
        </p>
       </blockquote>
       <p>
        Human nature hasn’t changed much, indeed.
       </p>
       <hr/>
       <p>
        Get the book here:
        <a href="https://www.amazon.com/Ogilvy-Advertising-David/dp/039472903X/ref=sr_1_1?ie=UTF8&amp;qid=1542089363&amp;sr=8-1&amp;keywords=ogilvy+on+advertising">
         <em>
          Ogivly on Advertising
         </em>
        </a>
       </p>
      </div>
      <p class="date">
       <a href="http://jlzych.com/2018/11/12/how-to-write-effective-advertisements-according-to-david-ogilvy/">
        by Jeff Zych at November 13, 2018 06:07 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 12, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3587">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/12/what-proportion-of-data-protection-violations-are-due-to-dark-data-flows/">
       What proportion of data protection violations are due to “dark data” flows?
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        “Data protection” refers to the aspect of privacy that is concerned with the use and misuse of personal data by those that process it. Though widely debated, scholars continue to converge (
        <a href="https://tlpc.colorado.edu/tlpc-files-privacy-law-scholar-comments-in-ntia-consumer-privacy-proceeding/">
         e.g.
        </a>
        ) on ideal data protection consisting of alignment between the purposes the data processor will use the data for and the expectations of the user, along with collection limitations that reduce exposure to misuse. Through its extraterritorial enforcement mechanism, the GDPR has threatened to make these standards global.
       </p>
       <p>
        The implication of these trends is that there will be a global field of data flows regulated by these kinds of rules. Many of the large and important actors that process user data can be held accountable to the law. Privacy violations by these actors will be due to a failure to act within the bounds of the law that applies to them.
       </p>
       <p>
        On the other hand, there is also
        <em>
         cybercrime
        </em>
        , an economy of data theft and information flows that exists “outside the law”.
       </p>
       <p>
        I wonder what proportion of data protection violations are due to
        <em>
         dark data flows
        </em>
        –flows of personal data that are handled by organizations operating outside of any effective regulation.
       </p>
       <p>
        I’m trying to draw an analogy to a global phenomenon that I know little about but which strikes me as perhaps more pressing than data protection: the interrelated problems of
        <a href="https://en.wikipedia.org/wiki/Money_laundering">
         money laundering
        </a>
        ,
        <a href="https://en.wikipedia.org/wiki/Panama_Papers">
         off-shore finance
        </a>
        , and
        <a href="https://en.wikipedia.org/wiki/Dark_money">
         dark money
        </a>
        contributions to election campaigns. While surely oversimplifying the issue, my impression is that the network of financial flows can be divided into those that are more and less regulated by effective global law. Wealth seeks out these opportunities in the dark corners.
       </p>
       <p>
        How much personal data flows in these dark networks? And how much is it responsible for privacy violations around the world? Versus how much is data protection effectively in the domain of accountable organizations (that may just make mistakes here and there)? Or is the dichotomy false, with truly no firm boundary between licit and illicit data flow networks?
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/12/what-proportion-of-data-protection-violations-are-due-to-dark-data-flows/">
        by Sebastian Benthall at November 12, 2018 01:37 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 11, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://bytegeist.wordpress.com" title="The Bytegeist">
       Richmond Wong
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://bytegeist.wordpress.com/?p=457">
     <h4 class="posttitle" lang="en">
      <a href="https://bytegeist.wordpress.com/2018/11/11/eliciting-values-reflections-by-engaging-privacy-futures-using-design-workbooks-talk/">
       Eliciting Values Reflections by Engaging Privacy Futures Using Design Workbooks [Talk]
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        <em>
         This blog post is a version of a talk I gave at the 2018
         <a href="http://cscw.acm.org/2018/">
          ACM Computer Supported Cooperative Work and Social Computing (CSCW) Conference
         </a>
         based on a paper written with Deirdre Mulligan, Ellen Van Wyk, John Chuang, and James Pierce, entitled
         <a href="https://dl.acm.org/citation.cfm?id=3134746">
          Eliciting Values Reflections by Engaging Privacy Futures Using Design Workbooks
         </a>
         , which was honored with a best paper award. Find out more on our
         <a href="http://biosense.berkeley.edu/portfolio/science-fiction-and-design-fiction-to-elicit-values-in-sensing-technologies/">
          project page
         </a>
         , our
         <a href="https://medium.com/acm-cscw/engaging-technologists-to-reflect-on-privacy-using-design-workbooks-a6a78411ecaa">
          summary blog post
         </a>
         , or download the paper:
         <a href="https://escholarship.org/uc/item/78c2802k">
          [PDF link]
         </a>
         <a href="https://dl.acm.org/citation.cfm?id=3134746">
          [ACM link]
         </a>
        </em>
       </p>
       <p>
        In the work described in our paper, we created a set of conceptual speculative designs to explore privacy issues around emerging biosensing technologies, technologies that sense human bodies. We then used these designs to help elicit discussions about privacy with students training to be technologists. We argue that this approach can be useful for Values in Design and Privacy by Design research and practice.
       </p>
       <p>
        <span id="more-457">
        </span>
       </p>
       <div class="wp-caption alignnone" id="attachment_257" style="width: 844px;">
        <img alt="dhs slide" class="alignnone size-full wp-image-257" src="https://bytegeist.files.wordpress.com/2017/06/dhs-slide.png?w=730"/>
        <p class="wp-caption-text">
         Image from
         <a href="https://publicintelligence.net/dhs-future-attribute-screening-technology-mobile-module-fast-m2-overview/">
          publicintelligence.net
         </a>
         . Note the middle bullet point in the middle column – “avoids all privacy issues.”
        </p>
       </div>
       <p>
        Let me start with a motivating example, which I’ve discussed in
        <a href="https://bytegeist.wordpress.com/2017/06/15/using-design-fiction-and-science-fiction-to-interrogate-privacy-sensing-technologies/">
         previous talks
        </a>
        . In 2007, the US Department of Homeland Security proposed a program to try to predict criminal behavior in advance of the crime itself –using thermal sensing, computer vision, eye tracking, gait sensing, and other physiological signals. And supposedly it would “avoid all privacy issues.” But it seems pretty clear that privacy was not fully thought through in this project. Now Homeland Security projects actually do go through privacy impact assessments and I would guess that in this case, they would probably go through the impact assessment process, find that the system doesn’t
        <em>
         store
        </em>
        the biosensed data, so privacy is protected. But while this might  address one conception of privacy related to storing data, there are other conceptions of privacy at play. There are still questions here about consent and movement in public space, about data use and collection, or about fairness and privacy from algorithmic bias.
       </p>
       <p>
        While that particular imagined future hasn’t come to fruition; a lot of these types of sensors are now becoming available as consumer devices, used in applications ranging from health and quantified self, to interpersonal interactions, to tracking and monitoring. And it often seems like privacy isn’t fully thought through before new sensing devices and services are publicly announced or released.
       </p>
       <p>
        A lot of existing privacy approaches, like privacy impact assessments, are deductive, checklist-based, or assume that privacy problems already known and well-defined in advance which often isn’t the case. Furthermore, the term “design” in discussions of Privacy by Design, is often seen as a way of providing solutions to problems identified by law, rather than viewing design as a generative set of practices useful to understanding what privacy issues might need to be considered in the first place. We argue that speculative design-inspired approaches can help explore and define problem spaces of privacy in inductive, situated, and contextual ways.
       </p>
       <h1>
        Design and Research Approach
       </h1>
       <p>
        We created a design workbook of speculative designs.
        <a href="https://doi.org/10.1145/1978942.1979169">
         Workbooks
        </a>
        are collections of conceptual designs drawn together to allow designers to explore and reflect on a design space.
        <a href="https://mitpress.mit.edu/books/speculative-everything">
         Speculative design
        </a>
        is a practice of using design to ask social questions, by creating conceptual designs or artifacts that help create or suggest a fictional world. We can create
        <a href="https://link.springer.com/chapter/10.1007/978-3-319-73374-6_10">
         speculative designs
        </a>
        explore different configurations of the world, imagine and understand possible alternative futures, which helps us think through issues that have relevance in the present. So rather than start with trying to find design solutions for privacy, we wanted to use design workbooks and speculative designs together to create a collection of designs to help us explore the what problem space of privacy might look like with emerging biosensing technologies.
       </p>
       <div class="wp-caption alignnone" id="attachment_263" style="width: 1209px;">
        <img alt="workbook pages" class="alignnone size-full wp-image-263" src="https://bytegeist.files.wordpress.com/2017/06/workbook-pages.png?w=730"/>
        <p class="wp-caption-text">
         A sampling of the conceptual designs we created as part of our design workbook
        </p>
       </div>
       <p>
        In our
        <a href="https://bytegeist.wordpress.com/2017/06/15/using-design-fiction-and-science-fiction-to-interrogate-privacy-sensing-technologies/">
         prior work
        </a>
        , we created a design workbook to do this exploration and reflection. Inspired by recent research, science fiction, and trends from the technology industry, we created a couple dozen fictional products, interfaces, and webpages of biosensing technologies. These included smart camera enabled neighborhood watch systems, advanced surveillance systems, implantable tracking devices, and non-contact remote sensors that detect people’s heartrates. This process is documented in a
        <a href="https://doi.org/10.1145/3064663.3064682">
         paper from Designing Interactive Systems
        </a>
        . These were created as part of a self-reflective exercise, for us as design researchers to explore the problem space of privacy. However, we wanted to know how non-researchers, particularly technology practitioners might discuss privacy in relation to these conceptual designs.
       </p>
       <p>
        A note on how we’re approaching privacy and values.
        <strong>
        </strong>
        Following other
        <a href="https://doi.org/10.1162/DESI_a_00354">
         values in design
        </a>
        work and privacy research, we want to
        <a href="https://doi.org/10.1145/1518701.1518875">
         avoid providing a single universalizing definition
        </a>
        of privacy as a social value. We recognize
        <a href="https://doi.org/10.1098/rsta.2016.0118">
         privacy as inherently multiple
        </a>
        – something that is situated and differs within different contexts and situations.
       </p>
       <p>
        Our goal was to use our workbook as a way to elicit values reflections and discussion about privacy from our participants – rather than looking for “stakeholder values” to generate design requirements for privacy solutions. In other words, we were interested in how technologists-in-training would use privacy and other values to make sense of the designs.
       </p>
       <p>
        Growing regulatory calls for “Privacy by Design” suggest that privacy should be embedded into all aspects of the design process, and at least partially done by designers and engineers. Because of this, the ability for technology professionals to surface, discuss, and address privacy and related values is vital. We wanted to know how people training for those jobs might use privacy to discuss their reactions to these designs. We conducted an interview study, recruiting 10 graduate students from a West Coast US University who are training to go into technology professions, most of whom had prior tech industry experience via prior jobs or internships. At the start of the interview, we gave them a physical copy of the designs and explained that the designs were conceptual, but didn’t tell them that the designs were initially made to think about privacy issues. In the following slides, I’ll show a few examples of the speculative design concepts we showed – you can see more of them in the paper. And then I’ll discuss the ways in which participants used values to make sense of or react to some of the designs.
       </p>
       <h1>
        Design examples
       </h1>
       <p>
       </p>
       <a href="https://bytegeist.wordpress.com/2018/11/11/eliciting-values-reflections-by-engaging-privacy-futures-using-design-workbooks-talk/airport-1/">
        <img alt="" class="attachment-thumbnail size-thumbnail" height="96" src="https://bytegeist.files.wordpress.com/2018/11/airport-1.png?w=150&amp;h=96" width="150"/>
       </a>
       <a href="https://bytegeist.wordpress.com/2018/11/11/eliciting-values-reflections-by-engaging-privacy-futures-using-design-workbooks-talk/airport-2/">
        <img alt="" class="attachment-thumbnail size-thumbnail" height="100" src="https://bytegeist.files.wordpress.com/2018/11/airport-2.png?w=150&amp;h=100" width="150"/>
       </a>
       <a href="https://bytegeist.wordpress.com/2018/11/11/eliciting-values-reflections-by-engaging-privacy-futures-using-design-workbooks-talk/airport-3/">
        <img alt="" class="attachment-thumbnail size-thumbnail" height="106" src="https://bytegeist.files.wordpress.com/2018/11/airport-3.png?w=150&amp;h=106" width="150"/>
       </a>
       <p>
        <strong>
        </strong>
        This design depicts an imagined surveillance system for public spaces like airports that automatically assigns threat statuses to people by color-coding them. We intentionally left it ambiguous how the design makes its color-coding determinations to try to invite questions about how the system classifies people.
       </p>
       <div class="wp-caption alignnone" id="attachment_262" style="width: 739px;">
        <img alt="truwork" class="alignnone size-full wp-image-262" src="https://bytegeist.files.wordpress.com/2017/06/truwork.png?w=730"/>
        <p class="wp-caption-text">
         Conceptual TruWork design – “An integrated solution for your office or workplace!”
        </p>
       </div>
       <p>
        In our designs, we also began to iterate on ideas relating to tracking implants, and different types of social contexts they could be used in. Here’s a scenario advertising a workplace implantable tracking device called TruWork. Employers can subscribe to the service and make their employees implant these devices to keep track of their whereabouts and work activities to improve efficiency.
       </p>
       <div class="wp-caption alignnone" id="attachment_462" style="width: 2427px;">
        <img alt="coupletrack3" class="alignnone size-full wp-image-462" src="https://bytegeist.files.wordpress.com/2018/11/coupletrack3.png?w=730"/>
        <p class="wp-caption-text">
         Conceptual CoupleTrack infographic depicting an implantable tracking chip for couples
        </p>
       </div>
       <p>
        We also re-imagined the implant as “coupletrack,” an implantable tracking chip for couples to use, as shown in this infographic.
       </p>
       <h1>
        Findings
       </h1>
       <p>
        We found that participants centered values in their discussions when looking at the designs – predominantly privacy, but also related values such as trust, fairness, security, and due process. We found eight themes of how participants interacted with the designs in ways that surfaced discussion of values, but I’ll highlight three here: Imagining the designs as real; seeing one’s self as multiple users; and seeing one’s self as a technology professional. The rest are discussed in more detail in the paper.
       </p>
       <h2>
        Imagining the Designs as Real
       </h2>
       <div class="wp-caption alignnone" id="attachment_461" style="width: 2570px;">
        <img alt="peta-cam-2" class="alignnone size-full wp-image-461" src="https://bytegeist.files.wordpress.com/2018/11/peta-cam-2.png?w=730"/>
        <p class="wp-caption-text">
         Conceptual product page for a small, hidden, wearable camera
        </p>
       </div>
       <p>
        Even though participants were aware that the designs were imagined, Some participants imagined the designs as seemingly real by thinking about long term effects in the fictional world of the design. This design (pictured above) is an easily hideable, wearable, live streaming HD camera. One participant imagined what could happen to social norms if these became widely adopted, saying “
        <em>
         If anyone can do it, then the definition of wrong-doing would be questioned, would be scrutinized
        </em>
        .” He suggests that previously unmonitored activities would become open for surveillance and tracking like “
        <em>
         are the nannies picking up my children at the right time or not? The definition of wrong-doing will be challenged
        </em>
        ”. Participants became actively involved fleshing out and creating the worlds in which these designs might exist. This reflection is also interesting, because it begins to consider some secondary implications of widespread adoption, highlighting potential changes in social norms with increasing data collection.
       </p>
       <h2>
        Seeing One’s Self as Multiple Users
       </h2>
       <p>
        Second, participants took multiple user subject positions in relation to the designs. One participant read the webpage for TruWork and laughed at the design’s claim to create a “happier, more efficient workplace,” saying, “
        <em>
         This is again, positioned to the person who would be doing the tracking, not the person who would be tracked
        </em>
        .”  She notes that the website is really aimed at the employer. She then imagines herself as an employee using the system, saying:
       </p>
       <blockquote>
        <p>
         If I called in sick to work, it shouldn’t actually matter if I’m really sick. […] There’s lots of reasons why I might not wanna say, “This is why I’m not coming to work.” The idea that someone can check up on what I said—it’s not fair.
        </p>
       </blockquote>
       <p>
        This participant put herself in both the viewpoint of an employer using the system and as an employee using the system, bringing up issues of workplace surveillance and fairness. This allowed participants to see values implications of the designs from different subject positions or stakeholder viewpoints.
       </p>
       <h2>
        Seeing One’s Self as a Technology Professional
       </h2>
       <p>
        Third, participants also looked at the designs through the lens of being a technology practitioner, relating the designs to their own professional practices. Looking at the design that automatically flags and detects supposedly suspicious people, one participant reflected on his self-identification as a data scientist and the values implications of predicting criminal behavior with data when he said:
       </p>
       <blockquote>
        <p>
         the creepy thing, the bad thing is, like—and I am a data scientist, so it’s probably bad for me too, but—the data science is predicting, like Minority Report… [and then half-jokingly says] …Basically, you don’t hire data scientists.
        </p>
       </blockquote>
       <p>
        Here he began to reflect on how his practices as data scientist might be implicated in this product’s creepiness – that a his initial propensity to want to use the data to predict if subjects are criminals or not might not be a good way to approach this problem and have implications for due process.
       </p>
       <p>
        Another participant compared the CoupleTrack design to a project he was working on. He said:
       </p>
       <blockquote>
        <p>
         [CoupleTrack] is very similar to our idea. […] except ours is not embedded in your skin. It’s like an IOT charm which people [in relationships] carry around. […] It’s voluntary, and that makes all the difference. You can choose to keep it or not to keep it.
        </p>
       </blockquote>
       <p>
        In comparing the fictional CoupleTrack product to the product he’s working on in his own technical practice, the value of consent, and how one might revoke consent, became very clear to this participant. Again, we thought it was compelling that the designs led some participants to begin reflecting on the privacy implications in their own technical practices.
       </p>
       <h1>
        Reflections and Takeaways
       </h1>
       <p>
        Given the workbooks’ ability to help elicit reflections on and discussion of privacy in multiple ways, we see this approach as useful for future Values in Design and Privacy by Design work.
       </p>
       <p>
        The speculative workbooks helped open up discussions about values, similar to some of what Katie Shilton identifies as “
        <a href="https://doi.org/10.1177/0162243912436985">
         values levers
        </a>
        ,” activities that foreground values, and cause them to be viewed as relevant and useful to design. Participants’ seeing themselves as users to reflect on privacy harms is similar to prior work showing how self-testing can lead to discussion of values. Participants looking at the designs from multiple subject positions evokes
        <a href="http://dx.doi.org/10.1561/1100000015">
         value sensitive design’s
        </a>
        foregrounding of multiple stakeholder perspectives. Participants reflected on the designs both from stakeholder subject positions and through the lenses of their professional practices as technology practitioners in training.
       </p>
       <p>
        While Shilton identifies a range of people who might surface values discussions, we see the workbook as an actor to help surface values discussions. By depicting some provocative designs that raised some visceral and affective reactions, the workbooks brought attention to questions about potential sociotechnical configurations of biosensing technologies. Future values in design work might consider creating and sharing speculative design workbooks for eliciting values reflections with experts and technology practitioners.
       </p>
       <p>
        More specifically, with this project’s focus on privacy, we think that this approach might be useful for “Privacy by Design”, particularly for technologists trying to surface discussions about the nature of the privacy problem at play for an emerging technology. We analyzed participants’ responses using Mulligan et al’s
        <a href="http://rsta.royalsocietypublishing.org/content/374/2083/20160118">
         privacy analytic framework
        </a>
        . The paper discusses this in more detail, but the important thing is that participants went beyond just saying privacy and other values are important to think about. They began to grapple with specific, situated, and contextual aspects of privacy – such as considering different ways to consent to data collection, or noting different types of harms that might emerge when the same technology is used in a workplace setting compared to an intimate relationship. Privacy professionals are looking for tools to help them “
        <a href="https://scholarship.law.berkeley.edu/facpubs/1305/">
         look around corners
        </a>
        ,” to help understand what new types of problems related to privacy might occur in emerging technologies and contexts. This provides a potential new tool for privacy professionals in addition to many of the current top-down, checklist approaches–which assume that the concepts of privacy at play are well known in advance.
        <strong>
         Speculative design practices can be particularly useful here – not to predict the future, but in helping to open and explore the space of possibilities.
        </strong>
       </p>
       <p>
        Thank you to my collaborators, our participants, and the anonymous reviewers.
       </p>
       <p>
        <strong>
         Paper citation:
        </strong>
        Richmond Y. Wong, Deirdre K. Mulligan, Ellen Van Wyk, James Pierce, and John Chuang. 2017. Eliciting Values Reflections by Engaging Privacy Futures Using Design Workbooks.
        <em>
         Proc. ACM Hum.-Comput. Interact. 1
        </em>
        , CSCW, Article 111 (December 2017), 26 pages. DOI:
        <a href="https://doi.org/10.1145/3134746">
         https://doi.org/10.1145/3134746
        </a>
       </p>
      </div>
      <p class="date">
       <a href="https://bytegeist.wordpress.com/2018/11/11/eliciting-values-reflections-by-engaging-privacy-futures-using-design-workbooks-talk/">
        by Richmond at November 11, 2018 11:06 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    November 07, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3582">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/11/07/the-resilience-of-agonistic-control-centers-of-global-trade/">
       the resilience of agonistic control centers of global trade
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        This post is merely notes; I’m fairly confident that I don’t know what I’m writing about. However, I want to learn more. Please recommend anything that could fill me in about this! I owe most of this to discussion with a colleague who I’m not sure would like to be acknowledged.
       </p>
       <p>
        Following the logic of James
        <a href="https://digifesto.com/tag/beniger/">
         Beniger
        </a>
        , an increasingly integrated global economy requires more points of information integration and control.
       </p>
       <p>
        Bourgeois (in the sense of ‘capitalist’) legal institutions exist precisely for the purpose of arbitrating between merchants.
       </p>
       <p>
        Hence, on the one hand we would expect international trade law to be Habermasian. However, international trade need not rest on a foundation of German idealism (which increasingly strikes me as the core of European law). Rather, it is an evolved mechanism.
       </p>
       <p>
        A key part of this mechanism, as I’ve heard, is that it is decentered. Multiple countries compete to be the sites of transnational arbitration, much like multiple nations compete to be tax havens. Sovereignty and discretion are factors of production in the economy of control.
       </p>
       <p>
        This means, effectively, that one cannot defeat capitalism by chopping off its head. It is rather much more like a hydra: the “heads” are the creation of two-sided markets. These heads have no internalized sense of the public good. Rather, they are optimized to be attractive to the transnational corporations in bilateral negotiation. The plaintiffs and defendants in these cases are corporations and states–social forms and institutions of complexity far beyond that of any individual person. This is where, so to speak, the AI’s clash.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/11/07/the-resilience-of-agonistic-control-centers-of-global-trade/">
        by Sebastian Benthall at November 07, 2018 01:38 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    October 31, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://stuartgeiger.com/" title="R. Stuart Geiger">
       Stuart Geiger
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="https://stuartgeiger.com/posts/2018/10/best-practices-team-challenges">
     <h4 class="posttitle">
      <a href="https://stuartgeiger.com/posts/2018/10/best-practices-team-challenges">
       Best Practices Team Challenges
      </a>
     </h4>
     <div class="entry">
      <div class="content">
       <p>
        <em>
         By Stuart Geiger and Dan Sholler, based on a conversation with Aaron Culich, Ciera Martinez, Fernando Hoces, Francois Lanusse, Kellie Ottoboni, Marla Stuart, Maryam Vareth, Sara Stoudt, and Stéfan van der Walt. This post first appeared on the
         <a href="https://bids.berkeley.edu/news/challenges-doing-data-intensive-research-teams-and-groups">
          BIDS Blog
         </a>
         .
        </em>
       </p>
       <p>
        This post is a summary of the first BIDS Best Practices lunch, in which we bring people together from across the Berkeley campus and beyond to discuss a particular challenge or issue in doing data-intensive research. The goal of the series is to informally share experiences and ideas on how to do data science well (or at least better) from many disciplines and contexts. The topic for this week was doing data-intensive research in teams, labs, and other groups. For this first meeting, we focused on just identifying and diagnosing the many different kinds of challenges. In future meetings, we will dive deeper into some of these specific issues and try to identify best practices for dealing with them.
       </p>
       <p>
        We began planning for this series by reviewing many of the published papers and series around “best practices” in scientific computing (e.g.
        <a href="https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745">
         Wilson et al, 2014
        </a>
        ), “good enough practices” (
        <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005510">
         Wilson et al, 2017
        </a>
        ) and PLOS Computational Biology’s “
        <a href="https://collections.plos.org/ten-simple-rules">
         ten simple rules
        </a>
        ” series (e.g.
        <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285">
         Sandve et al, 2013
        </a>
        ;
        <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003542">
         Goodman et al, 2014
        </a>
        ). We also see this series as an intellectual successor to the collection of case studies in reproducible research published by several BIDS fellows (
        <a href="http://practicereproducibleresearch.org">
         Kitzes, Turek, and Deniz, 2018
        </a>
        ). One reason we chose to identify issues with doing data science in teams and groups is because many of us felt like we understood how to best practice data-intensive research individually, but struggled with how to do this well in teams and groups.
       </p>
       <h2 id="compute-and-data-challenges">
        Compute and data challenges
       </h2>
       <h3 id="getting-on-the-same-stack">
        Getting on the same stack
       </h3>
       <p>
        Some of the major challenges in doing data-intensive research in teams is around technology use, particularly in using the same tools. Today’s computational researchers have an overwhelming number of options to choose in terms of programming languages, software libraries, data formats, operating systems, compute infrastructures, version control systems, collaboration platforms, and more. One of the major challenges we discussed was that members of a team often have been trained to work with different technologies, which also often come with their own ways of working on a problem. Getting everyone on the same technical stack often takes far more time than is anticipated, and new members can spend much time learning to work in a new stack.
       </p>
       <p>
        One of the biggest divides our group had experienced was in the choice of using programming languages, as many of us were more comfortable with either R or Python. These programming languages have their own extensive software libraries, like the tidyverse vs. the numpy/pandas/matplotlib stack. There are also many different software environments to choose from at various layers of the stack, from development environments like Jupyter notebooks versus RStudio and RMarkdown to the many options for package and dependency management. While most of the people in the room were committed to open source languages and environments, many people are trained to use proprietary software like MATLAB or SPSS, which raises an additional challenge in teams and groups.
       </p>
       <p>
        Another major issue is where the actual computing and data storage will take place. Members of a team often come in knowing how to run code on their own laptops, but there are many options for groups to work, including a lab’s own shared physical server, campus clusters, national grid/supercomputer infrastructures, corporate cloud services, and more.
       </p>
       <h3 id="workflow-and-pipeline-management">
        Workflow and pipeline management
       </h3>
       <p>
        Getting everyone to use an interoperable software and hardware environment is as much of a social challenge as it is a technical one, and we had a great discussion about whether a group leader should (or could) require members to use the same language, environment, or infrastructure. One of the technical solutions to this issue — working in staged data analysis pipelines — comes with its own set of challenges. With staged pipelines, data processing and analysis tasks are separated into modular tasks that an individual can solve in their own way, then output their work to a standardized file for the next stage of the pipeline to take as input.
       </p>
       <p>
        The ideal end goal is often imagined to be a fully-automated (or ‘one click’) data processing and analysis pipeline, but this is difficult to achieve and maintain in practice. Several people in our group said they personally spend substantial amounts of time setting up these pipelines and making sure that each person’s piece works with everyone else’s. Even with groups that had formalized detailed data management plans, a common theme was that someone had to constantly make sure that team members were actually following these standards so that the pipeline keep running.
       </p>
       <h3 id="external-handoffs-to-and-from-the-team">
        External handoffs to and from the team
       </h3>
       <p>
        Many of the research projects we discussed involved not only handoffs between members of the team, but also handoffs between the team and external groups. The “raw” data a team begins with is often the final output of another research team, government agency, or company. In these cases, our group discussed issues that ranged from technical to social, from data formats that are technically difficult to integrate at scale (like Excel spreadsheets) to not having adequate documentation to be able to interpret what the data actually means. Similarly, teams often must deliver data to external partners, who may have very different needs, expectations, and standards than the team has for itself. Finally, some teams have sensitive data privacy issues and requirements, which makes collaboration even more difficult. How can these external relationships be managed in mutually beneficial ways?
       </p>
       <h2 id="team-management-challenges">
        Team management challenges
       </h2>
       <p>
        Beyond technical challenges, a number of management issues face research groups aspiring to implement best practices for data-intensive research. Our discussion highlighted the difficulties of composing a well-balanced team, of dealing with fluid membership, and of fostering generative coordination and communication among group members.
       </p>
       <h3 id="composing-a-well-balanced-team">
        Composing a well-balanced team
       </h3>
       <p>
        Data-intensive research groups require a team with varied expertise. A consequence of varied expertise is varied capabilities and end goals, so project leads must devote attention to managing team composition. Whereas one or two members might be capable of carrying out tasks across the various stages of research, others might specialize in a particular area. How then can research groups ensure that no one member of the team departing would collapse the project and that the team holds the necessary expertise to accomplish the shared research goal? Furthermore, some members may participate simply to acquire skills, while others seek to establish or build an academic track record. How might groups achieve alignment between personal and team goals?
       </p>
       <h3 id="dealing-with-voluntary-and-fluid-membership">
        Dealing with voluntary and fluid membership
       </h3>
       <p>
        A practical management problem also relates to the quasi-voluntary and fluid nature of research groups. Research groups largely rely extensively on students and postdocs, with an expectation that they join the team temporarily to gain new skills and experience, then leave. Turnover becomes a problem when processes, practices, and tacit institutional knowledge are difficult to standardize or document. What strategies might project leads employ to alleviate the difficulties associated with voluntary, fluid membership?
       </p>
       <h3 id="fostering-coordination-and-communication">
        Fostering coordination and communication
       </h3>
       <p>
        The issues of team composition and voluntary or fluid membership raise a third challenge: fostering open communication among group members. Previous research and guidelines for managing teams (
        <a href="http://web.mit.edu/curhan/www/docs/Articles/15341_Readings/Organizational_Learning_and_Change/Edmondson_1999_Psychological_safety.pdf">
         Edmondson, 1999
        </a>
        ;
        <a href="https://rework.withgoogle.com/guides/understanding-team-effectiveness/steps/help-teams-determine-their-needs/">
         Google re:Work, 2017
        </a>
        ) emphasize the vital role of psychological safety in ensuring that team members share knowledge and collaborate effectively. Adequate psychological safety ensures that team members are comfortable speaking up about their ideas and welcoming of others’ feedback. Yet fostering psychological safety is a difficult task when research groups comprise members with various levels of expertise, career experience, and, increasingly, communities of practice (as in the case of data scientists working with domain experts). How can projects establish avenues for open communication between diverse members?
       </p>
       <h3 id="not-abandoning-best-practices-when-deadlines-loom">
        Not abandoning best practices when deadlines loom
       </h3>
       <p>
        One of the major issues that resonated across our group was the tendency for a team to stop following various best practices when deadlines rapidly approach. In the rush to do everything that is needed to get a publication submitted, it is easy to accrue what software engineers call “technical debt.” For example, substantial “collaboration debt” or “reproducibility debt” can be foisted on a team when a member works outside of the established workflow to produce a figure or fails to document their changes to analysis code. These stressful moments can also be difficult for the team’s psychological safety, particularly if there is an expectation to work late hours to make the deadline.
       </p>
       <h2 id="concluding-thoughts-and-plans">
        Concluding thoughts and plans
       </h2>
       <h3 id="are-there-universal-best-practices-for-all-cases-and-contexts">
        Are there universal best practices for all cases and contexts?
       </h3>
       <p>
        At the conclusion of our first substantive meeting, we began to evaluate topics for future discussions that might help us identify potential solutions to the challenges faced by data-intensive research groups. In doing so, we were quickly confronted with the diversity of technologies, research agendas, disciplinary norms, team compositions, and governance structures, and other factors that characterize scientific research groups. Are solutions that work for large teams appropriate for smaller teams? Do cross-institutional or inter-disciplinary teams face different problems than those working in the same institution or discipline? Are solutions that work in astronomy or physics appropriate for ecology or social sciences? Dealing with such diversity and contextuality, then, might require adjusting our line of inquiry to the following question: At what level should we attempt to generalize best practices?
       </p>
       <h3 id="our-future-plans">
        Our future plans
       </h3>
       <p>
        The differences within and between research groups are meaningful and deserve adequate attention, but commonalities do exist. This semester, our group will aggregate and develop input from a diverse community of practitioners to construct sets of thoughtful, grounded recommendations. For example, we’ll aim to provide recommendations on issues such as how to build and maintain pipelines and workflows, as well as strategies for achieving diversity and inclusion in teams. In our next post, we’ll offer some insights on how to manage the common problem of perpetual turnover in team membership. On all topics, we welcome feedback and recommendations.
       </p>
       <h3 id="combatting-impostor-syndrome">
        Combatting impostor syndrome
       </h3>
       <p>
        Finally, many people who attended told us afterwards how positive and valuable it was to share these kinds of issues and experiences, particularly for combatting the “impostor syndrome” that many of us often feel. We typically only present the final end-product of research. Even sharing one’s final code and data in perfectly reproducible pipelines can still hide all the messy, complex, and challenging work that goes into the research process. People deeply appreciated hearing others talk openly about the difficulties and challenges that come with doing data-intensive research and how they tried to deal with them. The format of sharing challenges followed by strategies for dealing with those challenges may be a meta-level best practice for this kind of work, versus the more standard approach of listing more abstract rules and principles. Through these kinds of conversations, we hope to continue to shed light on the doing of data science in ways that will be constructive and generative across the many fields, areas, and contexts in which we all work.
       </p>
      </div>
      <p class="date">
       <a href="https://stuartgeiger.com/posts/2018/10/best-practices-team-challenges">
        by R. Stuart Geiger at October 31, 2018 07:00 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    October 23, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3574">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/10/23/for-a-more-ethical-silicon-valley-we-need-a-wiser-economics-of-data/">
       For a more ethical Silicon Valley, we need a wiser economics of data
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Kara Swisher’s NYT
        <a href="https://www.nytimes.com/2018/10/21/opinion/who-will-teach-silicon-valley-to-be-ethical.html">
         op-ed
        </a>
        about the dubious ethics of Silicon Valley and Nitasha Tiku’s WIRED
        <a href="https://www.wired.com/story/alternative-history-of-silicon-valley-disruption/">
         article
        </a>
        reviewing books with alternative (and perhaps more cynical than otherwise stated) stories about the rise of Silicon Valley has generated
        <a href="http://blog.geomblog.org/2018/10/on-teaching-ethics-to-tech-companies.html">
         discussion
        </a>
        and buzz among the tech commentariat.
       </p>
       <p>
        One point of debate is whether the focus should be on “ethics” or on something more substantively defined, such as
        <em>
         human rights
        </em>
        . Another point is whether the emphasis should be on “ethics” or on something more substantively enforced, like laws which impose penalties between
        <a href="https://twitter.com/FrankPasquale/status/1054352479767404546">
         1% and 4% of profits
        </a>
        , referring of course to the GDPR.
       </p>
       <p>
        While I’m sympathetic to the European approach (laws enforcing human rights with real teeth), I think there is something naive about it. We have not yet seen whether it’s ever really possible to comply with the GDPR could wind up being a kind of heavy tax on Big Tech companies operating in the EU, but one that doesn’t truly wind up changing how people’s data are used. In any case, the broad principles of European privacy are based on
        <em>
         individual human dignity
        </em>
        , and so they do not take into account the ways that corporations are social structures, i.e. sociotechnical organizations that transcend individual people. The European regulations address the problem of individual privacy while leaving mystified the question of
        <em>
         why
        </em>
        the current corporate organization of the world’s personal information is what it is. This sets up the fight over ‘technology ethics’ to be a political conflict between different kinds of actors whose positions are defined as much by their
        <a href="https://digifesto.com/2014/07/08/the-facebook-ethics-problem-is-a-political-problem/">
         social habitus
        </a>
        as by their intellectual reasons.
       </p>
       <p>
        My own (unpopular!) view is that the solution to our problems of technology ethics are going to have to rely on a better adapted
        <em>
         technology economics
        </em>
        . We often forget today that economics was originally a branch of moral philosophy. Adam Smith wrote
        <em>
         The Theory of Moral Sentiments
        </em>
        (1759) before
        <em>
         An Inquiry into the Nature and Causes of the Wealth of Nations
        </em>
        (1776). Since then the main purpose of economics has been to intellectually grasp the major changes to society due to production, trade, markets, and so on in order to better steer policy and business strategy towards more fruitful equilibria. The discipline has a bad reputation among many “critical” scholars due to its role in supporting neoliberal ideology and policies, but it must be noted that this ideology and policy work is not entirely cynical; it was a successful centrist hegemony for some time. Now that it is under threat, partly due to the successes of the big tech companies that benefited under its regime, it’s worth considering what new lessons we have to learn to steer the economy in an improved direction.
       </p>
       <p>
        The difference between an economic approach to the problems of the tech economy and either an ‘ethics’ or a ‘law’ based approach is that it inherently acknowledges that there are a wide variety of strategic actors co-creating social outcomes. Individual “ethics” will not be able to settle the outcomes of the economy because the outcomes depend on collective and uncoordinated actions. A fundamentally decent person may still do harm to others due to their own bounded rationality; “the road to hell is paved with good intentions”. Meanwhile, regulatory law is not the same as
        <em>
         command
        </em>
        ; it is at best a way of setting the rules of a game that will be played, faithfully or not, by many others. Putting regulations in place without a good sense of how the game will play out differently because of them is just as irresponsible as implementing a sweeping business practice without thinking through the results, if not more so because the relationship between the state and citizens is coercive, not voluntary as the relationship between businesses and customers is.
       </p>
       <p>
        Perhaps the biggest obstacle to shifting the debate about technology ethics to one about technology economics is that it requires a change in register. It drains the conversation of the pathos which is so instrumental in surfacing it as an important political topic. Sound analysis often ruins parties like this. Nevertheless, it must be done if we are to progress towards a more just solution to the crises technology gives us today.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/10/23/for-a-more-ethical-silicon-valley-we-need-a-wiser-economics-of-data/">
        by Sebastian Benthall at October 23, 2018 03:04 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    October 17, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://bytegeist.wordpress.com" title="The Bytegeist">
       Richmond Wong
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://bytegeist.wordpress.com/?p=455">
     <h4 class="posttitle" lang="en">
      <a href="https://bytegeist.wordpress.com/2018/10/17/engaging-technologists-to-reflect-on-privacy-using-design-workbooks/">
       Engaging Technologists to Reflect on Privacy Using Design Workbooks
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p class="graf graf--p graf-after--h3" id="4d52">
        <em class="markup--em markup--p-em">
         This post summarizes a research paper,
        </em>
        <a class="markup--anchor markup--p-anchor" href="https://escholarship.org/uc/item/78c2802k" rel="nofollow noopener" target="_blank">
         <em class="markup--em markup--p-em">
          Eliciting Values Reflections by Engaging Privacy Futures Using Design Workbooks
         </em>
        </a>
        <em class="markup--em markup--p-em">
         , co-authored with Deirdre Mulligan, Ellen Van Wyk, John Chuang, and James Pierce. The paper will be presented at the
        </em>
        <a class="markup--anchor markup--p-anchor" href="https://cscw.acm.org/2018/index.html" rel="nofollow noopener" target="_blank">
         <em class="markup--em markup--p-em">
          ACM Conference on Computer-Supported Cooperative Work and Social Computing
         </em>
        </a>
        <em class="markup--em markup--p-em">
         (CSCW) on Monday November 5th (in the afternoon Privacy in Social Media session). Full paper
         <a href="https://escholarship.org/uc/item/78c2802k">
          available here
         </a>
         .
        </em>
       </p>
       <p class="graf graf--p graf-after--p" id="4cd3">
        Recent wearable and sensing devices, such as
        <a class="markup--anchor markup--p-anchor" href="https://bytegeist.wordpress.com/2016/06/06/a-closer-look-at-google-glasss-microsoft-hololens-concept-videos-and-surveillance-concenrs/" rel="nofollow noopener" target="_blank">
         Google Glass
        </a>
        ,
        <a class="markup--anchor markup--p-anchor" href="https://www.theguardian.com/world/2018/jan/28/fitness-tracking-app-gives-away-location-of-secret-us-army-bases" rel="nofollow noopener" target="_blank">
         Strava
        </a>
        , and
        <a class="markup--anchor markup--p-anchor" href="https://advocacy.mozilla.org/en-US/privacynotincluded" rel="nofollow noopener" target="_blank">
         internet-connected toys
        </a>
        have raised questions about ways in which privacy and other social values might be implicated by their development, use, and adoption. At the same time, legal,
        <a class="markup--anchor markup--p-anchor" href="https://www.ftc.gov/news-events/press-releases/2012/03/ftc-issues-final-commission-report-protecting-consumer-privacy" rel="nofollow noopener" target="_blank">
         policy
        </a>
        , and
        <a class="markup--anchor markup--p-anchor" href="https://software.imdea.org/~carmela.troncoso/papers/Gurses-CPDP11.pdf" rel="nofollow noopener" target="_blank">
         technical
        </a>
        advocates for “
        <a class="markup--anchor markup--p-anchor" href="https://iab.org/wp-content/IAB-uploads/2011/03/fred_carter.pdf" rel="nofollow noopener" target="_blank">
         privacy by design
        </a>
        ” have suggested that privacy should embedded into all aspects of the
        <em class="markup--em markup--p-em">
         design process
        </em>
        , rather than being addressed after a product is released, or rather than being addressed as just a legal issue. By advocating that privacy be addressed through technical design processes, the ability for technology professionals to surface, discuss, and address privacy and other social values becomes vital.
       </p>
       <p class="graf graf--p graf-after--p" id="1cea">
        Companies and technologists already use a range of tools and practices to help address privacy, including privacy engineering practices, or making privacy policies more readable and usable. But many existing privacy mitigation tools are either deductive, or assume that privacy problems already known and well-defined in advance. However we often don’t have privacy concerns well-conceptualized in advance when creating systems. Our research shows that design approaches (drawing on a set of techniques called speculative design and design fiction) can help better explore, define, perhaps even anticipate, the what we mean by “privacy” in a given situation. Rather than trying to look at a single, abstract, universal definition of privacy,
        <strong class="markup--strong markup--p-strong">
         these methods help us think about privacy as relations among people, technologies, and institutions in different types of contexts and situations.
        </strong>
       </p>
       <h2 class="graf graf--h3 graf-after--p" id="7d2a">
        Creating Design Workbooks
       </h2>
       <p class="graf graf--p graf-after--h3" id="be8e">
        We created a set of
        <a class="markup--anchor markup--p-anchor" href="https://www.researchgate.net/publication/221514270_Making_spaces_How_design_workbooks_work" rel="nofollow noopener" target="_blank">
         design workbooks
        </a>
        — collections of design proposals or conceptual designs, drawn together to allow designers to investigate, explore, reflect on, and expand a design space. We drew on speculative design practices: in brief, our goal was to create a set of slightly provocative conceptual designs to help engage people in reflections or discussions about privacy (rather than propose specific solutions to problems posed by privacy).
       </p>
       <div class="wp-caption aligncenter" style="width: 1210px;">
        <img class="progressiveMedia-image js-progressiveMedia-image aligncenter" height="866" src="https://cdn-images-1.medium.com/max/1200/0*796Cj-B_pG0utiO8" width="1200"/>
        <p class="wp-caption-text">
         <em class="markup--em markup--figure-em">
          A set of sketches that comprise the design workbook
         </em>
        </p>
       </div>
       <p class="graf graf--p graf-after--figure" id="f7d4">
        Inspired by science fiction, technology research, and trends from the technology industry, we created a couple dozen fictional products, interfaces, and webpages of biosensing technologies, or technologies that sense people. These included smart camera enabled neighborhood watch systems, advanced surveillance systems, implantable tracking devices, and non-contact remote sensors that detect people’s heartrates. In
        <a class="markup--anchor markup--p-anchor" href="https://escholarship.org/uc/item/7r229796" rel="nofollow noopener" target="_blank">
         earlier design work
        </a>
        , we reflected on how putting the same technologies in different types of situations, scenarios, and social contexts, would vary the types of privacy concerns that emerged (such as the different types of privacy concerns that would emerge if advanced miniatures cameras were used by the police, by political advocates, or by the general public). However, we wanted to see how non-researchers might react to and discuss the conceptual designs.
       </p>
       <h2 class="graf graf--h3 graf-after--p" id="834b">
        How Did Technologists-In-Training View the Designs?
       </h2>
       <p class="graf graf--p graf-after--h3" id="f596">
        Through a series of interviews, we shared our workbook of designs with masters students in an information technology program who were training to go into the tech industry. We found several ways in which they brought up privacy-related issues while interacting with the workbooks, and highlight three of those ways here.
       </p>
       <div class="wp-caption aligncenter" style="width: 1210px;">
        <img class="progressiveMedia-image js-progressiveMedia-image" height="1233" src="https://cdn-images-1.medium.com/max/1200/0*efG1R1RN1NpbxDI5" width="1200"/>
        <p class="wp-caption-text">
         <em class="markup--em markup--figure-em">
          TruWork — A product webpage for a fictional system that uses an implanted chip allowing employers to keep track of employees’ location, activities, and health, 24/7.
         </em>
        </p>
       </div>
       <p class="graf graf--p graf-after--figure" id="dae2">
        First, our interviewees discussed privacy by taking on multiple user subject positions in relation to the designs. For instance, one participant looked at the fictional TruWork workplace implant design by imagining herself in the positions of an employer using the system and an employee using the system, noting how the product’s claim of creating a “happier, more efficient workplace,” was a value proposition aimed at the employer rather than the employee. While the system promises to tell employers whether or not their employees are lying about why they need a sick day, the participant noted that there might be many reasons why an employee might need to take a sick day, and those reasons should be private from their employer. These reflections are valuable, as prior work has documented how considering the viewpoints of direct and indirect stakeholders is important for considering social values in design practices.
       </p>
       <figure class="graf graf--figure graf--layoutOutsetLeft graf-after--p" id="75ca">
        <div class="aspectRatioPlaceholder is-locked">
         <div class="aspectRatioPlaceholder-fill">
         </div>
         <div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded">
          <div class="wp-caption aligncenter" style="width: 1210px;">
           <img class="progressiveMedia-image js-progressiveMedia-image aligncenter" height="753" src="https://cdn-images-1.medium.com/max/1200/0*3Ju6Q1Ucr9dn38ad" width="1200"/>
           <p class="wp-caption-text">
            <em class="markup--em markup--figure-em">
             CoupleTrack — an advertising graphic for a fictional system that uses an implanted chip for people in a relationship wear in order to keep track of each other’s location and activities.
            </em>
           </p>
          </div>
         </div>
        </div>
       </figure>
       <p class="graf graf--p graf-after--figure" id="719b">
        A second way privacy reflections emerged was when participants discussed the designs in relation to their professional technical practices. One participant compared the fictional CoupleTrack implant to a wearable device for couples that he was building, in order to discuss different ways in which consent to data collection can be obtained and revoked. CoupleTrack’s embedded nature makes it much more difficult to revoke consent, while a wearable device can be more easily removed. This is useful because we’re looking for ways workbooks of speculative designs can help technologists discuss privacy in ways that they can relate back to their own technical practices.
       </p>
       <figure class="graf graf--figure graf--layoutOutsetLeft graf-after--p" id="e5ee">
        <div class="aspectRatioPlaceholder is-locked">
         <div class="aspectRatioPlaceholder-fill">
         </div>
         <div class="progressiveMedia js-progressiveMedia graf-image is-canvasLoaded is-imageLoaded">
          <div class="wp-caption alignnone" style="width: 1210px;">
           <img class="progressiveMedia-image js-progressiveMedia-image" height="750" src="https://cdn-images-1.medium.com/max/1200/0*IPdVqzN-WuZyQdQH" width="1200"/>
           <p class="wp-caption-text">
            <em class="markup--em markup--figure-em">
             Airport Tracking System — a sketch of an interface for a fictional system that automatically detects and flags “suspicious people” by color-coding people in surveillance camera footage.
            </em>
           </p>
          </div>
         </div>
        </div>
       </figure>
       <p class="graf graf--p graf-after--figure" id="a4a5">
        A third theme that we found was that participants discussed and compared multiple ways in which a design could be configured or implemented. Our designs tend to describe products’ functions but do not specify technical implementation details, allowing participants to imagine multiple implementations. For example, a participant looking at the fictional automatic airport tracking and flagging system discussed the privacy implication of two possible implementations: one where the system only identifies and flags people with a prior criminal history (which might create extra burdens for people who have already served their time for a crime and have been released from prison); and one where the system uses behavioral predictors to try to identify “suspicious” behavior (which might go against a notion of “innocent until proven guilty”). The designs were useful at provoking conversations about the privacy and values implications of different design decisions.
       </p>
       <h2 class="graf graf--h3 graf-after--p" id="c4d4">
        Thinking About Privacy and Social Values Implications of Technologies
       </h2>
       <p class="graf graf--p graf-after--h3" id="a0ed">
        This work provides a case study showing how design workbooks and speculative design can be useful for thinking about the social values implications of technology, particularly privacy. In the time since we’ve made these designs, some (sometimes eerily) similar technologies have been developed or released, such as workers at a Swedish company
        <a class="markup--anchor markup--p-anchor" href="https://www.washingtonpost.com/news/on-leadership/wp/2017/04/04/some-swedish-workers-are-getting-microchips-implanted-in-their-hands/?utm_term=.9da090d74884" rel="nofollow noopener" target="_blank">
         embedding RFID chips in their hands
        </a>
        , or
        <a class="markup--anchor markup--p-anchor" href="https://www.logitech.com/en-us/product/circle-2-home-security-camera" rel="nofollow noopener" target="_blank">
         Logitech’s Circle Camera
        </a>
        .
       </p>
       <p class="graf graf--p graf-after--p" id="978f">
        But our design work isn’t meant to predict the future. Instead, what we tried to do is take some technologies that are emerging or on the near horizon, and think seriously about ways in which they might get adopted, or used and misused, or interact with existing social systems — such as the workplace, or government surveillance, or school systems. How might privacy and other values be at stake in those contexts and situations? We aim for for these designs to help shed light on the space of possibilities, in an effort to help technologists make more
        <em class="markup--em markup--p-em">
         socially informed
        </em>
        design decisions in the present.
       </p>
       <p class="graf graf--p graf-after--p" id="519f">
        We find it compelling that our design workbooks helped technologists-in-training discuss emerging technologies in relation to everyday, situated contexts. These workbooks don’t depict far off speculative science fiction with flying cars and spaceships. Rather they imagine future uses of technologies by having someone look at a product website, or a amazon.com page or an interface and thinking about the real and diverse ways in which people might experience those technology products. Using these techniques that focus on the potential adoptions and uses of emerging technologies in everyday contexts helps raise issues which might not be immediately obvious if we only think about positive social implications of technologies, and they also help surface issues that we might not see if we only think about social implications of technologies in terms of “worst case scenarios” or dystopias.
       </p>
       <p class="graf graf--p graf-after--p" id="23f1">
        <strong class="markup--strong markup--p-strong">
         Paper Citation:
        </strong>
       </p>
       <p class="graf graf--p graf-after--p graf--trailing" id="5e61">
        Richmond Y. Wong, Deirdre K. Mulligan, Ellen Van Wyk, James Pierce, and John Chuang. 2017. Eliciting Values Reflections by Engaging Privacy Futures Using Design Workbooks.
        <em class="markup--em markup--p-em">
         Proc. ACM Hum.-Comput. Interact. 1
        </em>
        , CSCW, Article 111 (December 2017), 26 pages. DOI:
        <a class="markup--anchor markup--p-anchor" href="https://doi.org/10.1145/3134746" rel="nofollow noopener" target="_blank">
         https://doi.org/10.1145/3134746
        </a>
       </p>
       <hr/>
       <p>
        <em>
         This post is crossposted with the
         <a href="https://medium.com/acm-cscw">
          ACM CSCW Blog
         </a>
        </em>
       </p>
      </div>
      <p class="date">
       <a href="https://bytegeist.wordpress.com/2018/10/17/engaging-technologists-to-reflect-on-privacy-using-design-workbooks/">
        by Richmond at October 17, 2018 04:40 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    October 15, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3572">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/10/15/privacy-of-practicing-high-level-martial-artists-bjj-ci/">
       Privacy of practicing high-level martial artists (BJJ, CI)
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Continuing my somewhat lazy “ethnographic” study of
        <a href="https://digifesto.com/2018/09/09/brazilian-jiu-jitsu-bjj-and-the-sociology-of-martial-knowledge/">
         Brazilian Jiu Jitsu
        </a>
        , an interesting occurrence happened the other day that illustrates something interesting about BJJ that is reflective of privacy as contextual integrity.
       </p>
       <p>
        <a href="https://inprogress.cardiffuniversitypress.org/index.php/JOMEC/article/view/330">
         Spencer
        </a>
        (2016) has accounted for the changes in martial arts culture, and especially Brazilian Jiu Jitsu, due to the proliferation of video on-line. Social media is now a major vector for the skill acquisition in BJJ. It is also, in my gym, part of the social experience. A few dedicated accounts on social media platforms that share images and video from the practice. There is a group chat where gym members cheer each other on, share BJJ culture (memes, tips), and communicate with the instructors.
       </p>
       <p>
        Several members have been taking pictures and videos of others in practice and sharing them to the group chat. These are generally met with enthusiastic acclaim and acceptance. The instructors have also been inviting in very experienced (black belt) players for one-off classes. These classes are opportunities for the less experienced folks to see another perspective on the game. Because it is a complex sport, there are a wide variety of styles and in general it is exciting and beneficial to see moves and attitudes of masters besides the ones we normally train with.
       </p>
       <p>
        After some videos of a new guest instructor were posted to the group chat, one of the permanent instructors (“A”) asked not to do this:
       </p>
       <blockquote>
        <p>
         A: “As a general rule of etiquette, you need permission from a black belt and esp if two black belts are rolling to record them training, be it drilling not [sic] rolling live.”
        </p>
        <p>
         A: “Whether you post it somewhere or not, you need permission from both to record then [sic] training.”
        </p>
        <p>
         B: “Heard”
        </p>
        <p>
         C: “That’s totally fine by me, but im not really sure why…?
        </p>
        <p>
         B: “I’m thinking it’s a respect thing.”
        </p>
        <p>
         A: “Black belt may not want footage of him rolling or training. as a general rule if two black belts are training together it’s not to be recorded unless expressly asked. if they’re teaching, that’s how they pay their bills so you need permission to record them teaching. So either way, you need permission to record a black belt.”
        </p>
        <p>
         A: “I’m just clarifying for everyone in class on etiquette, and for visiting other schools. Unless told by X, Y, [other gym staff], etc., or given permission at a school you’re visiting, you’re not to record black belts and visiting upper belts while rolling and potentially even just regular training or class. Some schools take it very seriously.”
        </p>
        <p>
         C: “OK! Totally fine!”
        </p>
        <p>
         D: “[thumbs up emoji] gots it :)”
        </p>
        <p>
         D: “totally makes sense”
        </p>
       </blockquote>
       <p>
        A few observations on this exchange.
       </p>
       <p>
        First, there is the intriguing point that for martial arts black belts teaching, their instruction is part of their livelihood. The knowledge of the expert martial arts practitioner is hard-earned and valuable “intellectual property”, and it is exchanged through being observed. Training at a gym with high-rank players is a privilege that lower ranks pay for. The use of video recording has changed the economy of martial arts training. This has in many ways opened up the sport; it also opens up potential opportunities for the black belt in producing training videos.
       </p>
       <p>
        Second, this is framed as etiquette, not as a legal obligation. I’m not sure what the law would say about recordings in this case. It’s interesting that as a point of etiquette, it applies only to videos of high belt players. Recording low belt players doesn’t seem to be a problem according to the agreement in the discussion. (I personally have asked not to be recorded at one point at the gym when an instructor explicitly asked to be recorded in order to create demo videos. This was out of embarrassment at my own poor skills; I was also feeling badly because I was injured at the time. This sort of consideration does not, it seem, currently operate as privacy etiquette within the BJJ community. Perhaps these norms are currently being negotiated or are otherwise in flux.)
       </p>
       <p>
        Third, there is a sense in which high rank in BJJ comes with authority and privileges that do not require any justification. The “trainings are livelihood” argument does apply directly to general practice roles; the argument is not airtight. There is something else about the authority and gravitas of the black belt that is being preserved here. There is a sense of earned respect. Somehow this translates into a different form  of privacy (information flow) norm.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Spencer, D. C. (2016). From many masters to many Students: YouTube, Brazilian Jiu Jitsu, and communities of practice. Jomec Journal, (5).
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/10/15/privacy-of-practicing-high-level-martial-artists-bjj-ci/">
        by Sebastian Benthall at October 15, 2018 05:11 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    September 27, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://ctsp.berkeley.edu" title="CTSP">
       Citizen Technologist
      </a>
     </div>
     <div class="channel-affiliation">
      Center for Technology, Society &amp; Policy
     </div>
    </div>
    <div class="entrygroup" id="https://ctsp.berkeley.edu/?p=1861">
     <h4 class="posttitle" lang="en-US">
      <a href="https://ctsp.berkeley.edu/ctsp-alumni-updates/">
       CTSP Alumni Updates
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <h3>
        We’re thrilled to highlight some recent updates from our fellows:
       </h3>
       <p>
        Gracen Brilmyer, now a PhD student at UCLA, has published
        <span style="font-weight: 400;">
         a single authored work in one of the leading journals in archival studies,
         <em>
          Archival Science
         </em>
         :
        </span>
        <span style="font-weight: 400;">
         “
         <a href="https://link.springer.com/article/10.1007/s10502-018-9287-6">
          Archival Assemblages: Applying Disability Studies’ Political/Relational Model to Archival Description
         </a>
         ” and presented their work on archives, disability, and justice at a number of events over the past two years, including The Archival Education and Research Initiative (AERI), the Allied Media Conference, the International Communications Association (ICA) Preconference, Disability as Spectacle, and their research will be presented at the upcoming
         <a href="https://sites.google.com/monash.edu/cirnprato2018/home">
          Community Informatics Research Network (CIRN)
         </a>
         .
        </span>
       </p>
       <p>
        <em>
         CTSP Funded Project 2016:
         <a href="https://ctsp.berkeley.edu/projects#visionarchive">
          Vision
         </a>
         <a href="https://ctsp.berkeley.edu/projects#visionarchive">
          Archive
         </a>
        </em>
       </p>
       <hr/>
       <p>
        Originating in the 2017 project “
        <a href="https://ctsp.berkeley.edu/projects2017/#safetydatacollection">
         Assessing Race and Income Disparities in Crowdsourced Safety Data Collection
        </a>
        ” done by Fellows Kate Beck,
        <span style="font-weight: 400;">
         Aditya Medury, and Jesus Barajas, the
         <a href="https://safetrec.berkeley.edu/">
          Safe Transportation and Research Center
         </a>
         will launch a new project,
        </span>
        Street Story, in October 2018.
        <span style="font-weight: 400;">
         Street Story is an online platform that allows community groups and agencies to collect community input about transportation collisions, near-misses, general hazards and safe locations to travel. The platform will be available throughout California and is funded through the California Office of Traffic Safety.
        </span>
       </p>
       <p>
        <em>
         CTSP Funded Project 2017:
         <a href="https://ctsp.berkeley.edu/projects2017#safetydatacollection">
          Assessing Race and Income Disparities in Crowdsourced Safety Data Collection
         </a>
        </em>
       </p>
       <hr/>
       <p>
        Fellow Roel Dobbe has begun a postdoctoral scholar position at the new
        <a href="https://ainowinstitute.org/">
         AI Now Institute
        </a>
        . Inspired by his 2018 CTSP project, he has co-authored
        <span style="font-weight: 400;">
         a position paper with Sarah Dean, Tom Gilbert and Nitin Kohli titled
        </span>
        <a href="https://arxiv.org/abs/1807.00553">
         <span style="font-weight: 400;">
          A Broader View on Bias in Automated Decision-Making: Reflecting on Epistemology and Dynamics
         </span>
        </a>
        <span style="font-weight: 400;">
         .
        </span>
       </p>
       <p>
        <em>
         CTSP Funded Project 2018:
        </em>
        <em>
         <a href="https://ctsp.berkeley.edu/projects2018/#unpackingTheBlackBox">
          Unpacking the Black Box of Machine Learning Processes
         </a>
        </em>
       </p>
       <hr/>
       <p>
        We are also looking forward to a CTSP Fellow filled
        <a href="https://cscw.acm.org/2018/">
         Computer Supported Cooperative Work
        </a>
        conference in November this year! CTSP affiliated papers include:
       </p>
       <ul>
        <li>
         <span style="font-weight: 400;">
          “
          <a href="http://morganya.org/research/2018-Ames-CSCW-Constructionism.pdf">
           Hackers, Computers, and Cooperation: A Critical History of Logo and Constructionist Learning
          </a>
          ” by m
         </span>
         ulti-year fellow and CSTMS Associate Director Morgan Ames, who with this piece
         <span style="font-weight: 400;">
          bridges her previous work on CSCW and new interest in the moral visions of AI/ML.
         </span>
         <ul>
          <li>
           <em>
            CTSP Funded Projects:
            <a href="https://ctsp.berkeley.edu/projects/#technicalcultures">
             Promoting Ethical Technical Cultures and Digital Citizenship for Low-Income and Minority Students in Richmond, California
            </a>
            (2016),
            <a href="https://ctsp.berkeley.edu/projects2017/#ethicalsiliconvalley">
             Cultivating Ethical Silicon Valley Cultures through Diversity of Narratives
            </a>
            (2017), and
            <a href="https://ctsp.berkeley.edu/projects2018/#unpackingTheBlackBox">
             Unpacking the Black Box of Machine Learning Processes
            </a>
            (2018)
           </em>
          </li>
         </ul>
        </li>
        <li>
         <span style="font-weight: 400;">
          “People Tend to Wind Down, Not Up, When They Browse Social Media,” by former CTSP Co-Director and Fellow Galen Panger (now at Google), based on his award-winning CTSP/CLTC funded
          <a href="http://news.berkeley.edu/2018/01/11/winning-research-finds-social-media-users-actually-wind-down-not-up/">
           dissertation work
          </a>
          .
         </span>
        </li>
       </ul>
       <p>
        We also look forward to seeing CTSP affiliates presenting other work, including 2018 Fellows Richmond Wong, Noura Howell, Sarah Fox, and more!
       </p>
       <p>
       </p>
      </div>
      <p class="date">
       <a href="https://ctsp.berkeley.edu/ctsp-alumni-updates/">
        by Anne Jonas at September 27, 2018 10:40 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    September 25, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://ctsp.berkeley.edu" title="CTSP">
       Citizen Technologist
      </a>
     </div>
     <div class="channel-affiliation">
      Center for Technology, Society &amp; Policy
     </div>
    </div>
    <div class="entrygroup" id="https://ctsp.berkeley.edu/?p=1856">
     <h4 class="posttitle" lang="en-US">
      <a href="https://ctsp.berkeley.edu/digital-security-crash-course2018/">
       October 25th: Digital Security Crash Course
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <p>
        <em>
         <span style="font-weight: 400;">
          Thursday, October 25, 5-7pm, followed by reception
         </span>
        </em>
       </p>
       <p>
        <em>
         <span style="font-weight: 400;">
          UC Berkeley, South Hall Room 210
         </span>
        </em>
       </p>
       <p>
        <em>
         Open to the public!
        </em>
       </p>
       <p>
        <a href="https://goo.gl/forms/J1zsnSTNHR64aQVu1">
         <span style="font-weight: 400;">
          <em>
           RSVP is required.
          </em>
         </span>
        </a>
       </p>
       <p>
        <span style="font-weight: 400;">
         Understanding how to protect your personal digital security is more important than ever. Confused about two factor authentication options? Which messaging app is the most secure? What happens if you forget your password manager password, or lose the phone you use for 2 factor authentication? How do you keep your private material from being shared or stolen? And how do you help your friends and family consider the potential dangers and work to prevent harm, especially given increased threats to vulnerable communities and unprecedented data breaches?
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         Whether you are concerned about snooping family and friends, bullies and exes who are out to hack and harass you, thieves who want to impersonate you and steal your funds, or government and corporate spying, we can help you with this fun, straightforward training in how to protect your information and communications.
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         <strong>
          Join us for a couple hours of discussion and hands-on set up.
         </strong>
         We’ll go over various scenarios you might want to protect against, talk about good tools and best practices, and explore trade offs between usability and security. This training is designed for people at all levels of expertise, and those who want both personal and professional digital security protection.
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         <strong>
          Refreshments and hardware keys provided!
         </strong>
         <strong>
          Bring your laptop or other digital device.
         </strong>
         Take home a hardware key and better digital security practices.
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         This crash course is sponsored by the Center for Technology, Society &amp; Policy and generously funded by the Charles Koch Foundation.
        </span>
        <a href="https://jessysaurusrex.com/about/">
         <span style="font-weight: 400;">
          Jessy Irwin
         </span>
        </a>
        <span style="font-weight: 400;">
         will be our facilitator and guide. Jessy is Head of Security at Tendermint, where she excels at translating complex cybersecurity problems into relatable terms, and is responsible for developing, maintaining and delivering comprehensive security strategy that supports and enables the needs of her organization and its people. Prior to her role at Tendermint, she worked to solve security obstacles for non-expert users as a strategic advisor, security executive and former Security Empress at 1Password. She regularly writes and presents about human-centric security, and believes that people should not have to become experts in technology, security or privacy to be safe online.
        </span>
       </p>
       <p>
        <a href="https://goo.gl/forms/J1zsnSTNHR64aQVu1">
         <span style="font-weight: 400;">
          RSVP here!
         </span>
        </a>
       </p>
      </div>
      <p class="date">
       <a href="https://ctsp.berkeley.edu/digital-security-crash-course2018/">
        by Daniel Griffin at September 25, 2018 05:25 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    September 09, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3567">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/09/09/brazilian-jiu-jitsu-bjj-and-the-sociology-of-martial-knowledge/">
       Brazilian Jiu Jitsu (BJJ) and the sociology of martial knowledge
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Maybe 15 months ago, I started training in
        <a href="https://en.wikipedia.org/wiki/Brazilian_jiu-jitsu">
         Brazilian Jiu Jitsu
        </a>
        (BJJ), a martial art that focuses on grappling and ground-fighting. Matches are won through points based on position (e.g., “mount”, where you are sitting on somebody else) and through submission, when a player taps out due to hyperextension under a joint lock or asphyxiation by choking. I recommend it heartily to anybody as a fascinating, smart workout that also has a vibrant and supportive community around it.
       </p>
       <p>
        One of the impressive aspects of BJJ, which differentiates it from many other martial arts, is its emphasis on live drilling and sparring (“rolling”), which can offer a third or more of a training session. In the context of sparring, there is opportunity for experimentation and rapid feedback about technique. In addition to being good fun and practice, regular sparring continually reaffirms the hierarchical ranking of skill. As in some other martial arts, rank is awarded as different colored “belts”–white, blue, purple, brown, black. Intermediary progress is given as “stripes” on the belt. White belts can spar with higher belts; more often than not, when they do so they get submitted.
       </p>
       <p>
        BJJ also has tournaments, which allow players from different dojos to compete against each other. I attended my first tournament in August and thought it was a great experience. There is nothing like meeting a stranger for the first time and then engage them in single combat to kindle a profound respect for the value of sportsmanship. Off the mat, I’ve had some of the most courteous encounters with anybody I have ever met in New York City.
       </p>
       <p>
        At tournaments, hundreds of contestants are divided into brackets. The brackets are determined by belt (white, blue, etc.), weight (up to 155 lbs, up to 170 lbs, etc.), sex (men and women), and age (kids age groups, adult, 30+ adult). There is an “absolute” bracket for those who would rise above the division of weight classes. There are “gi” and “no gi” variants of BJJ; the former requires wearing special uniform of jacket and pants, which are used in many techniques.
       </p>
       <p>
        Overall, it is an efficient system for training a skill.
       </p>
       <hr/>
       <p>
        The few readers of this blog will recall that for some time I studied sociology of science and engineering, especially through the lens of Bourdieu’s
        <em>
         Science of Science and Reflexivity
        </em>
        . This was in turn a reaction to a somewhat startling exposure to sociology of science and education, and intellectual encounter that I never intended to have. I have been interested for a long time in the foundations of science. It was a rude shock, and one that I mostly regret, to have gone to grad school to become a better data scientist and find myself having to engage with the work of Bruno Latour. I did not know how to respond intellectually to the attack on scientific legitimacy on the basis that its self-understanding is insufficiently sociological until encountering Bourdieu, who refuted the Latourian critique and provides a clear-sighted view of how social structure under-girds scientific objectivity, when it works. Better was my encounter with Jean Lave, who introduced me to more phenomenological methods for understanding education through her class and works (Chaiklin and Lave, 1996). This made me more aware of the role of apprenticeship as well as the nuances of culture, framing, context, and purpose in education. Had I not encountered this work, I would likely never have found my way to Contextual Integrity, which draws more abstract themes about privacy from such subtle observations.
       </p>
       <p>
        Now it’s impossible for me to do something as productive and enjoyable as BJJ without considering it through these kinds of lenses. One day I would like to do more formal work along these lines, but as has been my habit I have a few notes to jot down at the moment.
       </p>
       <p>
        The first point, which is a minor one, is that there is something objectively known by experienced BJJ players, and that this knowledge is quintessentially grounded in intersubjective experience. The sparring encounter is the site at which technique is tested and knowledge is confirmed. Sparring simulates conditions of a fight for survival; indeed, if a choke is allowed to progress, a combatant can lose consciousness on the mat. This recalls Hegel’s observation that it is in single combat that a human being is forced to see the limits of their own solipsism. When the Other can kill you, that is an Other that you must see as, in some sense, equivalent in metaphysical status to oneself. This is a sadly forgotten truth in almost every formal academic environment I’ve found myself in, and that, I would argue, is why there is so much bullshit in academia. But now I digress.
       </p>
       <p>
        The second point, which is perhaps more significant, is that BJJ has figured out how to be an inclusive field of knowledge despite the pervasive and ongoing politics of what I have called in another post
        <a href="https://digifesto.com/2018/06/12/bodies-and-liberal-publics-in-the-20th-century-and-today/">
         body agonism
        </a>
        . We are at a point where political conflict in the United States and elsewhere seems to be at root about the fact that people have different kinds of bodies, and these differences are upsetting for liberalism.
        <em>
         How can we have functioning liberal society when, for example, some people have male bodies and other people have female bodies?
        </em>
        It’s an absurd question, perhaps, but nevertheless it seems to be the question of the day. It is certainly a question that plagues
        <a href="https://digifesto.com/2018/09/08/on-hills-work-on-greater-male-variability-hypothesis-gmvh/">
         academic politics
        </a>
        .
       </p>
       <p>
        BJJ provides a wealth of interesting case studies in how to deal productively with body agonism. BJJ is an unarmed martial art. The fact that there are different body types is an instrinsic aspect of the sport. Interestingly, in the dojo practices I’ve seen, trainings are co-ed and all body types (e.g., weight classes) train together. This leads to a dynamic and irregular practice environment that perhaps is better for teaching BJJ as a practical form of self-defense.
        <a href="https://www.vice.com/en_in/article/3kygw8/choking-men-in-a-mans-world">
         Anecdotally
        </a>
        , self-defense is an important motivation for why especially women are interested in BJJ, and in the context of a gym, sparring with men is a way to safely gain practical skill in defending against male assailants. On the other hand, as far as
        <em>
         ranking progress
        </em>
        is concerned, different bodies are considered in relation to
        <em>
         other similar bodies
        </em>
        through the tournament bracket system. While I know a badass 40-year old who submitted two college kids in the last tournament, that was extra. For the purposes of measuring my improvement in the discipline, I will be in the 30+ men’s bracket, compared with other guys approximately my weight. The general sense within the community is that progress in BJJ is a function of time spent practicing (something like the mantra that it takes 10,000 hours to master something), not any other intrinsic talent. Some people who are more dedicated to their training advance faster, and others advance slower.
       </p>
       <p>
        Training in BJJ has been a positive experience for me, and I often wonder whether other social systems could be more like BJJ. There are important lessons to be learned from it, as it is a mental discipline, full of subtlety and intellectual play, in its own right.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Bourdieu, Pierre. Science of science and reflexivity. Polity, 2004.
       </p>
       <p>
        Chaiklin, Seth, and Jean Lave, eds. Understanding practice: Perspectives on activity and context. Cambridge University Press, 1996.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/09/09/brazilian-jiu-jitsu-bjj-and-the-sociology-of-martial-knowledge/">
        by Sebastian Benthall at September 09, 2018 02:08 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    September 08, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3559">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/09/08/on-hills-work-on-greater-male-variability-hypothesis-gmvh/">
       On Hill’s work on ‘Greater Male Variability Hypothesis’ (GMVH)
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I’m writing in response to Ted Hill’s
        <a href="https://quillette.com/2018/09/07/academic-activists-send-a-published-paper-down-the-memory-hole/">
         recent piece
        </a>
        describe the acceptance and subsequent removal of a paper about the ‘Greater Male Variability Hypothesis’, the controversial idea that there is more variability in male intelligence than female intelligence, i.e. “that there are more idiots and more geniuses among men than among women.”
       </p>
       <p>
        I have no reason to doubt Hill’s account of events–his collaboration, his acceptance to a journal, and the mysterious political barriers to publication–and assume them for the purposes of this post. If these are refuted by future controversy somehow, I’ll stand corrected.
       </p>
       <p>
        The few of you who have followed this blog for some time will know that I’ve devoted some energy to understanding the controversy around gender and STEM.
        <a href="https://digifesto.com/2014/10/30/comments-on-haraway-situated-knowledge-bias-and-code/">
         One post
        </a>
        , criticizing how Donna Haraway, widely used in Science and Technology Studies, can be read as implying that women should not become ‘hard scientists’ in the mathematical mode, has gotten a lot of hits (and some pushback). Hill’s piece makes me revisit the issue.
       </p>
       <p>
        The
        <a href="https://arxiv.org/pdf/1703.04184.pdf">
         paper itself
        </a>
        is quite dry and the following quote is its main thesis:
       </p>
       <blockquote>
        <p>
         <strong>
          SELECTIVITY-VARIABILITY PRINCIPLE
         </strong>
         . In a species with two sexes A and B, both of which are needed for reproduction, suppose that sex A is relatively selective, i.e., will mate only with a top tier (less than half ) of B candidates. Then from one generation to the next, among subpopulations of B with comparable average attributes, those with greater variability will tend to prevail over those with lesser variability. Conversely, if A is relatively non-selective, accepting all but a bottom fraction (less than half ) of the opposite sex, then subpopulations of B with lesser variability will tend to prevail over those with comparable means and greater variability.
        </p>
       </blockquote>
       <p>
        This mathematical thesis is supported in the paper by computational simulations and mathematical proofs. From this, one can get the GMVH if one assumes that: (a) (human) males are less selective in their choice of (human) females when choosing to mate, and (b) traits that drive variability in intelligence are intergenerationally heritable, whether biologically or culturally. While not uncontroversial, neither of these are crazy ideas. In fact, if they weren’t both widely accepted, then we wouldn’t be having this conversation.
       </p>
       <p>
        <strong>
         Is this the kind of result that should be published?
        </strong>
        This is the controversy. I am less interested in the truth or falsehood of broad implications of the mathematical work than I am in
        <em>
         the arguments for why the mathematical work should not be published (in a mathematics journal).
        </em>
       </p>
       <p>
        As far as I can tell from Hill’s account and also from conversations and cultural osmosis on the matter, there are a number of reasons why research of this kind should not be published.
       </p>
       <p>
        The first reason might be that there are errors in the mathematical or simulation work. In other words, the Selectivity-Variability Principle may be false, and falsely supported. If that is the case, then the reviewers should have rejected the paper on those grounds. However, the principle is intuitively plausible and the reviewers accepted it. Few of Hill’s critics (though some) attacked the piece on mathematical grounds. Rather, the objections were of a social and political nature. I want to focus on these latter objections, though if there is a mathematical refutation of the Selectivity-Variability Principle I’m not aware of, I’ll stand corrected.
       </p>
       <p>
        The crux of the problem seems to be this: the two assumptions (a) and (b) are both so plausible that publishing a defense of (c) the Selectivity-Variability Principle would imply (d) the Greater Male Variability Hypothesis (GMVH). And if GMVH is true, then (e) there is a reason why more of the celebrated high-end of the STEM professions are male. It is because at the high-end, we’re looking at the thin tails of the human distribution, and the male tail is longer. (It is also longer at the low end, but nobody cares about the low end.)
       </p>
       <p>
        The argument goes that if
        <em>
         this claim (e)
        </em>
        were widely known by aspiring females in STEM fields, then they will be discouraged from pursuing these promising careers, because “women have a lesser chance to succeed in mathematics at the very top end”, which would be a biased, sexist view. (e) could be used to defend the idea that (f) normatively, there’s nothing wrong with men having most success at the top end of mathematics, though there is a big is/ought distinction there.
       </p>
       <p>
        My concern with this argument is that it assumes, at its heart, the idea that women aspiring to be STEM professionals are emotionally vulnerable to being dissuaded by this kind of mathematical argument, even when it is neither an empirical case (it is a mathematical model, not empirically confirmed within the paper) nor does it reflect on the capacity of any particular woman, and especially not after she has been selected for by the myriad social sorting mechanisms available. The argument that GMVH is professionally discouraging assumes many other hypotheses about human professional motivation, for example, the idea that it is only worth taking on a profession if one can expect to have a higher-than-average chance of achieving extremely high relative standing in that field. Given that extremely high relative standing in any field is going to be rare, it’s hard to say this is a good motivation for any profession, for men or for women, in the long run. In general, those that extrapolate from population level gender tendencies to individual cases are committing the
        <a href="https://en.wikipedia.org/wiki/Ecological_fallacy">
         ecological fallacy
        </a>
        . It is ironic that under the assumption of the critics, potential female entrants into STEM might be screened out precisely because of their inability to understand a mathematical abstraction, along with its limitations and questionable applicability, through a cloud of political tension. Whereas if one were really interested in reaching mathematics in an equitable way, that would require teaching the capacity to see through political tension to the precise form of a mathematical abstraction. That is precisely what top performance in the STEM field should be about, and that it should be unflinchingly encouraged as part of the educational process for both men and women.
       </p>
       <p>
        My point, really, is this: the argument that publishing and discussing GMVH is detrimental to the career aspirations of women, because of how individual women will internalize the result, depends on a host of sexist assumptions that are as if not more pernicious than GMVH. It is based on the idea that women as a whole need special protection from mathematical ideas in order to pursue careers in mathematics, which is self-defeating crazy talk if I’ve ever heard it. The whole point of academic publication is to enable a debate of defeasible positions on their intellectual merits. In the case of mathematics research, the standards of merit are especially clear. If there’s a problem with Hill’s model, that’s a great opportunity for another, better model, on a topic that is clearly politically and socially relevant. (If the reviewers ignored a lot prior work that settled the scientific relevance of the question, then that’s a different story. One gathers that is not what happened.)
       </p>
       <p>
        As a caveat, there are other vectors through which GMVH could lead to bias against women pursuing STEM careers. For example, it could bias their less smart families or colleagues into believing less in their potential on the basis of their sex. But GMVH is about the variance, not the mean, of mathematical ability. So the only population that it’s relevant to is that in the very top tier of performers. That nuance is itself probably beyond the reach of most people who do not have at least some training in STEM, and indeed if somebody is reasoning from GMVH to an assumption about women’s competency in math then they are almost certainly conflating it with a dumber hypothesis about population means which is otherwise irrelevant.
       </p>
       <p>
        This is perhaps the most baffling thing about this debate: that it boils down to a very rarefied form of elite conflict. “Should a respected mathematics journal publish a paper that implies that there is greater variance in mathematical ability between sexes based on their selectivity and therefore…” is a sentence that already selects for a very small segment of the population, a population that should know better than to censor a mathematical proof rather than to take the opportunity to engage it as an opportunity to educate people in STEM and why it is an interesting field.
        <em>
         Nobody
        </em>
        is objecting to the publication of support for GMVH on the grounds that it implies that more men are grossly incompetent and stupid than women, and it’s worth considering why that is. If our first reaction to GMVH is “but can no one woman never be
        <em>
         the best off
        </em>
        ?”, we are showing that our concerns lie with who gets to be on top, not the welfare of those on bottom.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/09/08/on-hills-work-on-greater-male-variability-hypothesis-gmvh/">
        by Sebastian Benthall at September 08, 2018 09:06 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    September 07, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3556">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/09/07/note-on-austins-cyber-policy-in-china-on-the-emphasis-on-ethics/">
       Note on Austin’s “Cyber Policy in China”: on the emphasis on ‘ethics’
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I’ve had recommended to me
        <a href="https://www.amazon.com/Cyber-Policy-China-Today/dp/0745669808/ref=sr_1_1?ie=UTF8&amp;qid=1536334253&amp;sr=8-1&amp;keywords=cyber+policy+in+china">
         Greg Austin’s “Cyber Policy in China” (2014)
        </a>
        as a good, recent work. I am not sure what I was expecting–something about facts and numbers, how companies are being regulated, etc. Just looking at the preface, it looks like this book is about something else.
       </p>
       <p>
        The preface frames the book in the discourse, beginning in the 20th century, about the “information society”. It explicitly mentions the UN’s World Summit on the Information Society (WSIS) as a touchstone of international consensus about what the information society is, as society “where everyone can create, access, utilise and share information and knowledge’ to ‘achieve their full potential’ in ‘improving their quality of life’. It is ‘people-centered’.
       </p>
       <p>
        In Chinese, the word for information society is
        <em>
         xinxi shehui
        </em>
        (Please forgive me: I’ve got little to know understanding of the Chinese language and that includes not knowing how to put the appropriate diacritics into transliterations of Chinese terms.) It is related to a term “informatization” (
        <em>
         xinxihua
        </em>
        ) that is compared to industrialization. It means the historical process by which information technology is fully used, information resources are developed and utilized, the exchange of information and knowledge sharing are promoted, the quality of economic growth is improved, and the transformation of economic and social development is promoted”.  Austin’s interesting point is that this is “less people-centered than the UN vision and more in the mould of the materialist and technocratic traditions that Chinese Communists have preferred.”
       </p>
       <p>
        This is an interesting statement on the difference between policy articulations by the United Nations and the CCP. It does not come as a surprise.
       </p>
       <p>
        What
        <em>
         did
        </em>
        come as a surprise is how Austin chooses to orient his book.
       </p>
       <blockquote>
        <p>
         On the assumption that outcomes in the information society are ethically determined, the analytical framework used in the book revolves around ideal policy values for achieving an advanced information society. This framework is derived from a study of ethics. Thus, the analysis is not presented as a work of social science (be that political science, industry policy or strategic studies). It is more an effort to situate the values of China’s leaders within an ethical framework implied by their acceptance of the ambition to become and advanced information society.
        </p>
       </blockquote>
       <p>
        This comes as a surprise to me because what I was expected from a book titled “Cyber Policy in China” is really something more like industry policy or strategic studies. I was not ready for, and am frankly a bit disappointed by, the idea that this is really a work of applied philosophy.
       </p>
       <p>
        Why? I do love philosophy as a discipline and have studied it carefully for many years. I’ve written and published about ethics and technological design. But my conclusion after so much study is that “the assumption that outcomes in the information society are ethically determined” is totally incorrect. I have been situated for some time in discussions of “technology ethics” and my main conclusion from them is that (a) “ethics” in this space are more often than not an attempt to universalize what are more narrow political and economic interests, and that (b) “ethics” are constantly getting compromised by economic motivations as well as the mundane difficulty of getting information technology to work as it is intended to in a narrow, functionally defined way. The real world is much bigger and more complex than any particular ethical lens can take in. Attempt to define technological change in terms of “ethics” are almost always a political maneuver, for good or for ill, of some kind that is reducing the real complexity of technological development into a soundbite. A true ethical analysis of cyber policy would need to address industrial policy and strategic aspects, as this is what drives the “cyber” part of it.
       </p>
       <p>
        The irony is that there is something terribly un-emic about this approach. By Austin’s own admission, the CCP cyber policy is motivated by material concerns about the distribution of technology and economic growth. Austin could have approached China’s cyber policy in the technocratic terms they see themselves in. But instead Austin’s approach is “human-centered”, with a focus on leaders and their values. I already doubt the research
        <i>
         on anthropological grounds
        </i>
        because of the distance between the researcher and the subjects.
       </p>
       <p>
        So I’m not sure what to do about this book. The preface makes it sound like it belongs to a genre of scholarship that
        <em>
         reads well
        </em>
        , and maybe does important ideological translation work, but does provide something like scientific knowledge of China’s cyber policy, which is what I’m most interested in. Perhaps I should move on, or take other recommendations for reading on this topic.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/09/07/note-on-austins-cyber-policy-in-china-on-the-emphasis-on-ethics/">
        by Sebastian Benthall at September 07, 2018 03:59 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    September 04, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://ctsp.berkeley.edu" title="CTSP">
       Citizen Technologist
      </a>
     </div>
     <div class="channel-affiliation">
      Center for Technology, Society &amp; Policy
     </div>
    </div>
    <div class="entrygroup" id="https://ctsp.berkeley.edu/?p=1829">
     <h4 class="posttitle" lang="en-US">
      <a href="https://ctsp.berkeley.edu/backstage-decisions-front-stage-experts-interviewing-genome-editing-scientists/">
       Backstage Decisions, Front-stage Experts: Interviewing Genome-Editing Scientists
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <p>
        <em>
         by
        </em>
        <span style="font-weight: 400;">
         <a href="https://ctsp.berkeley.edu/people2018/#santiago">
          Santiago Molina
         </a>
         and
         <a href="https://ctsp.berkeley.edu/people2018/#gordon">
          Gordon Pherribo
         </a>
         ,
         <em>
          CTSP Fellows
         </em>
        </span>
       </p>
       <p>
        <em>
         This is the first in a series of posts on the project
         <a href="https://ctsp.berkeley.edu/projects2018/#democratizingTechnology">
          “Democratizing” Technology: Expertise and Innovation in Genetic Engineering
         </a>
        </em>
       </p>
       <p>
        <span style="font-weight: 400;">
         When we think about who is making decisions that will impact the future health and wellbeing of society, one would hope that these individuals would wield their expertise in a way that addresses the social and economic issues affecting our communities. Scientists often fill this role: for example, an ecologist advising a state environmental committee on river water redistribution [1],
        </span>
        <span style="font-weight: 400;">
         a geologist consulting for an architectural team building a skyscraper [2],
        </span>
        <span style="font-weight: 400;">
         an oncologist discussing the best treatment options based on the patient’s diagnosis and values
        </span>
        <span style="font-weight: 400;">
         [3] or an economist brought in by a city government to help develop a strategy for allocating grants to elementary schools. Part of the general contract between technical experts and their democracies is that they inform relevant actors so that decisions are made with the strongest possible factual basis.
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         The three examples above describe scientists going outside of the boundaries of their disciplines to present for people outside of the scientific community “on stage” [4].
        </span>
        <span style="font-weight: 400;">
         But what about decisions made by scientists behind the scenes about new technologies that could affect more than daily laboratory life? In the 1970s, genetic engineers used their technical expertise to make a call about an exciting new technology, recombinant DNA (rDNA). This technology allowed scientists to mix and add DNA from different organisms; later giving rise to engineered bacteria that could produce insulin and eventually transgenic crops. The expert decision making process and outcome, in this case, had little to do with the possibility of commercializing biotechnology or the economic impacts of GMO seed monopolies. This happened before the patenting of whole biological organisms [5]
        </span>
        <span style="font-weight: 400;">
         , and the use of rDNA in plants in 1982. Instead, the emerging issues surrounding rDNA were dealt with as a technical issue of containment. Researchers wanted to ensure that anything tinkered with genetically stayed not just inside the lab, but inside specially marked and isolated rooms in the lab, eventually given rise to well-established institution of biosafety. A technical fix, for a technical issue.
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         Today, scientists are similarly engaged in a process of expert decision making around another exciting new technology, the CRISPR-Cas9 system. This technology allows scientists to make highly specific changes, “edits”, to the DNA of virtually any organism. Following the original publication that showed that CRISPR-Cas9 could be used to modify DNA in a “programmable” way, scientists have developed the system into a laboratory toolbox and laboratories across the life sciences are using it to tinker away at bacteria, butterflies, corn, frogs, fruit flies, human liver cells, nematodes, and many other organisms. Maybe because most people do not have strong feelings about nematodes, most of the attention in both popular news coverage and in expert circles about this technology has had to do with whether modifications that could affect human offspring (i.e. germline editing) are moral.
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         We have been interviewing faculty members directly engaged in these critical conversations about the potential benefits and risks of new genome editing technologies. As we continue to analyze these interviews, we want to better understand the nature of these backstage conversations and learn how the experiences and professional development activities of these expects influenced their decision-making. In subsequent posts we’ll be sharing some of our findings from these interviews, which so far have highlighted the role of a wide range of technical experiences and skills for the individuals engaged in these discussions, the strength of personal social connections and reputation in getting you a seat at the table and the dynamic nature of expert decision making.
        </span>
       </p>
       <p>
        [1]
        <span style="font-weight: 400;">
         Scoville, C. (2017). “We Need Social Scientists!” The Allure and Assumptions of Economistic Optimization in Applied Environmental Science.
        </span>
        <i>
         <span style="font-weight: 400;">
          Science as Culture
         </span>
        </i>
        <span style="font-weight: 400;">
         ,
        </span>
        <i>
         <span style="font-weight: 400;">
          26
         </span>
        </i>
        <span style="font-weight: 400;">
         (4), 468-480.
        </span>
       </p>
       <p>
        [2]
        <span style="font-weight: 400;">
         Wildermuth and Dineen (2017) “How ready will Bay Area be for next Quake?”
        </span>
        <i>
         <span style="font-weight: 400;">
          SF Chronicle.
         </span>
        </i>
        <span style="font-weight: 400;">
         Available online at:
         <a href="https://www.sfchronicle.com/news/article/How-ready-will-Bay-Area-be-for-next-big-quake-12216401.php">
          https://www.sfchronicle.com/news/article/How-ready-will-Bay-Area-be-for-next-big-quake-12216401.php
         </a>
        </span>
       </p>
       <p>
        [3]
        <span style="font-weight: 400;">
         Sprangers, M. A., &amp; Aaronson, N. K. (1992). The role of health care providers and significant others in evaluating the quality of life of patients with chronic disease: a review.
        </span>
        <i>
         <span style="font-weight: 400;">
          Journal of clinical epidemiology
         </span>
        </i>
        <span style="font-weight: 400;">
         ,
        </span>
        <i>
         <span style="font-weight: 400;">
          45
         </span>
        </i>
        <span style="font-weight: 400;">
         (7), 743-760.
        </span>
       </p>
       <p>
        [4]
        <span style="font-weight: 400;">
         Hilgartner, S. (2000).
        </span>
        <i>
         <span style="font-weight: 400;">
          Science on stage: Expert advice as public drama
         </span>
        </i>
        <span style="font-weight: 400;">
         . Stanford University Press.
        </span>
       </p>
       <p>
        [5]
        <span style="font-weight: 400;">
         Diamond v Chakrabarty was in 1980, upheld first whole-scale organism patent (bacterium that could digest crude oil).
        </span>
       </p>
      </div>
      <p class="date">
       <a href="https://ctsp.berkeley.edu/backstage-decisions-front-stage-experts-interviewing-genome-editing-scientists/">
        by Anne Jonas at September 04, 2018 06:18 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    September 03, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3553">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/09/03/how-trade-protection-can-increase-labor-wages-the-stolper-samuelson-theorem/">
       How trade protection can increase labor wages (the Stolper-Samuelson theorem)
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I’m continuing a look into
        <a href="https://digifesto.com/tag/trade-policy/">
         trade policy
        </a>
        8/08/30/trade-policy-and-income-distribution-effects/”&gt;using Corden’s (1997) book on the topic.
       </p>
       <p>
        Picking up where
        <a href="https://digifesto.com/2018/08/30/trade-policy-and-income-distribution-effects/">
         the last post
        </a>
        left off, I’m operating on the assumption that any reader is familiar with the arguments for free trade that are an extension of those arguments of laissez-faire markets. I will assume that these arguments are true as far as they go: that the economy grows with free trade, that tariffs create a dead weight loss, that subsidies are expensive, but that both tariffs and subsidies do shift the market towards imports.
       </p>
       <p>
        The question raised by Corden is why, despite its deleterious effects on the economy as a whole, protectionism enjoys political support by some sectors of the economy. He hints, earlier in Chapter 5, that this may be due to income distribution effects. He clarifies this with reference to an answer to this question that was given as early as 1941 by Stolper and Samuelson; their result is now celebrated as the
        <a href="https://en.wikipedia.org/wiki/Stolper%E2%80%93Samuelson_theorem">
         Stolper-Samuelson theorem
        </a>
        .
       </p>
       <p>
        The mathematics of the theorem can be read in
        <a href="http://internationalecon.com/Trade/Tch60/T60-5.php">
         many
        </a>
        <a href="http://www.economicsdiscussion.net/theorems/stolper-samuelson-theorem-sst-theorems-economics/26931">
         places
        </a>
        . Like any economic model, it depends on some assumptions that may or may not be the case. Its main advantage is that it articulates how it is possible for protectionism to benefit a class of the population, and not just in relative but in absolute terms. It does this by modeling the returns to different
        <em>
         factors of production
        </em>
        , which classically have been
        <em>
         labor, land, and capital
        </em>
        .
       </p>
       <p>
        Roughly, the argument goes like this. Suppose and economy has two commodities, one for import and one for export. Suppose that the imported good is produced with a higher labor to land ratio than the export good. Suppose a protectionist policy increases the amount of the import good produced relative to the export good. Then the
        <em>
         return on labor will increase
        </em>
        (because more labor is used in supply), and
        <em>
         the return on land will decrease
        </em>
        (because less land is used in supply). Wages will increase and rent on land will decrease.
       </p>
       <p>
        These breakdowns of the economy into “factors of production” feels very old school. You rarely read economists discuss the economy in these terms now, which is itself interesting. One reason why (and I am only speculating here) is that these models clarify how laborers, land-owners, and capital-owners have different political interests in economic intervention, and that can lead to the kind of thinking that was flushed out of the American academy during the McCarthy era. Another reason may be that “capital” has changed meaning from being about ownership of machine goods into being about having liquid funds available for financial investment.
       </p>
       <p>
        I’m interested in these kinds of models today partly because I’m interested in the political interests in various policies, and also because I’m interested in particular in the economics of supply chain logistics. The “factors of production” approach is a crude way to model the ‘supply chain’ in a broad sense, but one that has proven to be an effective source of insights in the past.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Corden, W. Max. “Trade policy and economic welfare.” OUP Catalogue (1997).
       </p>
       <p>
        Stolper, Wolfgang F., and Paul A. Samuelson. “Protection and real wages.” The Review of Economic Studies 9.1 (1941): 58-73.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/09/03/how-trade-protection-can-increase-labor-wages-the-stolper-samuelson-theorem/">
        by Sebastian Benthall at September 03, 2018 05:55 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    August 30, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3545">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/08/30/trade-policy-and-income-distribution-effects/">
       trade policy and income distribution effects
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        <img alt="And now for something completely different" class="alignright" src="https://pics.me.me/and-now-for-something-completely-different-28704862.png" width="125"/>
       </p>
       <p>
        I am going to start researching trade policy, meaning policies around trade between different countries; imports and exports. Why?
       </p>
       <ul>
        <li>
         It is politically relevant in the U.S. today.
        </li>
        <li>
         It is a key component to national
         <em>
          cybersecurity
         </em>
         strategy, both defensive and offensive, which hinges in many cases on supply chain issues.
        </li>
        <li>
         It maybe ought to be a component of national tech regulation and privacy policy, if e-commerce is seen as a trade activity. (This could be see as ‘cybersecurity’ policy, more broadly writ).
        </li>
        <li>
         Formal models from trade policy may be informative in other domains as well.
        </li>
       </ul>
       <p>
        In general, years of life experience and study have taught me that economics, however much it is maligned, is a wise and fundamental social science without which any other understanding of politics and society is incomplete, especially when considering the role of technology in society.
       </p>
       <p>
        Plenty of good reasons! Onward!
       </p>
       <p>
        As a starting point, I’m working through Max Corden’s
        <em>
         Trade policy and social welfare
        </em>
        (1997), which appears to be a well regarded text on the subject. In it, he sets out to describe a normative theory of trade policy. Here are two notable points based on a first perusal.
       </p>
       <p>
        <strong>
         1.
        </strong>
        (from Chapter 1, “Introduction”) Corden identifies three “stages of thought” about trade policy. The first is the discovery of the benefits of free trade with the great original economists Adam Smith and David Ricardo. Here, the new appreciation of free trade was simultaneous with the new appreciation of the free market in general. “Indeed, the case for free trade was really a special case of the argument for laissez-faire.”
       </p>
       <p>
        In the second phase, laissez-faire policies came into question. These policies may not lead to full employment, and the income distribution effects (which Corden takes seriously throughout the book, by the way) may not be desirable. Parallel to this, the argument for free trade was challenged. Some of these challenges were endorsed by John Stuart Mill. One argument is that tariffs might be necessary to protect “infant industries”.
       </p>
       <p>
        As time went on, the favorability of free trade more or less tracked the favorability of laissez-faire. Both were popular in Western Europe and failed to get traction in most other countries (almost all of which were ‘developing’).
       </p>
       <p>
        Corden traces the third stage of thought to Meade’s (1955)
        <em>
         Trade and welfare
        </em>
        . “In the third stage
        <em>
         the link between the case for free trade and the case for laissez-faire was broken.
        </em>
        “. The normative case for free trade, in this stage, did not depend on a normative case for laissez-faire, but existed despite normative reasons for government intervention in the economy. The point made in this approach, called
        <em>
         the theory of domestic distortions
        </em>
        , is that it is generally better for the kinds of government intervention made to solve domestic problems to be domestic interventions, not trade interventions.
       </p>
       <p>
        This third stage came with a much more sophisticated toolkit for comparing the effects of different kinds of policies, which is the subject of exposition for a large part of Corden’s book.
       </p>
       <p>
        <strong>
         2.
        </strong>
        (from Chapter 5, “Protection and Income Distribution) Corden devotes at least one whole chapter to an aspect of the trade policy discussion that is very rarely addressed in, say, the mainstream business press. This is the fact that trade policy can have an effect on internal income distribution, and that this has been throughout history a major source of the
        <em>
         political
        </em>
        momentum for protectionist policies. This explains why the domestic politics of protectionism and free trade can be so heated and are really often independent from arguments about the effect of trade policy on
        <em>
         the economy as a whole
        </em>
        , which, it must be said, few people realize they have a real stake in.
       </p>
       <p>
        Corden’s examples involve the creation of fledgling industries under the conditions of war, which often cut off foreign supplies. When the war ends, those businesses that flourished during war exert political pressure to protect themselves from erosion from market forces. “Thus the Napoleonic Wars cut off supplies of corn (wheat) to Britain from the Continent and led to expansion of acreage and higher prices of corn. When the war was over, the Corn Law of 1815 was designed to maintain prices, with an import prohibition as long as the domestic price was below a certain level.” It goes almost without saying that this served the interests of a section of the community, the domestic corn farmers, and not of others. This is what Corden means by an “income distribution effect”.
       </p>
       <p>
        “Any history book will show that these income distribution effects are the very stuff of politics. The great free trade versus protection controversies of the nineteenth century in Great Britain and in the United States brought out the conflicting interests of different sections of the community. It was the debate about the effects of the Corn Laws which really stimulated the beginnings of the modern theory of international trade.”
       </p>
       <p>
        Extending this argument a bit, one might say that a major reason why economics gets such a bad rap as a social science is that nobody really cares about Pareto optimality except for those sections of the economy that are well served by a policy that can be justified as being Pareto optimal (in practice, this would seem to be correlated with how much somebody has invested in mutual funds, as these track economic growth). The “stuff of politics” is people using political institutions to change their income outcomes, and the potential for this makes trade policy a very divisive topic.
       </p>
       <p>
        <strong>
         Implication for future research:
        </strong>
       </p>
       <p>
        The two key takeaways for trade policy in cybersecurity are:
       </p>
       <p>
        1) The trade policy discussion need not remain within the narrow frame of free trade versus protectionism, but rather a more nuanced set of policy analysis tools should be brought to bear on the problem, and
       </p>
       <p>
        2) An outcome of these policy analyses should be the identification not just of total effects on the economy, or security posture, or what have you, but on the particular effects on different sections of the economy and population.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Corden, W. Max. “Trade policy and economic welfare.” OUP Catalogue (1997).
       </p>
       <p>
        Meade, James Edward. Trade and welfare. Vol. 2. Oxford University Press, 1955.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/08/30/trade-policy-and-income-distribution-effects/">
        by Sebastian Benthall at August 30, 2018 08:49 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    August 21, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://ctsp.berkeley.edu" title="CTSP">
       Citizen Technologist
      </a>
     </div>
     <div class="channel-affiliation">
      Center for Technology, Society &amp; Policy
     </div>
    </div>
    <div class="entrygroup" id="https://ctsp.berkeley.edu/?p=1814">
     <h4 class="posttitle" lang="en-US">
      <a href="https://ctsp.berkeley.edu/standing-up-for-truth-in-the-age-of-disinformation/">
       Standing up for truth in the age of disinformation
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <p>
        Professor
        <a href="https://www.ischool.berkeley.edu/people/deirdre-mulligan">
         Deirdre K. Mulligan
        </a>
        and PhD student (and CTSP Co-Director)
        <a href="https://www.ischool.berkeley.edu/people/daniel-griffin">
         Daniel Griffin
        </a>
        have an op-ed in The Guardian considering how Google might consider its human rights obligations in the face of state censorship demands:
        <a href="https://www.theguardian.com/commentisfree/2018/aug/21/google-china-search-tiananmen-square-massacre">
         If Google goes to China, will it tell the truth about Tiananmen Square?
        </a>
       </p>
       <p>
        The op-ed advances a line of argument developed in a recent article of theirs in the
        <a href="https://www.georgetownlawtechreview.org/volume-2-issue-2/">
         Georgetown Law Technology Review
        </a>
        :
        <a href="https://www.georgetownlawtechreview.org/rescripting-search-to-respect-the-right-to-truth/GLTR-07-2018/">
         “Rescripting Search to Respect the Right to Truth”
        </a>
       </p>
      </div>
      <p class="date">
       <a href="https://ctsp.berkeley.edu/standing-up-for-truth-in-the-age-of-disinformation/">
        by Daniel Griffin at August 21, 2018 10:28 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    August 16, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://ctsp.berkeley.edu" title="CTSP">
       Citizen Technologist
      </a>
     </div>
     <div class="channel-affiliation">
      Center for Technology, Society &amp; Policy
     </div>
    </div>
    <div class="entrygroup" id="https://ctsp.berkeley.edu/?p=1803">
     <h4 class="posttitle" lang="en-US">
      <a href="https://ctsp.berkeley.edu/unpitchday2018/">
       Social Impact Un-Pitch Day 2018
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <p>
        <span style="font-weight: 400;">
         On Thursday, October 4th at 5:30pm the
        </span>
        <a href="https://ctsp.berkeley.edu/">
         <span style="font-weight: 400;">
          Center for Technology, Society &amp; Policy (CTSP)
         </span>
        </a>
        <span style="font-weight: 400;">
         and the School of Information’s
        </span>
        <a href="http://groups.ischool.berkeley.edu/imsa/">
         <span style="font-weight: 400;">
          Information Management Student Association (IMSA)
         </span>
        </a>
        <span style="font-weight: 400;">
         are co-hosting their
        </span>
        <b>
         third annual
        </b>
        <b>
         Social Impact Un-Pitch Day!
        </b>
       </p>
       <p>
        <span style="font-weight: 400;">
         Join CTSP and IMSA to brainstorm ideas for projects that address the challenges of technology, society, and policy. We welcome students, community organizations, local municipal partners, faculty, and campus initiatives to discuss discrete problems that project teams can take on over the course of this academic year. Teams will be encouraged to apply to CTSP to fund their projects.
        </span>
       </p>
       <p>
        <strong>
         Location:
        </strong>
        Room 202, in
        <a href="https://www.berkeley.edu/map?south">
         South Hall
        </a>
        .
       </p>
       <p>
        <a href="https://goo.gl/forms/jIYH0nwcgJSOvXLm2">
         <span style="font-weight: 400;">
          RSVP here!
         </span>
        </a>
       </p>
       <h2>
        <b>
         Agenda
        </b>
       </h2>
       <ul>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          5:40 Introductions from IMSA and CTSP
         </span>
        </li>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          5:45 Example Projects
         </span>
        </li>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          5:50 Sharing Un-Pitches
         </span>
        </li>
       </ul>
       <p style="padding-left: 60px;">
        <span style="color: #ff0000;">
         <strong>
          We’ve increased the time for Un-Pitches! (Still 3-minutes per Un-Pitch)
         </strong>
        </span>
       </p>
       <ul>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          6:40 Mixer (with snacks and refreshments)
         </span>
        </li>
       </ul>
       <p>
       </p>
       <h2>
        <b>
         Un-Pitches
        </b>
       </h2>
       <p>
        <span style="font-weight: 400;">
         Un-Pitches are meant to be informal and brief introductions of yourself, your idea, or your organization’s problem situation. Un-pitches can include designing technology, research, policy recommendations, and more. Students and social impact representatives will be given
        </span>
        <span style="color: #ff0000;">
         <b>
          3 minutes
         </b>
        </span>
        <span style="font-weight: 400;">
         to present their Un-Pitch. In order to un-pitch, please share 1-3 slides, as PDF and/or a less than 500-word description—at this email:
        </span>
        <a href="mailto:ctsp@berkeley.edu">
         <span style="font-weight: 400;">
          ctsp@
          <span class="oe_displaynone">
           null
          </span>
          berkeley.edu
         </span>
        </a>
        <span style="font-weight: 400;">
         . You can share slides and/or description of your ideas even if you aren’t able to attend. Deadline to share materials:
        </span>
        <b>
         midnight October 1st, 2018
        </b>
        <span style="font-weight: 400;">
         .
        </span>
       </p>
       <h2>
        <b>
         Funding Opportunities
        </b>
       </h2>
       <p>
        <span style="font-weight: 400;">
         The next application round for fellows will open in November. CTSP’s fellowship program will provide small grants to individuals and small teams of fellows for 2019. CTSP also has a recurring offer of small project support.
        </span>
       </p>
       <h2>
        <b>
         Prior Projects &amp; Collaborations
        </b>
       </h2>
       <p>
        <span style="font-weight: 400;">
         Here are several examples of projects that members of the I School community have pursued as
        </span>
        <a href="https://www.ischool.berkeley.edu/programs/mims/projects">
         <span style="font-weight: 400;">
          MIMS final projects
         </span>
        </a>
        <span style="font-weight: 400;">
         or CTSP Fellow projects (see more projects from
        </span>
        <a href="https://ctsp.berkeley.edu/projects/">
         <span style="font-weight: 400;">
          2016
         </span>
        </a>
        <span style="font-weight: 400;">
         ,
        </span>
        <a href="https://ctsp.berkeley.edu/projects2017/">
         <span style="font-weight: 400;">
          2017
         </span>
        </a>
        <span style="font-weight: 400;">
         , and
        </span>
        <a href="https://ctsp.berkeley.edu/projects2018/">
         <span style="font-weight: 400;">
          2018
         </span>
        </a>
        <span style="font-weight: 400;">
         ).
        </span>
       </p>
       <ul>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          A team of MIMS students partnered with a local non-profit working with vulnerable populations to build their information and communication capacity:
         </span>
         <a href="https://www.ischool.berkeley.edu/projects/2016/yakap">
          <span style="font-weight: 400;">
           Yakap
          </span>
         </a>
        </li>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          A team of MIMS students partnered with the Center for Democracy and Technology to research perceptions of algorithmic personalization:
         </span>
         <a href="https://ctsp.berkeley.edu/projects/#algorithmicdecisions">
          <span style="font-weight: 400;">
           “A User-Centered Perspective on Algorithmic Personalization”
          </span>
         </a>
        </li>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          A team of first and second year MIMS students and an I School PhD student partnered with a local organization to study the workings of the Oakland Privacy Advisory Commission. This project culminated in a report presented to the commission and multiple tools designed as a resource for cities and citizens:
         </span>
         <a href="https://ctsp.berkeley.edu/projects2017/#surveillanceandpolicing">
          <span style="font-weight: 400;">
           Increasing Transparency into the Capabilities of Surveillance and Policing Technologies
          </span>
         </a>
        </li>
        <li style="font-weight: 400;">
         <span style="font-weight: 400;">
          A team of MIMS students, partnered with an international non-profit and traveled to Nepal to conduct user research in support of the design of a sociotechnical data collection system:
         </span>
         <a href="https://ctsp.berkeley.edu/projects2018/#matriRaksha">
          <span style="font-weight: 400;">
           Matri-Raksha: Digital Data Collection for Maternal and Perinatal Healthcare in Rural Nepal
          </span>
         </a>
        </li>
       </ul>
       <p>
       </p>
       <h2>
        <b>
         Skills &amp; Interests of Students
        </b>
       </h2>
       <p>
        <span style="font-weight: 400;">
         The above projects demonstrate a range of interests and skills of the I School community. Students here and more broadly on the UC Berkeley campus are interested and skilled in all aspects of where information and technology meets people—from design and data science, to user research and information policy.
        </span>
       </p>
       <h2>
        <span style="text-decoration: underline;">
         <a href="https://goo.gl/forms/jIYH0nwcgJSOvXLm2">
          <b>
           RSVP here!
          </b>
         </a>
        </span>
       </h2>
      </div>
      <p class="date">
       <a href="https://ctsp.berkeley.edu/unpitchday2018/">
        by Daniel Griffin at August 16, 2018 03:51 AM
       </a>
      </p>
     </div>
    </div>
    <div class="entrygroup" id="https://ctsp.berkeley.edu/?p=1800">
     <h4 class="posttitle" lang="en-US">
      <a href="https://ctsp.berkeley.edu/habeas-data-panel-discussion/">
       August 30th, 5:30pm: Habeas Data Panel Discussion
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en-US">
       <h2>
        Location: South Hall Rm 202
       </h2>
       <h3>
        Time: 5:30-7pm (followed by light refreshments)
       </h3>
       <h3>
        CTSP’s first event of the semester!
       </h3>
       <h3>
        Co-Sponsored with the
        <strong>
         <a href="https://cltc.berkeley.edu/2018/08/16/rsvp-for-habeas-data-panel-discussion-with-cyrus-farivar-8-30-530pm/" rel="noopener" target="_blank">
          Center for Long-Term Cybersecurity
         </a>
        </strong>
       </h3>
       <p>
        Please join us for a panel discussion featuring award-winning tech reporter Cyrus Farivar, whose new book,
        <em>
         <a href="https://cyrusfarivar.com/blog/2018-book-tour/" rel="noopener" target="_blank">
          Habeas Data
         </a>
        </em>
        , explores how the explosive growth of surveillance technology has outpaced our understanding of the ethics, mores, and laws of privacy.
        <em>
         Habeas Data
        </em>
        explores ten historic court decisions that defined our privacy rights and matches them against the capabilities of modern technology. Mitch Kapor, co-founder, Electronic Frontier Foundation, said the book was “Essential reading for anyone concerned with how technology has overrun privacy.”
       </p>
       <p>
        The panel will be moderated by 2017 and 2018 CTSP Fellow
        <a href="https://www.linkedin.com/in/trushs" rel="noopener" target="_blank">
         Steve Trush
        </a>
        , a MIMS 2018 graduate and now a Research Fellow at the Center for Long-Term Cybersecurity (CLTC). He was on a
        <a href="https://ctsp.berkeley.edu/projects2017/#surveillanceandpolicing">
         CTSP project
        </a>
        starting in 2017 that provided a report to the Oakland Privacy Advisory Commission—read an
        <em>
         East Bay Express
        </em>
        write-up on their work
        <a href="https://www.ischool.berkeley.edu/news/2018/berkeley-i-school-students-map-oaklands-police-data" rel="noopener" target="_blank">
         here
        </a>
        .
       </p>
       <p>
        <span style="font-weight: 400;">
         The panelists will discuss what public governance models can help local governments protect the privacy of citizens—and what role citizen technologists can play in shaping these models. The discussion will showcase the ongoing collaboration between the UC Berkeley School of Information and the
        </span>
        <a href="http://www2.oaklandnet.com/government/o/CityAdministration/d/PrivacyAdvisoryCommission/index.htm">
         <span style="font-weight: 400;">
          Oakland Privacy Advisory Commission
         </span>
        </a>
        <span style="font-weight: 400;">
         (OPAC). Attendees will learn how they can get involved in addressing issues of governance, privacy, fairness, and justice related to state surveillance.
        </span>
        <span style="font-weight: 400;">
         <br/>
        </span>
       </p>
       <h3>
        <strong>
         Panel:
        </strong>
       </h3>
       <ul>
        <li>
         <strong>
          Cyrus Farivar
         </strong>
         , Author, Habeas Data: Privacy vs. the Rise of Surveillance Tech
        </li>
        <li>
         <strong>
          Deirdre Mulligan
         </strong>
         , Associate Professor in the School of Information at UC Berkeley, Faculty Director, UC Berkeley Center for Law &amp; Technology
        </li>
        <li>
         <strong>
          Catherine Crump
         </strong>
         , Assistant Clinical Professor of Law, UC Berkeley; Director, Samuelson Law, Technology &amp; Public Policy Clinic.
        </li>
        <li>
         <strong>
          Camille Ochoa
         </strong>
         , Coordinator, Grassroots Advocacy; Electronic Frontier Foundation
        </li>
        <li>
         Moderated by
         <strong>
          Steve Trush
         </strong>
         , Research Fellow, UC Berkeley Center for Long-Term Cybersecurity
        </li>
       </ul>
       <p>
        The panel will be followed by a reception with light refreshments. Building is wheelchair accessible – wheelchair users can enter through the ground floor level and take the elevator to the second floor.
       </p>
       <p>
        This event will
        <em>
         not
        </em>
        be taped or live-streamed.
       </p>
       <h2>
        <a href="https://docs.google.com/forms/d/e/1FAIpQLSe0rJXDtEfDqlOu_rL6d7DLjExt5aa4G8guSHZ9BA17GI57Uw/viewform">
         <span style="color: #ff9900;">
          RSVP
          <strong>
           here
          </strong>
          to attend.
         </span>
        </a>
       </h2>
       <p>
       </p>
       <h3>
        <strong>
         Panelist Bios:
        </strong>
       </h3>
       <p>
        <b>
         Cyrus [“suh-ROOS”] Farivar
        </b>
        <span style="font-weight: 400;">
         is a Senior Tech Policy Reporter at Ars Technica, and is also an author and radio producer. His second book,
        </span>
        <a href="http://www.habeasdatabook.com">
         <i>
          <span style="font-weight: 400;">
           Habeas Data
          </span>
         </i>
        </a>
        <span style="font-weight: 400;">
         , about the legal cases over the last 50 years that have had an outsized impact on surveillance and privacy law in America, is out now from Melville House. His first book,
        </span>
        <a href="http://www.amazon.com/The-Internet-Elsewhere-Emergent-Effects/dp/0813549620">
         <i>
          <span style="font-weight: 400;">
           The Internet of Elsewhere
          </span>
         </i>
        </a>
        <span style="font-weight: 400;">
         —about the history and effects of the Internet on different countries around the world, including Senegal, Iran, Estonia and South Korea—was published in April 2011. He previously was the Sci-Tech Editor, and host of “Spectrum” at Deutsche Welle English, Germany’s international broadcaster. He has also reported for the Canadian Broadcasting Corporation, National Public Radio, Public Radio International, The Economist, Wired, The New York Times and many others. His PGP key and other secure channels are available
        </span>
        <a href="http://arstechnica.com/ars-staff-pgp-keys/#cyrus-farivar">
         <span style="font-weight: 400;">
          here.
         </span>
        </a>
       </p>
       <p>
        <b>
         Deirdre K. Mulligan
        </b>
        <span style="font-weight: 400;">
         is an Associate Professor in the School of Information at UC Berkeley, a faculty Director of the
        </span>
        <a href="https://www.law.berkeley.edu/research/bclt/">
         <span style="font-weight: 400;">
          Berkeley Center for Law &amp; Technology
         </span>
        </a>
        <span style="font-weight: 400;">
         , and an affiliated faculty on the
        </span>
        <a href="https://cltc.berkeley.edu/">
         <span style="font-weight: 400;">
          Center for Long-Term Cybersecurity
         </span>
        </a>
        <span style="font-weight: 400;">
         .  Mulligan’s research explores legal and technical means of protecting values such as privacy, freedom of expression, and fairness in emerging technical systems.  Her book,
        </span>
        <a href="https://mitpress.mit.edu/books/privacy-ground">
         <span style="font-weight: 400;">
          Privacy on the Ground: Driving Corporate Behavior in the United States and Europe
         </span>
        </a>
        <span style="font-weight: 400;">
         , a study of privacy practices in large corporations in five countries, conducted with UC Berkeley Law Prof. Kenneth Bamberger was recently published by MIT Press. Mulligan and  Bamberger received the 2016
        </span>
        <a href="https://iapp.org/about/annual-awards/iapp-privacy-leadership-award/">
         <span style="font-weight: 400;">
          International Association of Privacy Professionals Leadership Award
         </span>
        </a>
        <span style="font-weight: 400;">
         for their research contributions to the field of privacy protection.
        </span>
       </p>
       <p>
        <b>
         Catherine Crump:
        </b>
        <span style="font-weight: 400;">
         Catherine Crump is an Assistant Clinical Professor of Law and Director of the Samuelson Law, Technology &amp; Public Policy Clinic. An experienced litigator specializing in constitutional matters, she has represented a broad range of clients seeking to vindicate their First and Fourth Amendment rights. She also has extensive experience litigating to compel the disclosure of government records under the Freedom of Information Act. Professor Crump’s primary interest is the impact of new technologies on civil liberties. Representative matters include serving as counsel in the ACLU’s challenge to the National Security Agency’s mass collection of Americans’ call records; representing artists, media outlets and others challenging a federal internet censorship law, and representing a variety of clients seeking to invalidate the government’s policy of conducting suspicionless searches of laptops and other electronic devices at the international border.
        </span>
       </p>
       <p>
        <span style="font-weight: 400;">
         Prior to coming to Berkeley, Professor Crump served as a staff attorney at the ACLU for nearly nine years. Before that, she was a law clerk for Judge M. Margaret McKeown at the United States Court of Appeals for the Ninth Circuit.
        </span>
       </p>
       <p>
        <b>
         Camille Ochoa
        </b>
        <span style="font-weight: 400;">
         :
        </span>
        <a href="https://www.eff.org/about/staff/camille-ochoa">
         <span style="font-weight: 400;">
          Camille
         </span>
        </a>
        <span style="font-weight: 400;">
         promotes the Electronic Frontier Foundation’s grassroots advocacy initiative (the
        </span>
        <a href="https://www.eff.org/electronic-frontier-alliance">
         <span style="font-weight: 400;">
          Electronic Frontier Alliance
         </span>
        </a>
        <span style="font-weight: 400;">
         ) and coordinates outreach to student groups, community groups, and hacker spaces throughout the country. She has very strong opinions about food deserts, the school-to-prison pipeline, educational apartheid in America, the takeover of our food system by chemical companies, the general takeover of everything in American life by large conglomerates, and the right to not be spied on by governments or corporations.
        </span>
       </p>
      </div>
      <p class="date">
       <a href="https://ctsp.berkeley.edu/habeas-data-panel-discussion/">
        by Daniel Griffin at August 16, 2018 03:50 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    August 12, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3542">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/08/11/the-politicization-of-the-social-and-politics-of-identity-in-omi-and-winant-cha-6/">
       “the politicization of the social” and “politics of identity” in Omi and Winant, Cha. 6
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        A confusing debate in my corner of the intellectual Internet is about (a) whether the progressive left has a coherent intellectual stance that can be articulated, (b) what to call this stance, (c) whether the right-wing critics of this stance have the intellectual credentials to refer to it and thereby land any kind of rhetorical punch. What
        <em>
         may
        </em>
        be true is that both “sides” reflect social movements more than they reflect coherent philosophies as such, and so trying to bridge between them intellectually is fruitless.
       </p>
       <p>
        Happily, reading through
        <a href="https://digifesto.com/tag/omi-and-winant/">
         Omi and Winant
        </a>
        , which among other things outlines a history of what I think of as the progressive left, or the “social justice”, “identity politics” movement in the United States. They address this in their
        <a href="https://books.google.com/books?id=T7LcAwAAQBAJ&amp;lpg=PA163&amp;ots=k5xVxQtSZg&amp;dq=%22great%20transformation%22%20racial&amp;pg=PA161#v=onepage&amp;q=%22great%20transformation%22%20racial&amp;f=false">
         Chapter 6
        </a>
        : “The Great Transformation”. They use “the Great Transformation” to refer to “racial upsurges” in the 1950’s and 1960’s.
       </p>
       <p>
        They are, as far as I can tell, the only people who ever use “The Great Transformation” to refer to this period. I don’t think it is going to stick. They name it this because they see this period as a great victorious period for democracy in the United States. Omi and Winant refer to previous periods in the United States as “racial despotism”, meaning that the state was actively treating nonwhites as second class citizens and preventing them from engaging in democracy in a real way. “Racial democracy”, which would involve true integration across race lines, is an ideal future or political trajectory that was approached during the Great Transformation but not realized fully.
       </p>
       <p>
        The story of the civil rights movements in the mid-20th century are textbook material and I won’t repeat Omi and Winant’s account, which is interesting for a lot of reasons. One reason why it is interesting is how explicitly influenced by Gramsci their analysis is. As the “despotic” elements of United States power structures fade, the racial order is maintained less by coercion and more by consent. A power disparity in social order maintained by consent is a
        <em>
         hegemony
        </em>
        , in Gramscian theory.
       </p>
       <p>
        They explain the Great Transformation as being due to two factors. One was the decline of the
        <a href="https://digifesto.com/2018/06/06/notes-on-omi-and-winant-2014-ethnicity/">
         ethnicity paradigm
        </a>
        of race, which had perhaps naively assumed that racial conflicts could be resolved through assimilation and recognition of ethnic differences without addressing the politically entrenched mechanisms of racial stratification.
       </p>
       <p>
        The other factor was the rise of new social movements characterized by, in alliance with second-wave feminism, the
        <em>
         politicization of the social
        </em>
        , whereby social identity and demographic categories were made part of the public political discourse, rather than something private. This is the birth of “politics of identity”, or “identity politics”, for short. These were the original social justice warriors. And they attained some real political victories.
       </p>
       <p>
        The reason why these social movements are not exactly normalized today is that there was a conservative reaction to resist changes in the 70’s. The way Omi and Winant tell it, the “colorblind ideology” of the early 00’s was culmination of a kind of political truce between “racial despotism” and “racial democracy”–a “racial hegemony”. Gilman has
        <a href="https://www.the-american-interest.com/2018/03/02/collapse-racial-liberalism/">
         called this
        </a>
        “racial liberalism”.
       </p>
       <p>
        So what does this mean for identity politics today?  It means it has its roots in political activism which was once very radical. It really is influenced by Marxism, as these movements were. It means that its co-option by the right is not actually new, as “reverse racism” was one of the inventions of the groups that originally resisted the Civil Rights movement in the 70’s. What’s new is the crisis of hegemony, not the constituent political elements that were its polar extremes, which have been around for decades.
       </p>
       <p>
        What it also means is that identity politics has been, from its start, a tool for political mobilization. It is not a philosophy of knowledge or about how to live the good life or a world view in a richer sense. It serves a particular instrumental purpose. Omi and Winant talk about the politics of identity is “attractive”, that it is a contagion. These are positive terms for them; they are impressed at how anti-racism spreads. These days I am often referred to Phillips’
        <a href="https://datasociety.net/output/oxygen-of-amplification/">
         report
        </a>
        , “The Oxygen of Amplification”, which is about preventing the spread of extremist views by reducing the amount of reporting on them in ‘disgust’. It must be fair to point out that identity politics as a left-wing innovation were at one point an “extremist” view, and that proponents of that view do use media effectively to spread it. This is just how media-based organizing tactics work, now.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/08/11/the-politicization-of-the-social-and-politics-of-identity-in-omi-and-winant-cha-6/">
        by Sebastian Benthall at August 12, 2018 03:44 AM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    August 07, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3539">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/08/07/racial-projects-and-racism-omi-and-winant-2014-jeong-case-study/">
       Racial projects and racism (Omi and Winant, 2014; Jeong case study)
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Following up on earlier posts on
        <a href="https://digifesto.com/tag/omi-and-winant/">
         Omi and Winant
        </a>
        , I’ve gotten to the part where they discuss
        <em>
         racial projects
        </em>
        and
        <em>
         racism
        </em>
        .
       </p>
       <p>
        Because I use Twitter, I have not been able to avoid the discussion of Sarah Jeong’s tweets. I think it provides a useful case study in Omi and Winant’s terminology. I am not a journalist or particularly with-it person, so I have encountered this media event mainly through articles about it.
        <a href="https://www.motherjones.com/kevin-drum/2018/08/are-we-no-longer-allowed-to-mock-white-men/">
         Here
        </a>
        <a href="http://nymag.com/daily/intelligencer/2018/08/sarah-jeong-new-york-times-anti-white-racism.html">
         are
        </a>
        <a href="https://www.salon.com/2018/08/04/andrew-sullivan-plays-himself-proves-racist-tweets-by-new-york-times-hire-were-innocent/">
         some
        </a>
        .
       </p>
       <p>
        To recap, for Omi and Winant, race is a “master category” of social organization, but nevertheless one that is unstable and politically contested. The continuity of racial classification is due to a historical, mutually reinforcing process that includes
        <em>
         both
        </em>
        social structures that control the distribution of resources
        <em>
         and
        </em>
        social meanings and identities that have been acquired by properties of people’s bodies. The fact that race is sustained through this historical and semiotically rich structuration (to adopt a term from Giddens), means that
       </p>
       <blockquote>
        <p>
         “To identify an individual or group racially is to locate them within a socially and historically demarcated set of demographic and cultural boundaries, state activities, “life-chances”, and tropes of identity/difference/(in)equality.
        </p>
       </blockquote>
       <blockquote>
        <p>
         “We cannot understand how racial representations set up patterns of residential segregation, for example, without considering how segregation reciprocally shapes and reinforces the meaning of race itself.”
        </p>
       </blockquote>
       <p>
        This is totally plausible. Identifying the way that racial classification depends on a relationship between meaning and social structure opens the possibility of human political agency in the (re)definition of race. Omi and Winant’s term for these racial acts is
        <strong>
         racial projects
        </strong>
        .
       </p>
       <blockquote>
        <p>
         A racial project is simultaneously an interpretation, representation, or explanation of racial identities and meanings, and an effort to organize and distribute resources (economic, political, cultural) along particular racial lines.
         <br/>
         … Racial projects connect the meaning of race in discourse and ideology with the way that social structures are racially organized.
        </p>
       </blockquote>
       <p>
        “Racial project” is a broad category that can include both large state and institutional interventions and individual actions. “even the decision to wear dreadlocks”. What makes them racial projects is how they reflect and respond to broader patterns of race, whether to reproduce it or to subvert it. Prevailing stereotypes are one of the main ways we can “read” the racial meanings of society, and so the perpetuation of subversion of stereotypes is a form of “racial project”. Racial projects are often in contest with each other; the racial formation process
        <em>
         is
        </em>
        the interaction and accumulation of these projects.
       </p>
       <p>
        Racial project is a useful category partly because it is key to Omi and Winant’s definition of
        <em>
         racism
        </em>
        . They acknowledge that the term itself is subject to “enormous debate”, at times inflated to be meaningless and at other times deflated to be too narrow. They believe the definition of racism as “racial
        <em>
         hate
        </em>
        ” is too narrow, though it has gain legal traction as a category, as in when “hate crimes” are considered an offense with enhanced sentencing, or universities institute codes against “hate speech”. I’ve read “racial animus” as another term that means something similar, though perhaps more subtle, than ‘racial hate’.
       </p>
       <p>
        The narrow definition of racism as racial hate is rejected due to an argument O&amp;W attribute to David Theo Goldberg (1997), which is that by narrowly focusing on “crimes of passion” (I would gloss this more broadly to ‘psychological states’), the interpretation of racism misses the ideologies, policies, and practices that “normalize and reproduce racial inequality and domination”. In other words, racism, as a term, has to reference the social structure that is race in order to adequate.
       </p>
       <p>
        Omi and Winant define racism thus:
       </p>
       <blockquote>
        <p>
         A racial project can be defined as
         <em>
          racist
         </em>
         if it creates or reproduces structures of domination based on racial significance and identities.
        </p>
       </blockquote>
       <p>
        A key implication of their argument is that
        <em>
         not all racial projects are racist
        </em>
        . Recall that Omi and Winant are very critical of
        <em>
         colorblindness
        </em>
        as (they allege) a political hegemony. They want to make room for racial solidarity and agency despite the hierarchical nature of race as a social fact. This allows them to answer two important questions.
       </p>
       <p>
        <em>
         Are there anti-racist projects?
        </em>
        Yes. “[w]e define anti-racist projects as those that
        <em>
         undo or resist structures of domination based on racial significations and identities.
        </em>
        ”
       </p>
       <p>
        Note that the two definitions are not exactly parallel in construction. To “create and reproduce structure” is not entirely the opposite of “undo or resist structure”. Given O&amp;W’s ontology, and the fact that racial structure is always the accumulation of a long history of racial projects, projects that have been performed by (bluntly) both the right and the left, and given that social structure is not homogeneous across location (consider how race is different in the United States and in Brazil, or different in New York City and in Dallas), and given that an act of resistance is also an act of creation, implicitly, one could easily get confused trying to apply these definitions. The key word, “domination”, is not defined precisely, and everything hinges on this. It’s clear from the writing that Omi and Winant subscribe to the “left” view of how racial domination works; this orients their definition of racism concretely. But they also not that the political agency of people of color in the United States over the past hundred years or so has gained them political power. Isn’t the key to being racist having power? This leads O&amp;W to the second question, which is
       </p>
       <p>
        <em>
         Can Group of Color Advance Racist Projects?
        </em>
        O&amp;W’s answer is, yes, they can. There are exceptions to the hierarchy of white supremacy, and in these exceptions there can be racial conflicts where a group of color is racist. Their example is in cases where blacks and Latinos are in contest over resources. O&amp;W do not go so far as to say that it is possible to be racist against white people, because they believe all racial relations are shaped by the overarching power of white supremacy.
       </p>
       <h4>
        Case Study: Jeong’s tweets
       </h4>
       <p>
        That is the setup. So what about Sarah Jeong? Well, she wrote some tweets mocking white people, and specifically white men, in 2014, which was by the way the heyday of obscene group conflict on Twitter. That was the year of Gamergate. A whole year of tweets that are probably best forgotten. She compared white people to goblins, she compared them the dogs. She said she wished ill on white men. As has been pointed out, if any other group besides white men were talked about, her tweets would be seen as undeniably racist, etc. They are, truth be told, similar rhetorically to the kinds of tweets that the left media have been so appalled at for some time.
       </p>
       <p>
        They have surfaced again because Jeong was hired by the New York Times, and right wing activists (or maybe just trolls, I’m a little unclear about which) surfaced the old tweets. In the political climate of 2018, when Internet racism feels like it’s gotten terribly real, these struck a chord and triggered some reflection.
       </p>
       <p>
        What should we make of these tweets, in light of racial formation theory?
       </p>
       <p>
        First, we should acknowledge that the New York Times has some really great lawyers working for it. Their statement was the at the time, (a) Jeong was being harassed, (b) that she responded to them in the same rhetorical manner of the harassment, that (c) that’s regrettable, but also, it’s long past and not so bad. Sarah Jeong’s
        <a href="https://twitter.com/sarahjeong/status/1025050118989332480">
         own statement
        </a>
        makes this point, acknowledges that the tweets may be hurtful out of context, and that she didn’t mean them the way others could take them. “
        <a href="https://definitions.uslegal.com/h/harassment/">
         Harassment
        </a>
        ” is actually a relatively neutral term; you can harass somebody, legally speaking, on the basis of their race without invoking a reaction from anti-racist sociologists. This is all perfectly sensible, IMO, and the case is pretty much closed.
       </p>
       <p>
        But that’s not where the discussion on the Internet ended. Why? Because the online media is where the contest of racial formation is happening.
       </p>
       <p>
        We can ask: Were Sarah Jeong’s tweets a
        <em>
         racial project
        </em>
        ? The answer seems to be, yes, they were. It was a representation of racial identity (whiteness) “to organize and distribute resources (economic, political, cultural) along particular racial lines”. Jeong is a journalist and scholar, and these arguments are happening in social media, which are always-already part of the capitalist attention economy. Jeong’s success is partly due to her confrontation of on-line harassers and responses to right-wing media figures. And her activity is the kind that rallies attention along racial lines–anti-racist, racist, etc.
       </p>
       <p>
        Confusingly, the language she used in these tweets reads as hateful. “Dumbass fucking white people marking up the internet with their opinions like dogs pissing on fire hydrants” does, reasonably, sound like it expresses some racial animus. If we were to accept the definition of racism as
        <em>
         merely
        </em>
        the possession of ill will towards a race, which seems to be Andrew Sullivan’s
        <a href="http://nymag.com/daily/intelligencer/2018/08/sarah-jeong-new-york-times-anti-white-racism.html">
         definition
        </a>
        , then we would have to say those were racist tweets.
       </p>
       <p>
        We could invoke a defense here. Were the tweets satire? Did Jeong not actually have any ill will towards white people? One might wonder, similarly, whether 4chan anti-Semites are actually anti-Semitic or just trolling. The whole question of who is just trolling and who should be taken seriously on the Internet is such an interesting one. But it’s one I had to walk away from long ago after
        <a href="https://digifesto.com/2012/10/18/weird-twitter-art-experiment-method-notes-and-observations/">
         the heat got turned up on me
        </a>
        one time. So it goes.
       </p>
       <p>
        What everyone knows is at stake, though, is the contention that the ‘racial animus’ definition is not the real definition of racism, but rather that something like O&amp;W’s definition is. By their account, (a) a racial project is only racist if it aligns with structures of racial domination, and (b) the structure of racial domination is a white supremacist one. Ergo, by this account, Jeong’s tweets are
        <em>
         not
        </em>
        racist, because insulting white people does not create or reproduce structures of white supremacist domination.
       </p>
       <p>
        It’s worth pointing out that there are two different definitions of a word here and that neither one is inherently more correct of a definition. I’m hesitant to label the former definition “right” and the latter definition “left” because there’s nothing about the former definition that would make you, say, not want to abolish the cradle-to-prison system or any number of other real, institutional reforms. But the latter definition is favored by progressives, who have a fairly coherent world view. O&amp;W’s theorizing is consistent with it. The helpful thing about this worldview is that it makes it difficult to complain about progressive rhetorical tactics without getting mired into a theoretical debate about their definitions, which makes it an excellent ideology for getting into fights on the Internet. This is largely what Andrew Sullivan was getting at in his critique.
       </p>
       <p>
        What Jeong and the NYT seem to get, which some others don’t, is that comments that insult an entire race can be hurtful and bothersome even if they are not racist in the progressive sense of the term. It is not clear what we should call a racial project that is hurtful and bothersome to white people if we do not call it racist. A difficulty with the progressive definition of racism is that agreement on the application of the term is going to depend on agreement about what the dominate racial structures are. What we’ve learned in the past few years is that the left-wing view of what these racial structures are is not as widely shared as it was believed to be. Example, there are far more people who believe in anti-Semitic conspiracies, in which the dominant race is the Jews, active in American political life than was supposed. Given O&amp;W’s definition of racism, if it were, factually, the case that Jews ran the world, then anti-Semitic comments would not be racist in the meaningful sense.
       </p>
       <p>
        Which means that the progressive definition of racism, to be effective, depends on widespread agreement about white supremacist hegemony, which is a much, much more complicated thing to try to persuade somebody of than a particular person’s racial animus.
       </p>
       <p>
        A number of people have been dismissing any negative reaction to the resurfacing of Jeong’s tweets, taking the opportunity to disparage that reaction as misguided and backwards. As far as I can tell, there is an argument that Jeong’s tweets are actually
        <em>
         anti-racist
        </em>
        . This
        <a href="https://www.vox.com/policy-and-politics/2018/8/3/17648566/sarah-jeong-new-york-times-twitter-andrew-sullivan">
         article
        </a>
        argues that casually disparaging white men is just something anti-racists do lightly to call attention to the dominant social structures and also the despicable behavior of some white men. Naturally, these comments are meant humorously, and not intended to refer to all white men (to assume it does it to distract from the structural issues at stake). They are jokes that should be celebrated, because the the progressives have already won this argument over #notallmen, also in 2014. Understood properly as progressive, anti-racist, social justice idiom, there is nothing offensive about Jeong’s tweets.
       </p>
       <p>
        I am probably in a minority on this one, but I do not agree with this assessment, for a number of reasons.
       </p>
       <p>
        First, the idea that you can have a private, in-group conversation on Twitter is absurd.
       </p>
       <p>
        Second, the idea that a whole community of people casually expresses racial animus because of representative examples of wrongdoing by members of a social class can be alarming whether or not it’s Trump voters talking about Mexicans or anti-racists talking about white people. That alarm, as an emotional reaction, is a reality whether or not the dominant racial structures are being reproduced or challenged.
       </p>
       <p>
        Third, I’m not convinced that as a racial project, tweets simply insulting white people really counts as “anti-racist” in a substantive sense. Anti-racist projects are “those that
        <em>
         undo or resist structures of domination based on racial significations and identities
        </em>
        .” Is saying “white men are bullshit” undoing a structure of domination? I’m pretty sure any white supremacist structures of domination have survived that attack. Does it
        <em>
         resist
        </em>
        white supremacist domination? The thrust of wise sociology of race is that what’s more important than the social meanings are the institutional structures that maintain racial inequality. Even if this statement has a meaning that is degrading to white people, it doesn’t seem to be doing any work of reorganizing resources around (anti-)racial lines. It’s just a crass insult. It may well have actually backfired, or had an effect on the racial organization of attention that neither harmed nor supported white supremacy, but rather just made its manifestation on the Internet more toxic (in response to other, much greater, toxicity, of course).
       </p>
       <p>
        I suppose what I’m arguing for is greater nuance than either the “left” or “right” position has offered on this case. I’m saying that it is possible to engage in a racial project that is neither racist nor anti-racist. You could have a racial project that is amusingly absurd, or toxic, or cleverly insightful. Moreover, there is a complex of ethical responsibilities and principles that intersects with racial projects but is not contained by the logic of race. There are greater standards of decency that can be invoked. These are not simply constraints on etiquette. They also are relevant to the contest of racial projects and their outcomes.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/08/07/racial-projects-and-racism-omi-and-winant-2014-jeong-case-study/">
        by Sebastian Benthall at August 07, 2018 07:48 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    August 05, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3537">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/08/05/from-social-movements-to-business-standards/">
       From social movements to business standards
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        Matt Levine has a recent
        <a href="https://www.bloomberg.com/view/articles/2018-08-02/-metoo-is-a-due-diligence-issue-now">
         piece
        </a>
        discussing how discovering the history of sexual harassment complaints about a company’s leadership is becoming part of standard due diligence before an acquisition. Implicitly, the threat of liability, and presumably the costs of a public relations scandal, are material to the value of the company being acquired.
       </p>
       <p>
        Perhaps relatedly, the
        <a href="https://nvca.org/">
         National Venture Capital Association
        </a>
        has added to its
        <a href="https://nvca.org/resources/model-legal-documents/">
         Model Legal Documents
        </a>
        a slew of policies related to harassment and discrimination, codes of conduct, attracting and retaining diverse talent, and family friendly policies. Rumor has it that venture capitalists will now encourage companies they invest in to adopt these tested versions of the policies, much as an organization would adopt a tested and well-understood technical standard.
       </p>
       <p>
        I have in various researcher roles studied social movements and political change, but these studies have left me with the conclusion that changes to culture are rarely self-propelled, but rather are often due to more fundamental changes in demographics or institutions. State legislation is very slow to move and limited in its range, and so often trails behind other amassing of power and will.
       </p>
       <p>
        Corporate self-regulation, on the other hand, through standards, contracts, due diligence, and the like, seems to be quite adaptive. This is leading me to the conclusion that a best kept secret of cultural change is that some of the main drivers of it are actually deeply embedded in corporate law. Corporate law has the reputation of being a dry subject which sucks in recent law grads into soulless careers. But what if that wasn’t what corporate law was? What if corporate law was really where the action is?
       </p>
       <p>
        In broader terms, the adaptivety of corporate policy to changing demographics and social needs perhaps explains the paradox of “progressive neoliberalism”, or the idea that the emerging professional business class seems to be socially liberal, whether or not it is fiscally conservative. Professional culture requires, due to antidiscrimination law and other policies, the compliance of its employees with a standard of ‘political correctness’. People can’t be hostile to each other in the workplace or else they will get fired, and they especially can’t be hostile to anybody on the basis of their being part of a protected category. This has been enshrined into law long ago. Part of the role of educational institutions is to teach students a coherent story about why these rules are what they are and how they are not just legally mandated, but morally compelling. So the professional class has an ideology of inclusivity because it must.
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/08/05/from-social-movements-to-business-standards/">
        by Sebastian Benthall at August 05, 2018 08:14 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="daygroup">
   <h2 class="daygroup-date">
    July 30, 2018
   </h2>
   <div class="channelgroup">
    <div class="channel-header">
     <div class="channel-title">
      <a href="https://digifesto.com" title="Digifesto">
       Sebastian Benthall
      </a>
     </div>
     <div class="channel-affiliation">
      Ph.D. student
     </div>
    </div>
    <div class="entrygroup" id="http://digifesto.com/?p=3534">
     <h4 class="posttitle" lang="en">
      <a href="https://digifesto.com/2018/07/30/how-the-internet-changed-everything-a-grand-theory-of-ai-etc/">
       How the Internet changed everything: a grand theory of AI, etc.
      </a>
     </h4>
     <div class="entry">
      <div class="content" lang="en">
       <p>
        I have read many a think piece and critical take about AI, the Internet, and so on. I offer a new theory of What Happened, the best I can come up with based on my research and observations to date.
       </p>
       <p>
        Consider
        <a href="https://www.newstatesman.com/science-tech/internet/2018/07/death-don-draper">
         this article
        </a>
        , “The death of Don Draper”, as a story that represents the changes that occur more broadly. In this story, advertising was once a creative field that any company with capital could hire out to increase their chances of getting noticed and purchased, albeit in a noisy way. Because everything was very uncertain, those that could afford it blew a lot of money on it (“Half of advertising is useless; the problem is knowing which half”).
       </p>
       <p>
        A similar story could be told about access to the news–dominated by big budgets that hid quality–and political candidates–whose activities were largely not exposed to scrutiny and could follow a similarly noisy pattern of hype and success.
       </p>
       <p>
        Then along came the Internet and targeted advertising, which did a number of things:
       </p>
       <ul>
        <li>
         It reduced search costs for people looking for particular products, because Google searches the web and Amazon indexes all the products (and because of lots of smaller versions of Google and Amazon).
        </li>
        <li>
         It reduced the uncertainty of advertising effectiveness because it allowed for fine-grained measurement of conversion metrics. This reduced the search costs of producers to advertisers, and from advertisers to audiences.
        </li>
        <li>
         It reduced the search costs of people finding alternative media and political interest groups, leading to a reorganization of culture. The media and cultural landscape could more precisely reflect the exogenous factors of social difference.
        </li>
        <li>
         It reduced the cost of finding people based on their wealth, social influence, and so on, implicitly creating a kind of ‘social credit system’ distributed across various web services. (Gandy, 1993; Fourcade and Healy, 2016)
        </li>
       </ul>
       <p>
        What happens when you reduce search costs in markets? Robert Jensen’s (2007) study of the introduction of mobile phones to fish markets in Kerala is illustrative here. Fish prices were very noisy due to bad communication until mobile phones were introduced. After that, the prices stabilized, owing to swifter communication between fisherman and markets. Suddenly able to preempt prices rather than subject to the vagaries to them, fisherman could then choose to go to the market that would give them the best price.
       </p>
       <p>
        Reducing search costs makes markets more efficient and larger. In doing so, it increases inequality, because whereas a lot of lower quality goods and services can survive in a noisy economy, when consumers are more informed and more efficient at searching, they can cut out less useful services. They can then standardize on “the best” option available, which can be produced with economies of scale. So inefficient, noisy parts of the economy were squeezed out and the surplus amassed in the hands of a big few intermediaries, who we now see as Big Tech leveraging AI.
       </p>
       <p>
        Is AI an appropriate term? I have always liked this definition of AI: “Anything that humans still do better than computers.” Most recently I’ve seen this restated in an
        <a href="https://www.forbes.com/sites/peterhigh/2017/10/30/carnegie-mellon-dean-of-computer-science-on-the-future-of-ai/#266b45172197">
         interview
        </a>
        with Andrew Moore, quoted by
        <a href="http://approximatelycorrect.com/2018/06/05/ai-ml-ai-swirling-nomenclature-slurried-thought/">
         Zachary Lipton
        </a>
        :
       </p>
       <blockquote>
        <p>
         Artificial intelligence is the science and engineering of making computers behave in ways that, until recently, we thought required human intelligence.
        </p>
       </blockquote>
       <p>
        The use of technical platforms to dramatically reduce search costs. “Searching” for people, products, and information is something that used to require human intelligence. Now it is assisted by computers. And whether or not the average user knows that they are doing when they search (Mulligan and Griffin, 2018), as a commercial function, the panoply of search engines and recommendation systems and auctions that occupy the central places in the information economy
        <strong>
         outperform
        </strong>
        human intelligence largely by virtue of having access to more data–a broader perspective–than any individual human could ever accomplish.
       </p>
       <p>
        The comparison between the Google search engine and a human’s intelligence is therefore ill-posed. The kinds of functions tech platforms are performing are things that have only every been solved by human organizations, especially bureaucratic ones. And while the digital user interfaces of these services hides the people “inside” the machines, we know that of course there’s an enormous amount of ongoing human labor involved in the creation and maintenance of any successful “AI” that’s in production.
       </p>
       <p>
        In conclusion, the Internet changed everything for a mundane reason that could have been predicted from neoclassical economic theory. It reduced search costs, creating economic efficiency and inequality, by allowing for new kinds of organizations based on broad digital connectivity. “AI” is a distraction from these accomplishments, as is most “critical” reaction to these developments, which do not do justice to the facts of the matter because by taking up a humanistic lens, they tend not to address how decisions by individual humans and changes to their experience experience are due to large-scale aggregate processes and strategic behaviors by businesses.
       </p>
       <p>
        <strong>
         References
        </strong>
       </p>
       <p>
        Gandy Jr, Oscar H. The Panoptic Sort: A Political Economy of Personal Information. Critical Studies in Communication and in the Cultural Industries. Westview Press, Inc., 5500 Central Avenue, Boulder, CO 80301-2877 (paperback: ISBN-0-8133-1657-X, $18.95; hardcover: ISBN-0-8133-1656-1, $61.50)., 1993.
       </p>
       <p>
        Fourcade, Marion, and Kieran Healy. “Seeing like a market.” Socio-Economic Review 15.1 (2016): 9-29.
       </p>
       <p>
        Jensen, Robert. “The digital provide: Information (technology), market performance, and welfare in the South Indian fisheries sector.” The quarterly journal of economics 122.3 (2007): 879-924.
       </p>
       <p>
        Mulligan, Deirdre K.  and Griffin, Daniel S. “Rescripting Search to Respect the Right to Truth.” 2 GEO. L. TECH. REV. 557 (2018)
       </p>
      </div>
      <p class="date">
       <a href="https://digifesto.com/2018/07/30/how-the-internet-changed-everything-a-grand-theory-of-ai-etc/">
        by Sebastian Benthall at July 30, 2018 09:40 PM
       </a>
      </p>
     </div>
    </div>
   </div>
  </div>
  <div class="sidebar">
   <h2>
    School of Information Blog Planet
   </h2>
   <p>
    The I School Blog Planet is an aggregated and unfiltered feed of blog posts by students, faculty, staff, scholars, and alumni of the
    <a href="http://ischool.berkeley.edu">
     UC Berkeley School of Information
    </a>
    .
   </p>
   <h2>
    Blogs
   </h2>
   <ul>
    <li>
     <a href="https://medium.com/feed/@andyoyellow" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://medium.com/@andyoyellow?source=rss-30b3a3c0fdac------2" title="Stories by Andrew Huang on Medium">
      Andrew Huang
     </a>
     <span class="channel-affiliation">
      (MIMS 2016)
     </span>
    </li>
    <li>
     <a href="https://medium.com/feed/@atlambert" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://medium.com/@atlambert?source=rss-7e4726593dc9------2" title="Stories by Andrew Lambert on Medium">
      Andrew Lambert
     </a>
     <span class="channel-affiliation">
      (MIMS 2016)
     </span>
    </li>
    <li>
     <a href="https://metafarce.com/feed.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="message channel-title" href="https://metafarce.com" title="404: not found">
      Andrew McConachie
     </a>
     <span class="channel-affiliation">
      (MIMS 2015)
     </span>
    </li>
    <li>
     <a href="http://arthurhungry.com/blog/rss.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://arthurhungry.com/blog/" title="arthur hungry">
      Arthur Che
     </a>
     <span class="channel-affiliation">
      (MIMS 2013)
     </span>
    </li>
    <li>
     <a href="https://arvinsahni.wordpress.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://arvinsahni.wordpress.com" title="Data Science and other random thoughts…">
      Arvin Sanhi
     </a>
     <span class="channel-affiliation">
      (MIDS student)
     </span>
    </li>
    <li>
     <a href="https://hoofnagle.berkeley.edu/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://hoofnagle.berkeley.edu" title="Chris Hoofnagle | UC Berkeley School of Information, School of Law">
      Chris Hoofnagle
     </a>
     <span class="channel-affiliation">
      (adjunct professor)
     </span>
    </li>
    <li>
     <a href="https://ctsp.berkeley.edu/feed" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://ctsp.berkeley.edu" title="CTSP">
      Citizen Technologist
     </a>
     <span class="channel-affiliation">
      (Center for Technology, Society &amp; Policy)
     </span>
    </li>
    <li>
     <a href="http://blogs.ischool.berkeley.edu/dperkel/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://blogs.ischool.berkeley.edu/dperkel" title="Perkelating">
      Dan Perkel
     </a>
     <span class="channel-affiliation">
      (Ph.D. alumnus)
     </span>
    </li>
    <li>
     <a href="http://feeds.feedburner.com/davelester" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://blog.davelester.org/" title="Pastiche">
      Dave Lester
     </a>
     <span class="channel-affiliation">
      (MIMS 2013)
     </span>
    </li>
    <li>
     <a href="https://daviddoesdata.wordpress.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://daviddoesdata.wordpress.com" title="David Does Data">
      David Greis
     </a>
     <span class="channel-affiliation">
      (MIMS 2014)
     </span>
    </li>
    <li>
     <a href="https://muchnessofd.wordpress.com/category/info/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://muchnessofd.wordpress.com" title="Info – Muchness. And More.">
      Divya Anand
     </a>
     <span class="channel-affiliation">
      (MIMS 2014)
     </span>
    </li>
    <li>
     <a href="https://medium.com/feed/@GabeNicholas" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://medium.com/@GabeNicholas?source=rss-46376ff20bd3------2" title="Stories by Gabe Nicholas on Medium">
      Gabe Nicholas
     </a>
     <span class="channel-affiliation">
      (MIMS 2018)
     </span>
    </li>
    <li>
     <a href="http://languagelog.ldc.upenn.edu/nll/?author=11&amp;feed=rss2" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="message channel-title" href="http://languagelog.ldc.upenn.edu/nll" title="404: not found">
      Geoff Nunberg
     </a>
     <span class="channel-affiliation">
      (adjunct professor)
     </span>
    </li>
    <li>
     <a href="https://hblog.org/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://hblog.org" title="Hblog.org">
      Heather Ford
     </a>
     <span class="channel-affiliation">
      (MIMS 2011)
     </span>
    </li>
    <li>
     <a href="http://jlzych.com/feed.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://jlzych.com/" title="Jeff Zych">
      Jeff Zych
     </a>
     <span class="channel-affiliation">
      (MIMS 2012)
     </span>
    </li>
    <li>
     <a href="http://dominantprimordialbeast.blogspot.com/feeds/posts/default?alt=rss" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://dominantprimordialbeast.blogspot.com/" title="Project Space">
      Jen Wang
     </a>
     <span class="channel-affiliation">
      (MIMS 2013)
     </span>
    </li>
    <li>
     <a href="https://infolocity.wordpress.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://infolocity.wordpress.com" title="Infolocity">
      Jessica Santana
     </a>
     <span class="channel-affiliation">
      (MIMS 2010)
     </span>
    </li>
    <li>
     <a href="https://josephhall.org/nqb2/index.php?tempskin=_atom" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://josephhall.org/nqb2/index.php" title="Not Quite a Blog">
      Joseph Lorenzo Hall
     </a>
     <span class="channel-affiliation">
      (Ph.D. alumnus)
     </span>
    </li>
    <li>
     <a href="http://artfordorks.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://artfordorks.com" title="Art For Dorks by Laura Devendorf">
      Laura Devendorf
     </a>
     <span class="channel-affiliation">
      (Ph.D. student)
     </span>
    </li>
    <li>
     <a href="http://napsterization.org/stories/index.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://napsterization.org/stories/" title="Napsterization">
      Mary Hodder
     </a>
     <span class="channel-affiliation">
      (MIMS 2004)
     </span>
    </li>
    <li>
     <a href="https://michaeljaylissner.com/feeds/all.atom.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://michaeljaylissner.com/" title="Michael Jay Lissner">
      Michael Lissner
     </a>
     <span class="channel-affiliation">
      (MIMS 2010)
     </span>
    </li>
    <li>
     <a href="https://godelescherblog.wordpress.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://godelescherblog.wordpress.com" title="Godel, Escher, Blog">
      Nicholas Hamlin
     </a>
     <span class="channel-affiliation">
      (MIDS student)
     </span>
    </li>
    <li>
     <a href="http://bcc.npdoty.name/feeds/atom.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://bcc.npdoty.name/" title="Bcc">
      Nick Doty
     </a>
     <span class="channel-affiliation">
      (Ph.D. student)
     </span>
    </li>
    <li>
     <a href="http://blog.cosmopol.is/feed.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="message channel-title" href="http://blog.cosmopol.is/" title="internal server error">
      Nick Merrill
     </a>
     <span class="channel-affiliation">
      (Ph.D. student)
     </span>
    </li>
    <li>
     <a href="http://nickrabinowitz.com/blog/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://nickrabinowitz.com" title="Nick Rabinowitz » Blog">
      Nick Rabinowitz
     </a>
     <span class="channel-affiliation">
      (MIMS 2009)
     </span>
    </li>
    <li>
     <a href="https://medium.com/feed/@n1khl" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://medium.com/@n1khl?source=rss-f99795e0edf5------2" title="Stories by nikhil on Medium">
      Nikhil Mane
     </a>
     <span class="channel-affiliation">
      (MIMS 2016)
     </span>
    </li>
    <li>
     <a href="https://bytegeist.wordpress.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://bytegeist.wordpress.com" title="The Bytegeist">
      Richmond Wong
     </a>
     <span class="channel-affiliation">
      (Ph.D. student)
     </span>
    </li>
    <li>
     <a href="https://www.ryangreenberg.com/atom.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://ryangreenberg.com/" title="Ryan Greenberg">
      Ryan Greenberg
     </a>
     <span class="channel-affiliation">
      (MIMS 2010)
     </span>
    </li>
    <li>
     <a href="https://digifesto.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://digifesto.com" title="Digifesto">
      Sebastian Benthall
     </a>
     <span class="channel-affiliation">
      (Ph.D. student)
     </span>
    </li>
    <li>
     <a href="http://stuartgeiger.com/feed.xml" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://stuartgeiger.com/" title="R. Stuart Geiger">
      Stuart Geiger
     </a>
     <span class="channel-affiliation">
      (Ph.D. student)
     </span>
    </li>
    <li>
     <a href="https://berkeley-biosense.tumblr.com/rss" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://berkeley-biosense.tumblr.com/" title="this week in biosensing">
      This Week in Biosensing
     </a>
     <span class="channel-affiliation">
      (BioSENSE research project)
     </span>
    </li>
    <li>
     <a href="http://blogs.ischool.berkeley.edu/tim/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://blogs.ischool.berkeley.edu/tim" title="Tim's Learning Analytics blog">
      Tim Stutt
     </a>
     <span class="channel-affiliation">
      (MIMS 2013)
     </span>
    </li>
    <li>
     <a href="http://www.zephoria.org/thoughts/feed" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="http://www.zephoria.org/thoughts" title="danah boyd | apophenia">
      danah boyd
     </a>
     <span class="channel-affiliation">
      (Ph.D. alumna)
     </span>
    </li>
    <li>
     <a href="https://koalacarte.wordpress.com/feed/" title="subscribe">
      <img alt="(feed)" src="images/feed-icon-10x10.png"/>
     </a>
     <a class="channel-title" href="https://koalacarte.wordpress.com" title="koAlacarte">
      koAlacarte
     </a>
     <span class="channel-affiliation">
      (MIMS 2016 final project)
     </span>
    </li>
   </ul>
   <p>
    <strong>
     Last updated:
    </strong>
    <br/>
    March 10, 2019 06:07 AM
    <br/>
    <em>
     All times are UTC.
    </em>
    <br/>
    <br/>
    Powered by:
    <br/>
    <a href="http://www.planetplanet.org/">
     <img alt="Planet" border="0" height="15" src="images/planet.png" width="80"/>
    </a>
   </p>
  </div>
 </body>
</html>
